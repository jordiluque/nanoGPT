{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy datasets tiktoken wandb tqdm networkx --quiet\n",
    "!pip3 install transformers --quiet\n",
    "!pip install audiolm-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jls/Soft/nanoGPT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Dataset created with data_url: None\n",
      "DEBUG:root:Parsing data with 400718 characters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train has 165036 tokens\n",
      "val has 18571 tokens\n"
     ]
    }
   ],
   "source": [
    "#@markdown ## Fetch and parse dataset\n",
    "%cd /home/jls/repos/nanoGPT\n",
    "from data.calderon.prepare import Dataset\n",
    "import logging, os\n",
    "\n",
    "# Set logging to debug\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "# Example using shakespeare\n",
    "ds = Dataset()\n",
    "ds.load('./data/calderon/54436-0-clean.txt')\n",
    "ds.parse()\n",
    "ds.export('./data/calderon/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing from OpenAI GPT-2 weights: gpt2\n",
      "loading weights from pretrained gpt: gpt2\n",
      "forcing vocab_size=50257, block_size=1024, bias=True\n",
      "overriding dropout rate to 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 123.65M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /gpt2/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /gpt2/resolve/main/generation_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 50, with 123,925,248 parameters\n",
      "num non-decayed parameter tensors: 98, with 121,344 parameters\n",
      "using fused AdamW: True\n",
      "compiling the model... (takes a ~minute)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-11 12:32:28,442] torch._dynamo.eval_frame: [DEBUG] skipping __init__ /home/jls/.pyenv/versions/3.10.11/lib/python3.10/contextlib.py\n",
      "[2023-05-11 12:32:28,444] torch._dynamo.eval_frame: [DEBUG] skipping __enter__ /home/jls/.pyenv/versions/3.10.11/lib/python3.10/contextlib.py\n",
      "[2023-05-11 12:32:28,445] torch._dynamo.eval_frame: [DEBUG] skipping __init__ /home/jls/.pyenv/versions/3.10.11/lib/python3.10/contextlib.py\n",
      "[2023-05-11 12:32:28,446] torch._dynamo.eval_frame: [DEBUG] skipping __enter__ /home/jls/.pyenv/versions/3.10.11/lib/python3.10/contextlib.py\n",
      "[2023-05-11 12:32:28,447] torch._dynamo.eval_frame: [DEBUG] skipping enable_dynamic /home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py\n",
      "[2023-05-11 12:32:28,454] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward\n",
      "[2023-05-11 12:32:28,455] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:178\n",
      "[2023-05-11 12:32:28,456] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST idx []\n",
      "[2023-05-11 12:32:28,458] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [TensorVariable()]\n",
      "[2023-05-11 12:32:28,459] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device [TorchVariable(cuda:0)]\n",
      "[2023-05-11 12:32:28,460] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:179\n",
      "[2023-05-11 12:32:28,462] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST idx []\n",
      "[2023-05-11 12:32:28,463] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:32:28,465] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:32:28,466] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [SizeVariable()]\n",
      "[2023-05-11 12:32:28,467] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST b [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:28,469] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST t [ConstantVariable(int)]\n",
      "[2023-05-11 12:32:28,470] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:180\n",
      "[2023-05-11 12:32:28,471] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST t []\n",
      "[2023-05-11 12:32:28,472] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(int)]\n",
      "[2023-05-11 12:32:28,473] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,476] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR block_size [ConstantVariable(int), UserDefinedObjectVariable(GPTConfig)]\n",
      "[2023-05-11 12:32:28,478] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP <= [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:28,479] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 54 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:28,480] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:181\n",
      "[2023-05-11 12:32:28,487] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [ConstantVariable(str)]\n",
      "[2023-05-11 12:32:28,489] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR arange [ConstantVariable(str), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:28,491] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [ConstantVariable(str), TorchVariable(<built-in method arange of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:28,493] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST t [ConstantVariable(str), TorchVariable(<built-in method arange of type object at 0x7fe33e7c5540>), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:28,494] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [ConstantVariable(str), TorchVariable(<built-in method arange of type object at 0x7fe33e7c5540>), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:28,495] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR long [ConstantVariable(str), TorchVariable(<built-in method arange of type object at 0x7fe33e7c5540>), ConstantVariable(int), ConstantVariable(int), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:28,498] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device [ConstantVariable(str), TorchVariable(<built-in method arange of type object at 0x7fe33e7c5540>), ConstantVariable(int), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2023-05-11 12:32:28,499] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dtype', 'device') [ConstantVariable(str), TorchVariable(<built-in method arange of type object at 0x7fe33e7c5540>), ConstantVariable(int), ConstantVariable(int), ConstantVariable(dtype), TorchVariable(cuda:0)]\n",
      "[2023-05-11 12:32:28,501] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 4 [ConstantVariable(str), TorchVariable(<built-in method arange of type object at 0x7fe33e7c5540>), ConstantVariable(int), ConstantVariable(int), ConstantVariable(dtype), TorchVariable(cuda:0), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.arange.start\n",
      "[2023-05-11 12:32:28,512] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR unsqueeze [ConstantVariable(str), TensorVariable()]\n",
      "[2023-05-11 12:32:28,514] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [ConstantVariable(str), GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2023-05-11 12:32:28,516] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "[2023-05-11 12:32:28,525] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST pos [ConstantVariable(str), TensorVariable()]\n",
      "[2023-05-11 12:32:28,526] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:184\n",
      "[2023-05-11 12:32:28,528] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2023-05-11 12:32:28,529] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transformer [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,534] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR wte [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,537] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST idx [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,539] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.embedding.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.index.Tensor\n",
      "[2023-05-11 12:32:28,567] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST tok_emb [ConstantVariable(str), TensorVariable()]\n",
      "[2023-05-11 12:32:28,569] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:185\n",
      "[2023-05-11 12:32:28,571] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2023-05-11 12:32:28,572] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transformer [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,575] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR wpe [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,578] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST pos [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,579] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.embedding.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.index.Tensor\n",
      "[2023-05-11 12:32:28,609] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST pos_emb [ConstantVariable(str), TensorVariable()]\n",
      "[2023-05-11 12:32:28,610] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:186\n",
      "[2023-05-11 12:32:28,613] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2023-05-11 12:32:28,614] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transformer [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,617] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR drop [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,620] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST tok_emb [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,622] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST pos_emb [ConstantVariable(str), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:28,623] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [ConstantVariable(str), NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:28,635] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:28,640] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), TensorVariable()]\n",
      "[2023-05-11 12:32:28,642] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:32:28,643] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2023-05-11 12:32:28,645] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transformer [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,649] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR h [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,652] torch._dynamo.symbolic_convert: [DEBUG] TRACE GET_ITER None [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,661] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:28,664] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,665] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:32:28,667] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:28,668] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,672] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:28,675] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:28,677] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:32:28,679] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:28,681] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:28,683] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,686] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,688] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,690] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,692] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:28,695] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:28,698] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:28,699] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:28,702] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:28,705] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:28,707] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:28,708] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:28,723] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:28,726] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:28,728] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:28,745] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:28,747] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:28,763] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:28,765] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:28,785] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:28,787] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:28,788] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:28,793] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:28,798] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:32:28,799] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:28,801] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:32:28,803] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:32:28,806] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:32:28,807] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:28,809] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:28,810] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:32:28,816] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:32:28,818] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:28,819] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,822] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,823] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:28,906] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:32:28,909] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:32:28,911] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,916] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:28,917] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:28,919] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:32:28,964] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:32:28,966] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:28,968] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:28,970] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:28,973] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:32:28,975] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:32:28,977] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:28,980] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:28,981] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:28,982] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:28,984] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,986] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:28,987] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:28,989] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:28,991] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:28,996] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:29,003] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:29,006] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:29,007] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:29,008] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:29,019] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:32:29,021] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:32:29,023] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:32:29,025] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:29,028] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:29,030] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:29,032] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:29,033] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,037] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:29,039] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:29,040] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,044] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:29,046] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:29,054] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:29,057] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:29,059] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:29,061] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:29,069] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:32:29,070] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:32:29,072] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:32:29,073] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:29,075] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:29,077] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:29,078] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:29,079] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,082] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:29,084] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:29,085] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,092] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:29,094] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:29,102] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:29,105] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:29,107] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:29,108] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:29,117] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:29,119] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:32:29,121] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:29,123] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,126] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:29,128] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:32:29,130] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:32:29,131] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:29,134] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:32:29,136] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:29,139] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:32:29,140] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:32:29,141] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:29,143] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:29,144] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:29,145] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,148] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:29,150] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:29,157] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:29,159] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:29,160] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "[2023-05-11 12:32:29,176] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:29,177] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:32:29,179] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:32:29,180] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:29,182] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:29,184] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:29,186] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:29,190] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:29,197] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:32:29,200] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2023-05-11 12:32:29,204] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:29,207] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:29,208] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:29,210] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:29,211] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:29,221] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:29,223] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:32:29,224] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:29,225] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,228] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,230] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,232] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,234] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:29,313] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:29,317] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:29,319] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:32:29,320] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:29,321] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:29,325] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:32:29,326] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:29,335] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:29,336] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:32:29,338] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:29,340] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:29,341] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,345] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,347] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,350] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,352] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:29,356] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:29,358] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:29,360] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:29,363] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:29,365] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:29,368] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:29,370] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:29,385] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:29,388] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:29,390] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:29,406] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:29,408] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:29,424] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:29,427] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:29,442] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:29,444] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:29,445] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:29,448] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:29,450] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:32:29,451] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:29,453] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,458] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,461] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:29,535] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:29,536] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:32:29,539] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:32:29,541] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:32:29,543] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:29,546] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:29,548] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:32:29,550] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:32:29,551] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:32:29,553] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:29,564] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:32:29,566] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:29,568] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:29,570] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:29,572] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:29,575] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:32:29,577] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:29,581] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:29,584] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:29,586] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:29,588] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:29,589] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:32:29,591] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:29,593] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:29,595] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:29,596] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:32:29,598] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:32:29,610] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:29,619] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:29,626] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:29,635] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "[2023-05-11 12:32:29,643] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:29,651] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:29,658] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:29,660] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:32:29,661] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:29,664] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:32:29,665] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:29,667] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,671] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,673] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:29,750] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:29,752] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:32:29,753] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:29,756] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,759] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,761] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:29,765] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:29,767] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:32:29,768] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:29,769] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:29,771] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:32:29,772] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:29,782] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:29,783] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:32:29,784] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:29,786] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:29,787] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:32:29,788] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:29,790] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:29,791] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:32:29,792] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:29,793] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,795] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:32:29,796] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:29,797] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,798] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:29,801] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:29,807] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:32:29,808] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:29,809] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:29,810] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,813] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,815] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,818] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,819] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:29,822] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:29,824] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:29,825] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:29,827] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:29,829] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:29,830] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:29,831] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:29,848] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:29,851] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:29,853] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:29,869] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:29,871] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:29,890] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:29,892] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:29,907] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:29,909] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:29,911] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:29,915] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:29,920] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:32:29,921] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:29,922] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:32:29,924] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:32:29,926] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:32:29,928] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:29,929] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:29,931] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:32:29,932] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:32:29,934] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:29,940] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,943] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:29,945] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:30,021] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:32:30,024] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:32:30,025] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,028] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,031] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,032] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:32:30,074] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:32:30,076] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:30,078] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:30,080] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:30,081] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:32:30,082] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:32:30,084] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:30,086] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:30,088] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,089] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,091] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,093] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,095] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,096] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,099] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,100] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:30,114] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:30,116] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:30,118] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,119] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:30,128] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:32:30,129] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:32:30,131] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:32:30,132] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:30,137] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:30,138] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,141] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,143] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,146] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,148] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,149] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,153] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,155] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:30,163] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:30,166] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:30,167] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,169] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:30,178] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:32:30,180] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:32:30,182] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:32:30,183] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:30,186] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:30,187] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,189] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,190] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,193] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,194] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,195] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,198] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,200] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:30,212] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:30,215] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:30,217] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,219] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:30,227] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:30,228] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:32:30,231] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:30,232] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,236] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:30,238] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:32:30,240] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:32:30,243] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:30,245] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:32:30,248] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:30,251] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:32:30,252] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:32:30,254] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:30,255] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:30,257] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:30,258] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,261] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:30,262] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:30,264] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,265] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:30,266] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "[2023-05-11 12:32:30,283] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:30,285] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:32:30,286] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:32:30,288] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:30,291] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:30,293] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:30,295] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,298] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:30,306] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:32:30,309] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2023-05-11 12:32:30,313] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:30,315] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:30,318] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,319] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:30,321] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:30,330] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:30,332] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:32:30,333] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:30,334] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,337] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,339] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,342] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,343] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:30,425] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:30,429] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:30,431] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:32:30,432] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:30,433] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:30,435] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:32:30,436] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:30,446] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:30,448] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:32:30,450] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:30,451] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:30,452] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,455] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,457] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,459] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,461] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:30,463] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:30,465] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:30,466] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:30,468] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:30,470] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:30,472] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:30,473] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:30,494] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:30,497] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:30,499] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:30,514] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:30,516] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:30,532] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:30,534] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:30,549] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:30,551] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:30,553] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:30,555] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:30,558] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:32:30,559] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:30,561] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,566] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,568] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:30,644] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:30,646] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:32:30,647] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:32:30,649] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:32:30,651] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:30,656] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:30,658] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:32:30,661] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:32:30,662] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:32:30,664] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:30,674] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:32:30,676] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:30,678] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:30,681] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:30,683] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:30,685] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:32:30,687] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:30,688] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:30,691] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:30,693] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:30,695] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:30,696] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:32:30,701] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:30,703] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:30,705] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:30,707] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:32:30,708] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:32:30,717] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:30,725] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:30,734] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:30,742] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "[2023-05-11 12:32:30,750] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:30,757] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:30,765] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:30,766] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:32:30,768] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:30,769] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:32:30,770] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:30,772] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,775] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,776] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:30,853] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:30,855] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:32:30,857] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:30,859] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,862] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,864] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:30,869] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:30,871] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:32:30,872] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:30,874] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:30,875] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:32:30,877] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:30,887] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:30,888] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:32:30,890] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:30,891] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:30,892] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:32:30,893] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:30,894] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:30,896] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:32:30,897] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:30,898] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,900] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:32:30,901] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:30,902] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,903] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:30,906] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:30,913] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:32:30,914] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:30,915] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:30,916] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,919] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,921] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,924] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:30,926] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:30,928] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:30,930] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:30,931] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:30,933] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:30,935] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:30,936] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:30,938] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:30,953] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:30,956] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:30,959] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:30,974] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:30,976] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:30,992] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:30,994] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:31,012] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:31,014] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:31,015] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:31,020] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:31,024] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:32:31,026] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:31,027] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:32:31,029] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:32:31,031] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:32:31,032] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,034] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,039] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,041] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:32:31,043] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:31,044] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,047] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,049] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:31,123] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:32:31,126] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:32:31,127] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,130] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,133] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,135] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:32:31,178] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:32:31,180] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:31,181] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:31,184] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:31,186] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:32:31,188] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:32:31,190] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:31,192] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:31,195] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,196] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,198] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,201] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,203] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,204] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,206] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,208] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:31,216] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:31,219] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:31,221] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,223] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:31,232] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:32:31,234] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:32:31,235] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:32:31,237] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:31,241] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:31,243] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,245] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,247] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,250] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,253] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,254] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,256] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,258] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:31,268] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:31,270] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:31,272] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,273] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:31,283] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:32:31,284] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:32:31,287] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:32:31,288] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:31,292] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:31,293] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,296] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,297] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,301] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,303] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,305] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,307] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,309] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:31,319] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:31,321] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:31,324] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,326] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:31,334] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:31,336] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:32:31,338] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:31,339] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,342] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:31,344] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:32:31,345] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:32:31,347] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:31,349] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:32:31,351] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:31,353] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:32:31,355] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:32:31,356] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:31,357] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:31,359] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:31,360] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,362] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:31,363] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:31,365] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,366] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:31,368] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "[2023-05-11 12:32:31,387] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:31,389] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:32:31,390] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:32:31,391] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:31,393] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:31,395] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:31,396] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,400] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:31,407] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:32:31,410] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2023-05-11 12:32:31,414] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:31,416] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:31,418] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,419] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:31,421] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:31,431] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:31,433] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:32:31,434] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:31,435] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,438] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,439] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,442] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,444] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:31,524] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:31,529] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:31,530] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:32:31,531] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:31,533] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:31,540] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:32:31,542] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:31,552] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:31,553] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:32:31,555] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:31,557] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:31,559] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,562] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,563] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,566] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,569] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:31,572] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:31,574] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:31,576] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:31,577] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:31,580] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:31,581] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:31,582] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:31,599] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:31,602] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:31,604] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:31,620] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:31,622] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:31,637] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:31,639] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:31,655] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:31,656] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:31,658] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:31,660] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:31,662] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:32:31,664] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:31,665] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,668] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,669] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:31,745] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:31,747] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:32:31,748] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:32:31,750] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:32:31,751] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:31,754] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:31,756] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:32:31,757] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:32:31,759] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:32:31,760] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:31,773] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:32:31,774] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:31,776] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:31,778] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:31,780] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:31,782] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:32:31,783] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:31,785] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:31,787] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:31,789] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:31,791] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:31,792] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:32:31,794] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:31,802] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:31,804] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:31,805] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:32:31,807] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:32:31,816] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:31,824] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:31,833] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:31,840] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "[2023-05-11 12:32:31,848] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:31,856] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:31,864] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:31,865] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:32:31,866] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:31,868] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:32:31,871] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:31,872] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,875] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,877] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:31,952] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:31,954] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:32:31,956] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:31,958] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,961] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,964] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:31,968] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:31,969] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:32:31,971] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:31,974] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:31,975] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:32:31,978] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:31,985] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:31,987] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:32:31,988] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:31,989] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:31,990] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:32:31,992] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:31,993] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:31,994] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:32:31,995] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:31,997] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:31,998] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:32:31,999] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:32,000] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,001] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:32,004] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:32,010] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:32:32,012] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:32,013] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:32,013] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,016] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,018] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,021] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,022] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:32,024] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:32,027] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:32,028] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:32,029] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:32,031] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:32,032] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:32,033] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:32,048] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:32,051] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:32,053] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:32,068] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:32,069] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:32,084] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:32,086] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:32,103] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:32,104] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:32,106] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:32,111] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:32,115] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:32:32,116] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:32,117] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:32:32,120] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:32:32,122] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:32:32,123] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,125] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,126] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,128] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:32:32,134] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:32,135] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,138] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,140] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:32,212] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:32:32,215] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:32:32,217] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,219] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,221] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,223] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:32:32,265] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:32:32,267] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:32,269] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:32,270] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:32,271] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:32:32,273] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:32:32,274] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:32,279] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:32,281] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,282] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,284] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,286] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,288] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,289] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,291] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,293] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:32,304] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:32,307] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:32,309] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,311] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:32,319] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:32:32,321] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:32:32,322] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:32:32,323] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:32,326] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:32,327] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,328] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,330] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,332] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,337] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,339] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,342] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,344] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:32,353] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:32,355] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:32,357] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,359] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:32,367] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:32:32,369] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:32:32,371] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:32:32,372] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:32,375] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:32,377] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,380] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,381] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,385] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,387] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,388] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,391] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,392] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:32,402] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:32,405] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:32,406] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,408] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:32,417] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:32,419] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:32:32,420] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:32,421] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,426] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:32,427] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:32:32,430] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:32:32,432] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:32,434] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:32:32,437] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:32,439] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:32:32,441] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:32:32,442] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:32,444] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:32,445] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:32,447] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,449] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:32,450] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:32,452] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,457] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:32,459] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "[2023-05-11 12:32:32,471] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:32,473] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:32:32,475] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:32:32,476] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:32,478] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:32,480] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:32,482] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,483] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:32,493] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:32:32,496] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2023-05-11 12:32:32,501] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:32,504] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:32,505] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,508] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:32,509] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:32,517] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:32,519] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:32:32,520] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:32,521] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,524] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,528] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,531] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,533] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:32,609] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:32,614] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:32,616] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:32:32,617] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:32,619] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:32,620] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:32:32,622] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:32,632] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:32,633] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:32:32,635] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:32,636] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:32,637] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,640] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,642] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,644] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,646] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:32,649] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:32,651] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:32,652] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:32,659] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:32,661] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:32,663] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:32,664] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:32,679] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:32,683] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:32,684] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:32,700] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:32,701] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:32,717] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:32,718] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:32,734] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:32,736] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:32,737] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:32,740] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:32,742] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:32:32,743] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:32,745] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,750] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,752] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:32,825] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:32,826] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:32:32,829] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:32:32,831] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:32:32,834] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:32,836] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:32,839] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:32:32,841] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:32:32,843] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:32:32,845] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:32,855] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:32:32,856] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:32,859] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:32,862] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:32,864] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:32,867] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:32:32,869] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:32,874] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:32,876] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:32,879] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:32,881] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:32,884] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:32:32,885] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:32,887] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:32,890] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:32,891] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:32:32,892] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:32:32,903] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:32,911] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:32,920] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:32,928] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "[2023-05-11 12:32:32,936] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:32,944] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:32,953] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:32,954] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:32:32,956] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:32,959] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:32:32,960] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:32,961] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,964] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:32,967] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:33,044] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:33,045] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:32:33,047] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:33,050] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,052] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,054] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:33,059] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:33,061] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:32:33,063] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:33,065] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:33,066] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:32:33,068] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:33,077] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:33,078] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:32:33,080] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:33,081] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:33,083] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:32:33,084] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:33,085] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:33,087] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:32:33,088] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:33,090] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,091] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:32:33,092] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:33,094] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,095] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:33,098] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:33,104] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:32:33,105] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:33,106] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:33,108] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,110] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,111] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,114] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,117] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:33,120] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:33,122] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:33,123] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:33,125] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:33,127] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:33,128] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:33,129] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:33,145] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:33,147] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:33,150] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:33,164] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:33,165] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:33,180] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:33,183] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:33,199] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:33,200] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:33,202] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:33,206] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:33,210] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:32:33,212] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:33,213] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:32:33,215] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:32:33,217] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:32:33,218] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,220] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,221] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,222] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:32:33,223] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:33,225] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,233] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,234] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:33,309] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:32:33,312] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:32:33,314] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,317] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,318] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,320] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:32:33,363] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:32:33,365] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:33,367] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:33,368] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:33,370] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:32:33,371] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:32:33,372] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:33,375] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:33,376] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,378] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,383] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,386] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,388] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,389] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,391] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,394] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:33,401] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:33,404] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:33,406] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,407] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:33,417] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:32:33,419] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:32:33,420] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:32:33,422] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:33,424] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:33,426] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,427] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,428] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,431] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,432] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,433] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,436] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,437] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:33,451] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:33,454] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:33,455] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,458] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:33,465] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:32:33,467] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:32:33,469] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:32:33,471] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:33,474] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:33,476] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,478] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,479] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,482] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,483] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,485] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,487] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,489] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:33,499] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:33,502] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:33,504] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,506] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:33,515] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:33,518] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:32:33,519] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:33,522] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,525] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:33,526] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:32:33,529] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:32:33,531] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:33,533] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:32:33,535] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:33,538] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:32:33,539] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:32:33,540] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:33,542] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:33,543] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:33,544] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,547] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:33,548] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:33,550] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,552] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:33,553] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "[2023-05-11 12:32:33,572] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:33,573] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:32:33,574] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:32:33,576] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:33,577] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:33,579] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:33,581] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,582] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:33,593] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:32:33,596] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2023-05-11 12:32:33,600] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:33,602] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:33,605] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,607] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:33,609] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:33,617] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:33,619] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:32:33,622] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:33,623] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,627] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,629] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,633] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,635] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:33,708] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:33,713] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:33,715] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:32:33,716] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:33,718] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:33,719] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:32:33,722] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:33,730] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:33,732] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:32:33,733] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:33,734] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:33,735] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,738] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,742] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,745] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,746] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:33,749] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:33,753] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:33,754] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:33,756] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:33,758] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:33,760] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:33,761] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:33,778] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:33,781] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:33,783] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:33,798] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:33,800] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:33,814] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:33,816] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:33,832] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:33,834] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:33,835] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:33,838] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:33,840] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:32:33,843] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:33,844] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,847] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:33,850] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:33,926] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:33,928] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:32:33,930] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:32:33,932] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:32:33,933] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:33,936] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:33,940] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:32:33,942] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:32:33,945] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:32:33,946] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:33,955] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:32:33,957] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:33,960] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:33,962] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:33,964] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:33,966] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:32:33,968] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:33,970] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:33,975] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:33,977] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:33,979] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:33,981] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:32:33,982] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:33,984] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:33,986] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:33,987] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:32:33,989] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:32:33,999] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:34,007] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:34,015] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:34,023] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "[2023-05-11 12:32:34,031] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:34,040] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:34,048] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:34,049] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:32:34,052] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:34,053] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:32:34,055] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:34,057] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,060] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,061] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:34,135] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:34,137] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:32:34,138] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:34,140] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,143] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,144] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:34,150] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:34,151] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:32:34,153] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:34,154] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:34,156] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:32:34,157] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:34,167] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:34,168] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:32:34,170] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:34,172] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:34,173] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:32:34,175] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:34,176] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:34,177] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:32:34,179] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:34,181] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,182] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:32:34,183] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:34,187] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,188] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:34,192] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:34,194] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:32:34,195] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:34,196] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:34,197] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,200] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,202] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,205] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,207] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:34,210] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:34,212] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:34,213] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:34,216] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:34,218] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:34,220] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:34,221] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:34,236] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:34,240] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:34,241] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:34,257] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:34,259] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:34,275] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:34,277] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:34,293] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:34,295] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:34,296] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:34,301] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:34,305] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:32:34,306] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:34,308] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:32:34,310] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:32:34,312] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:32:34,314] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,315] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,317] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,318] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:32:34,320] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:34,321] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,329] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,331] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:34,403] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:32:34,405] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:32:34,407] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,410] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,411] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,413] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:32:34,455] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:32:34,457] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:34,459] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:34,461] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:34,463] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:32:34,464] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:32:34,467] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:34,470] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:34,472] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,474] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,475] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,478] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,481] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,482] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,486] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,488] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:34,496] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:34,499] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:34,501] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,502] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:34,512] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:32:34,514] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:32:34,515] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:32:34,518] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:34,521] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:34,522] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,525] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,527] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,530] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,532] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,533] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,536] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,539] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:34,546] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:34,549] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:34,551] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,553] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:34,562] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:32:34,564] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:32:34,565] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:32:34,567] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:34,569] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:34,571] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,572] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,573] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,576] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,577] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,579] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,581] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,583] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:34,596] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:34,598] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:34,600] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,601] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:34,610] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:34,611] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:32:34,613] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:34,615] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,618] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:34,620] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:32:34,623] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:32:34,624] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:34,628] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:32:34,630] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:34,633] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:32:34,634] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:32:34,637] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:34,638] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:34,640] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:34,642] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,645] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:34,646] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:34,648] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,649] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:34,650] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "[2023-05-11 12:32:34,666] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:34,668] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:32:34,669] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:32:34,670] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:34,672] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:34,674] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:34,676] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,677] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:34,687] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:32:34,690] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2023-05-11 12:32:34,694] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:34,697] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:34,699] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,700] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:34,702] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:34,711] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:34,713] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:32:34,714] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:34,715] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,718] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,722] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,724] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,726] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:34,804] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:34,808] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:34,810] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:32:34,811] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:34,813] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:34,814] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:32:34,818] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:34,826] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:34,827] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:32:34,828] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:34,830] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:34,831] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,836] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,838] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,841] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,843] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:34,846] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:34,849] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:34,850] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:34,853] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:34,856] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:34,857] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:34,859] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:34,875] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:34,878] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:34,880] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:34,896] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:34,898] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:34,913] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:34,915] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:34,932] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:34,933] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:34,935] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:34,938] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:34,942] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:32:34,943] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:34,944] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,947] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:34,949] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:35,039] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:35,041] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:32:35,042] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:32:35,046] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:32:35,047] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:35,051] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:35,053] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:32:35,055] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:32:35,056] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:32:35,058] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:35,068] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:32:35,071] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:35,073] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:35,075] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:35,077] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:35,080] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:32:35,083] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:35,085] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:35,088] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:35,090] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:35,092] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:35,094] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:32:35,095] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:35,097] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:35,099] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:35,101] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:32:35,102] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:32:35,114] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:35,123] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:35,132] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:35,140] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "[2023-05-11 12:32:35,147] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:35,156] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:35,164] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:35,166] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:32:35,167] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:35,170] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:32:35,172] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:35,174] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,177] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,179] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:35,255] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:35,257] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:32:35,258] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:35,260] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,263] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,264] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:35,270] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:35,272] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:32:35,273] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:35,274] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:35,277] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:32:35,279] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:35,287] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:35,289] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:32:35,291] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:35,292] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:35,293] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:32:35,295] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:35,296] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:35,297] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:32:35,298] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:35,300] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,301] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:32:35,302] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:35,304] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,305] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:35,307] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:35,313] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:32:35,314] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:35,315] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:35,316] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,318] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,321] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,323] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,325] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:35,327] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:35,329] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:35,330] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:35,332] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:35,334] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:35,335] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:35,336] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:35,351] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:35,354] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:35,356] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:35,371] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:35,373] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:35,388] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:35,390] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:35,407] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:35,409] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:35,410] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:35,415] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:35,419] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:32:35,421] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:35,423] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:32:35,425] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:32:35,427] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:32:35,429] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,430] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,432] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,433] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:32:35,434] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:35,436] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,439] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,440] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:35,518] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:32:35,520] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:32:35,521] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,524] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,525] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,527] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:32:35,570] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:32:35,572] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:35,574] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:35,575] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:35,579] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:32:35,580] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:32:35,581] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:35,585] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:35,587] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,589] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,590] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,592] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,594] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,595] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,600] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,602] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:35,609] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:35,612] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:35,614] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,616] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:35,624] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:32:35,626] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:32:35,628] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:32:35,630] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:35,633] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:35,634] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,636] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,637] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,642] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,644] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,646] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,649] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,651] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:35,659] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:35,662] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:35,664] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,666] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:35,674] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:32:35,676] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:32:35,678] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:32:35,679] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:35,681] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:35,683] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,687] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,689] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,692] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,693] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,694] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,697] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,698] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:35,708] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:35,711] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:35,713] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,716] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:35,723] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:35,725] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:32:35,727] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:35,729] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,732] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:35,735] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:32:35,737] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:32:35,739] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:35,741] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:32:35,745] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:35,747] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:32:35,749] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:32:35,750] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:35,752] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:35,754] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:35,756] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,759] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:35,761] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:35,762] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,764] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:35,765] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "[2023-05-11 12:32:35,779] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:35,780] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:32:35,781] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:32:35,782] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:35,784] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:35,786] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:35,789] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,792] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:35,800] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:32:35,803] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2023-05-11 12:32:35,807] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:35,809] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:35,811] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,812] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:35,813] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:35,823] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:35,825] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:32:35,827] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:35,828] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,831] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,833] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,836] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,837] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:35,910] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:35,914] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:35,916] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:32:35,917] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:35,919] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:35,920] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:32:35,922] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:35,931] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:35,932] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:32:35,934] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:35,935] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:35,936] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,939] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,940] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,943] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:35,945] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:35,948] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:35,949] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:35,951] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:35,952] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:35,954] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:35,956] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:35,964] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:35,978] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:35,981] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:35,982] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:35,997] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:35,999] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:36,014] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:36,015] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:36,031] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:36,032] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:36,035] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:36,037] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:36,040] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:32:36,041] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:36,042] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,045] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,049] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:36,122] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:36,123] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:32:36,126] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:32:36,128] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:32:36,131] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:36,134] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:36,137] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:32:36,138] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:32:36,139] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:32:36,143] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:36,152] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:32:36,153] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:36,155] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:36,157] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:36,159] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:36,162] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:32:36,163] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:36,165] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:36,167] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:36,169] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:36,171] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:36,173] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:32:36,174] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:36,181] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:36,183] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:36,184] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:32:36,186] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:32:36,195] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:36,202] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:36,210] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:36,218] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "[2023-05-11 12:32:36,226] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:36,233] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:36,241] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:36,242] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:32:36,245] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:36,246] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:32:36,249] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:36,250] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,254] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,256] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:36,328] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:36,330] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:32:36,332] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:36,334] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,337] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,338] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:36,343] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:36,345] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:32:36,347] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:36,348] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:36,350] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:32:36,352] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:36,361] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:36,363] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:32:36,364] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:36,365] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:36,368] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:32:36,370] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:36,372] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:36,373] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:32:36,374] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:36,376] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,377] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:32:36,378] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:36,379] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,380] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:36,383] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:36,388] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:32:36,389] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:36,390] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:36,391] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,394] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,396] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,399] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,401] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:36,403] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:36,406] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:36,407] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:36,409] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:36,411] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:36,412] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:36,413] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:36,428] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:36,431] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:36,433] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:36,448] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:36,450] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:36,464] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:36,466] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:36,482] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:36,484] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:36,485] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:36,490] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:36,494] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:32:36,495] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:36,497] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:32:36,499] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:32:36,500] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:32:36,502] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,503] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,504] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,506] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:32:36,507] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:36,508] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,511] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,512] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:36,591] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:32:36,594] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:32:36,595] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,598] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,599] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,601] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:32:36,645] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:32:36,647] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:36,649] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:36,651] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:36,653] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:32:36,654] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:32:36,655] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:36,658] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:36,659] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,663] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,664] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,667] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,669] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,670] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,673] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,675] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:36,683] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:36,687] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:36,689] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,690] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:36,698] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:32:36,700] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:32:36,702] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:32:36,703] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:36,706] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:36,707] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,708] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,710] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,712] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,714] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,715] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,717] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,719] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:36,733] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:36,735] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:36,737] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,740] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:36,748] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:32:36,749] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:32:36,751] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:32:36,753] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:36,756] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:36,758] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,760] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,762] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,765] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,767] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,768] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,770] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,774] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:36,782] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:36,785] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:36,787] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,788] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:36,798] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:36,799] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:32:36,802] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:36,803] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,807] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:36,808] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:32:36,811] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:32:36,813] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:36,816] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:32:36,818] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:36,822] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:32:36,823] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:32:36,824] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:36,825] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:36,827] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:36,828] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,831] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:36,832] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:36,834] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,835] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:36,837] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "[2023-05-11 12:32:36,853] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:36,854] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:32:36,856] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:32:36,857] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:36,858] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:36,863] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:36,865] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,866] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:36,875] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:32:36,878] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2023-05-11 12:32:36,881] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:36,885] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:36,886] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,888] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:36,889] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:36,898] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:36,900] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:32:36,902] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:36,903] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,906] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,908] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,911] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:36,912] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:36,991] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:36,995] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:36,996] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:32:36,999] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:37,000] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:37,002] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:32:37,003] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:37,012] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:37,013] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:32:37,015] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:37,017] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:37,018] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,021] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,022] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,025] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,026] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:37,029] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:37,031] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:37,032] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:37,034] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:37,036] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:37,037] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:37,038] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:37,057] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:37,060] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:37,062] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:37,076] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:37,078] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:37,092] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:37,094] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:37,109] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:37,111] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:37,112] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:37,115] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:37,116] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:32:37,118] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:37,119] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,122] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,123] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:37,200] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:37,201] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:32:37,202] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:32:37,205] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:32:37,206] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:37,208] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:37,210] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:32:37,212] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:32:37,213] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:32:37,215] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:37,227] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:32:37,229] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:37,231] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:37,233] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:37,236] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:37,238] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:32:37,241] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:37,243] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:37,245] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:37,247] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:37,248] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:37,252] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:32:37,254] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:37,257] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:37,259] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:37,261] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:32:37,262] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:32:37,271] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:37,280] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:37,288] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:37,296] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "[2023-05-11 12:32:37,303] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:37,311] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:37,318] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:37,320] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:32:37,322] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:37,323] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:32:37,326] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:37,327] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,331] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,333] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:37,404] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:37,406] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:32:37,407] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:37,410] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,413] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,416] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:37,420] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:37,422] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:32:37,423] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:37,425] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:37,426] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:32:37,428] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:37,438] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:37,439] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:32:37,440] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:37,442] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:37,443] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:32:37,444] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:37,446] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:37,450] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:32:37,451] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:37,453] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,456] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:32:37,457] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:37,458] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,459] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:37,462] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:37,465] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:32:37,467] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:37,468] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:37,469] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,472] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,475] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,477] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,480] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:37,482] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:37,485] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:37,486] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:37,487] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:37,489] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:37,491] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:37,492] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:37,506] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:37,510] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:37,512] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:37,528] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:37,530] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:37,544] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:37,546] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:37,563] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:37,564] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:37,566] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:37,571] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:37,575] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:32:37,576] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:37,577] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:32:37,579] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:32:37,581] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:32:37,583] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,584] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,585] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,587] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:32:37,588] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:37,589] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,592] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,599] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:37,670] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:32:37,673] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:32:37,675] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,678] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,680] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,682] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:32:37,725] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:32:37,728] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:37,729] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:37,730] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:37,732] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:32:37,733] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:32:37,737] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:37,739] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:37,741] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,743] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,744] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,746] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,749] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,750] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,752] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,755] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:37,763] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:37,765] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:37,767] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,769] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:37,777] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:32:37,779] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:32:37,780] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:32:37,783] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:37,785] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:37,787] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,788] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,789] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,791] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,793] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,794] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,796] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,798] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:37,809] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:37,812] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:37,814] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,816] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:37,824] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:32:37,825] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:32:37,828] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:32:37,829] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:37,832] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:37,833] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,834] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,836] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,839] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,840] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,841] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,848] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,850] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:37,858] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:37,861] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:37,862] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,864] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:37,872] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:37,873] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:32:37,876] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:37,877] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,880] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:37,883] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:32:37,884] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:32:37,886] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:37,888] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:32:37,890] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:37,893] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:32:37,894] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:32:37,898] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:37,900] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:37,902] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:37,904] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,907] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:37,909] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:37,910] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,912] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:37,914] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "[2023-05-11 12:32:37,926] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:37,928] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:32:37,929] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:32:37,930] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:37,931] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:37,933] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:37,935] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,939] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:37,947] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:32:37,949] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2023-05-11 12:32:37,953] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:37,955] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:37,957] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,958] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:37,960] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:37,969] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:37,971] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:32:37,972] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:37,973] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,976] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,980] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,983] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:37,984] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:38,057] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:38,061] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:38,062] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:32:38,063] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:38,064] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:38,066] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:32:38,067] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:38,077] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:38,079] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:32:38,080] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:38,082] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:38,084] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,087] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,089] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,092] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,094] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:38,097] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:38,099] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:38,100] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:38,102] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:38,104] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:38,105] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:38,106] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:38,122] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:38,126] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:38,127] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:38,143] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:38,144] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:38,159] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:38,161] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:38,176] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:38,177] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:38,179] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:38,182] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:38,184] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:32:38,185] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:38,187] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,189] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,191] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:38,264] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:38,266] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:32:38,268] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:32:38,270] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:32:38,271] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:38,274] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:38,276] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:32:38,278] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:32:38,279] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:32:38,281] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:38,292] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:32:38,294] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:38,297] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:38,299] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:38,301] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:38,305] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:32:38,307] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:38,309] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:38,312] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:38,313] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:38,315] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:38,319] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:32:38,321] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:38,324] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:38,327] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:38,328] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:32:38,330] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:32:38,338] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:38,346] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:38,354] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:38,361] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "[2023-05-11 12:32:38,368] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:38,376] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:38,383] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:38,385] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:32:38,386] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:38,388] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:32:38,389] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:38,390] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,393] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,394] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:38,467] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:38,470] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:32:38,471] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:38,474] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,477] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,478] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:38,484] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:38,485] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:32:38,487] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:38,490] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:38,491] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:32:38,493] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:38,502] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:38,503] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:32:38,505] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:38,506] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:38,508] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:32:38,511] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:38,512] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:38,513] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:32:38,514] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:38,516] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,517] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:32:38,518] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:38,519] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,520] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:38,523] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:38,528] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:32:38,529] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:38,530] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:38,531] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,534] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,536] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,539] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,540] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:38,543] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:38,545] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:38,546] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:38,548] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:38,550] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:38,551] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:38,552] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:38,568] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:38,571] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:38,572] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:38,588] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:38,589] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:38,605] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:38,607] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:38,623] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:38,624] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:38,626] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:38,631] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:38,635] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:32:38,637] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:38,638] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:32:38,641] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:32:38,643] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:32:38,645] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,646] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,647] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,648] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:32:38,650] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:38,651] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,654] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,655] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:38,736] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:32:38,739] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:32:38,740] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,743] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,744] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,746] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:32:38,789] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:32:38,791] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:38,793] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:38,795] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:38,796] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:32:38,797] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:32:38,799] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:38,801] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:38,803] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,807] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,808] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,811] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,812] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,815] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,817] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,819] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:38,827] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:38,829] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:38,831] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,833] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:38,842] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:32:38,844] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:32:38,846] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:32:38,847] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:38,851] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:38,853] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,855] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,856] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,859] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,860] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,861] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,865] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,868] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:38,875] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:38,878] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:38,881] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,882] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:38,891] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:32:38,893] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:32:38,894] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:32:38,896] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:38,898] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:38,900] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,901] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,903] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,905] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,907] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,908] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,911] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,912] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:38,925] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:38,927] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:38,929] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,930] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:38,940] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:38,941] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:32:38,942] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:38,943] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,946] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:38,950] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:32:38,951] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:32:38,953] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:38,957] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:32:38,959] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:38,962] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:32:38,964] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:32:38,965] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:38,966] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:38,967] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:38,968] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:32:38,971] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:38,972] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:38,974] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:38,975] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:38,976] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "[2023-05-11 12:32:38,993] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:38,994] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:32:38,995] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:32:38,997] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:38,998] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:39,002] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:39,004] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,005] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:39,013] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:32:39,015] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2023-05-11 12:32:39,019] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:39,022] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:39,024] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,025] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,027] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:39,037] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:39,039] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:32:39,040] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:39,041] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,044] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,046] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,048] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,050] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:39,127] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:39,132] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:39,133] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:32:39,135] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:39,137] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:39,140] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:32:39,141] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:39,150] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:39,152] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:32:39,154] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:39,155] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:39,156] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,159] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,161] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,163] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,165] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:39,167] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:39,174] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:39,175] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:39,177] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:39,179] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:39,180] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:39,181] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:39,197] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:39,201] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:39,202] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:39,218] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:39,219] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:39,235] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:39,236] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:39,252] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:39,254] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:39,255] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:39,258] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:39,262] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:32:39,263] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:39,265] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,268] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,269] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:39,347] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:39,349] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:32:39,350] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:32:39,353] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:32:39,356] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:39,359] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:39,362] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:32:39,364] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:32:39,366] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:32:39,368] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:39,378] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:32:39,379] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:39,382] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:39,385] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:39,387] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:39,390] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:32:39,392] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:39,395] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:39,397] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:39,399] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:39,403] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:39,404] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:32:39,407] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:39,409] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:39,411] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:39,413] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:32:39,416] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:32:39,424] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:39,432] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:39,440] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:39,448] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "[2023-05-11 12:32:39,455] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:39,463] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:39,469] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:39,471] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:32:39,472] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:39,474] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:32:39,475] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:39,477] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,480] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,481] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:39,557] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:39,558] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:32:39,560] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:39,561] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,564] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,568] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:39,572] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:39,573] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:32:39,575] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:39,576] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:39,578] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:32:39,581] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:39,589] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:39,591] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:32:39,592] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:39,593] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:39,595] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:32:39,596] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:39,597] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:39,599] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:32:39,600] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:39,605] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,606] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:32:39,607] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:39,608] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,609] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:39,612] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:39,616] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:32:39,617] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:39,618] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:39,619] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,622] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,624] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,627] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,629] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:39,631] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:39,633] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:39,635] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:39,636] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:39,638] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:39,639] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:39,640] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:39,656] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:39,660] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:39,661] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:39,677] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:39,679] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:39,695] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:39,696] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:39,713] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:39,715] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:39,716] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:39,721] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:39,725] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:32:39,727] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:39,728] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:32:39,730] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:32:39,732] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:32:39,733] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,735] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,736] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,737] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:32:39,739] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:39,740] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,742] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,744] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:39,819] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:32:39,822] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:32:39,823] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,826] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,827] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,829] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:32:39,873] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:32:39,875] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:39,877] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:39,878] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:39,880] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:32:39,881] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:32:39,885] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:39,888] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:39,889] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,891] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,892] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,895] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,898] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,900] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,903] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,905] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:39,912] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:39,915] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:39,916] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,918] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:39,927] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:32:39,928] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:32:39,931] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:32:39,932] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:39,936] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:39,939] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,940] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,942] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,945] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,946] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,948] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,951] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,956] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:39,964] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:39,967] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:39,970] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,972] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:39,980] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:32:39,981] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:32:39,983] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:32:39,984] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:39,987] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:39,991] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,992] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,994] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:39,997] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:39,999] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:40,001] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,003] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:40,005] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:40,013] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:40,017] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:40,019] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:40,021] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:40,029] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:40,031] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:32:40,032] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:40,034] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,037] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:40,038] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:32:40,039] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:32:40,041] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:40,043] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:32:40,046] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:40,048] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:32:40,050] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:32:40,051] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:40,053] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:40,054] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:40,056] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,065] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:40,066] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:40,067] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:40,069] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:40,070] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "[2023-05-11 12:32:40,083] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:40,085] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:32:40,086] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:32:40,087] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:40,089] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:40,091] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:40,093] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:40,094] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:40,105] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:32:40,108] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2023-05-11 12:32:40,112] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:40,114] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:40,116] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:40,117] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:40,121] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:40,129] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:40,130] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:32:40,131] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:40,132] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,135] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,137] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,140] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,141] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:40,222] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:40,226] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:40,228] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:32:40,229] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:40,232] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:40,233] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:32:40,235] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:40,243] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:40,245] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:32:40,246] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:40,248] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:40,249] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,252] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,253] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,256] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,257] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:40,264] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:40,266] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:40,268] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:40,269] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:40,271] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:40,273] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:40,274] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:40,292] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:40,295] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:40,296] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:40,312] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:40,314] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:40,328] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:40,330] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:40,347] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:40,348] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:40,350] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:40,353] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:40,355] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:32:40,356] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:40,358] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,361] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,365] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:40,438] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:40,439] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:32:40,441] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:32:40,444] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:32:40,446] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:40,449] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:40,451] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:32:40,454] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:32:40,455] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:32:40,457] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:40,466] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:32:40,468] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:40,470] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:40,472] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:40,474] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:40,476] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:32:40,477] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:40,479] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:40,482] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:40,483] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:40,485] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:40,487] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:32:40,488] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:40,490] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:40,492] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:40,494] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:32:40,495] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:32:40,511] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:40,519] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:40,526] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:40,533] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "[2023-05-11 12:32:40,540] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:40,548] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:40,555] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:40,557] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:32:40,559] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:40,560] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:32:40,563] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:40,564] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,567] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,569] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:40,643] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:40,644] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:32:40,646] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:40,647] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,652] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,654] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:40,659] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:40,661] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:32:40,662] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:40,664] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:40,665] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:32:40,667] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:40,677] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:40,678] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:32:40,680] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:40,681] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:40,683] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:32:40,686] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:40,687] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:40,689] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:32:40,692] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:40,693] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,694] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:32:40,696] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:40,697] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,698] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:40,701] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:40,705] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:32:40,706] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:40,707] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:40,709] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,711] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,714] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,717] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,719] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:40,722] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:40,724] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:40,725] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:40,727] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:40,729] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:40,730] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:40,731] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:40,746] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:40,749] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:40,751] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:40,766] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:40,768] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:40,783] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:40,785] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:40,802] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:40,804] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:40,805] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:40,810] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:40,815] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:32:40,816] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:40,818] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:32:40,820] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:32:40,822] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:32:40,824] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:40,826] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:40,827] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:32:40,829] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:32:40,830] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:40,831] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,834] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,835] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:40,909] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:32:40,912] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:32:40,914] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,918] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:40,919] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:40,922] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:32:40,964] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:32:40,967] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:40,968] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:40,970] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:40,971] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:32:40,972] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:32:40,974] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:40,976] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:40,980] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:40,981] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:40,982] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,985] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:40,987] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:40,988] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:40,991] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:40,994] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:41,001] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:41,004] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:41,006] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:41,008] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:41,015] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:32:41,017] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:32:41,019] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:32:41,021] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:41,023] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:41,026] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:41,028] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:41,030] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,032] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:41,035] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:41,036] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,039] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:41,041] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:41,049] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:41,051] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:41,053] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:41,056] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:41,064] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:32:41,066] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:32:41,067] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:32:41,069] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:41,071] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:41,073] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:41,074] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:41,079] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,081] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:41,084] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:41,085] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,088] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:41,090] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:41,098] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:41,100] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:41,102] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:41,103] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:41,112] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:32:41,114] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:32:41,116] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:41,117] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,120] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:41,121] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:32:41,122] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:32:41,124] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:41,127] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:32:41,129] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:41,135] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:32:41,136] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:32:41,138] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:41,139] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:41,141] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:41,142] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,144] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:41,146] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:41,147] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:41,149] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:41,150] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "[2023-05-11 12:32:41,166] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:41,167] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:32:41,169] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:32:41,170] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:41,171] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:32:41,173] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:32:41,174] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:41,178] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:32:41,185] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:32:41,187] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2023-05-11 12:32:41,191] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:32:41,194] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:41,196] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:41,197] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:41,198] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:41,208] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:41,210] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:32:41,211] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:41,214] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,217] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,220] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,223] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,225] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:41,298] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:41,303] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:32:41,304] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:32:41,306] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:32:41,307] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:41,308] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:32:41,310] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:41,320] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:41,322] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:32:41,324] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:41,326] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:32:41,328] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,331] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,332] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,335] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,338] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:41,340] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:41,343] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:41,345] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:41,347] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:41,349] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:41,350] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:41,351] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:41,368] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:41,371] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:41,374] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:41,388] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:41,390] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:41,404] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:41,406] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:41,422] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:41,423] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:41,425] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:41,428] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:41,430] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:32:41,431] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:41,435] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,438] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,441] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:41,515] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:41,516] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:32:41,518] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:32:41,520] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:32:41,521] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:41,524] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:41,526] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:32:41,527] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:32:41,529] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:32:41,530] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:41,543] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:32:41,545] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:41,548] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:41,550] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:41,553] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:41,556] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:32:41,558] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:41,560] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:32:41,563] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:41,565] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:41,567] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:41,568] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:32:41,572] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:32:41,574] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:32:41,577] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:32:41,579] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:32:41,582] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:32:41,590] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:41,597] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:41,605] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:41,612] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "[2023-05-11 12:32:41,619] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:41,626] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:32:41,634] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:41,635] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:32:41,637] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:41,638] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:32:41,639] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:41,640] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,643] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,644] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:41,719] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:41,720] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:32:41,721] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:32:41,724] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,727] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,729] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:41,734] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:41,735] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:32:41,736] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:41,738] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:41,739] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:32:41,741] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:32:41,750] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:32:41,752] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:32:41,753] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:32:41,754] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:41,755] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:32:41,757] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:41,758] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:41,759] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:32:41,760] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:32:41,762] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:189\n",
      "[2023-05-11 12:32:41,763] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2023-05-11 12:32:41,764] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transformer [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,767] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_f [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,774] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,776] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:41,779] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:32:41,781] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:32:41,782] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:32:41,783] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:41,787] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:32:41,788] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:32:41,789] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:41,804] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:41,806] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:32:41,808] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:41,823] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:41,825] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:32:41,840] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:41,842] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:32:41,858] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:32:41,859] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:32:41,861] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), TensorVariable()]\n",
      "[2023-05-11 12:32:41,862] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:191\n",
      "[2023-05-11 12:32:41,864] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST targets [ConstantVariable(str)]\n",
      "[2023-05-11 12:32:41,865] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(str), TensorVariable()]\n",
      "[2023-05-11 12:32:41,867] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(str), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:32:41,869] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 216 [ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2023-05-11 12:32:41,874] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:193\n",
      "[2023-05-11 12:32:41,875] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2023-05-11 12:32:41,876] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR lm_head [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,881] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:32:41,882] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:41,919] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST logits [ConstantVariable(str), TensorVariable()]\n",
      "[2023-05-11 12:32:41,920] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:194\n",
      "[2023-05-11 12:32:41,921] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F [ConstantVariable(str)]\n",
      "[2023-05-11 12:32:41,923] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cross_entropy [ConstantVariable(str), TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:32:41,925] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST logits [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>)]\n",
      "[2023-05-11 12:32:41,927] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), TensorVariable()]\n",
      "[2023-05-11 12:32:41,930] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:41,934] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST logits [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:41,936] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), GetAttrVariable(TensorVariable(), view), ConstantVariable(int), TensorVariable()]\n",
      "[2023-05-11 12:32:41,940] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), GetAttrVariable(TensorVariable(), view), ConstantVariable(int), GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:32:41,942] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), GetAttrVariable(TensorVariable(), view), ConstantVariable(int), GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:41,944] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:41,953] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST targets [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), TensorVariable()]\n",
      "[2023-05-11 12:32:41,954] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:41,958] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), TensorVariable(), GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:32:41,960] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), TensorVariable(), GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:32:41,968] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:41,970] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('ignore_index',) [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), TensorVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2023-05-11 12:32:41,972] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 3 [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), TensorVariable(), TensorVariable(), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._log_softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.log.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.nll_loss_forward.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.where.ScalarOther\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gather.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.squeeze.dim\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.neg.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.where.ScalarOther\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.device\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "[2023-05-11 12:32:42,101] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST loss [ConstantVariable(str), TensorVariable()]\n",
      "[2023-05-11 12:32:42,103] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:200\n",
      "[2023-05-11 12:32:42,104] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST logits [ConstantVariable(str)]\n",
      "[2023-05-11 12:32:42,106] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST loss [ConstantVariable(str), TensorVariable()]\n",
      "[2023-05-11 12:32:42,107] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [ConstantVariable(str), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:32:42,109] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [ConstantVariable(str), TupleVariable()]\n",
      "[2023-05-11 12:32:42,111] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)\n",
      "[2023-05-11 12:32:42,112] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2023-05-11 12:32:42,114] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/jls/Soft/nanoGPT/model.py, line 200 in forward>])\n",
      "[2023-05-11 12:32:42,179] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.arange.start\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.embedding.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.index.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.embedding.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.index.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._log_softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.log.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.nll_loss_forward.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.where.ScalarOther\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gather.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.squeeze.dim\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.neg.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.where.ScalarOther\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.device\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.arange.start\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.embedding.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.index.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.embedding.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.index.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._log_softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.log.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.nll_loss_forward.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.where.ScalarOther\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gather.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.squeeze.dim\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.neg.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.where.ScalarOther\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.device\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.embedding.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.index.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.embedding.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.index.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.log.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gather.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.squeeze.dim\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.neg.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:00,271] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0\n",
      "[2023-05-11 12:33:00,354] torch._inductor.graph: [INFO] Creating implicit fallback for:\n",
      "  target: aten._scaled_dot_product_efficient_attention.default\n",
      "  args[0]: TensorBox(\n",
      "    PermuteView(data=View(\n",
      "      ReinterpretView(\n",
      "        StorageBox(\n",
      "          ExternKernelOut(\n",
      "            name=buf4,\n",
      "            layout=FixedLayout('cuda', torch.float32, size=[512, 2304], stride=[2304, 1]),\n",
      "            inputs=[InputBuffer(name='arg53_1', layout=FixedLayout('cuda', torch.float32, size=[2304], stride=[1])), ReinterpretView(\n",
      "              StorageBox(\n",
      "                ComputedBuffer(name='buf3', layout=FixedLayout('cuda', torch.float32, size=[1, 512, 768], stride=[393216, 768, 1]), data=Pointwise(\n",
      "                  'cuda',\n",
      "                  torch.float32,\n",
      "                  tmp0 = load(arg149_1, i1)\n",
      "                  tmp1 = load(arg50_1, i2 + 768 * (tmp0))\n",
      "                  tmp2 = index_expr(i1, dtype=torch.int64)\n",
      "                  tmp3 = load(arg51_1, i2 + 768 * (tmp2))\n",
      "                  tmp4 = tmp1 + tmp3\n",
      "                  tmp5 = load(buf1, i1)\n",
      "                  tmp6 = tmp4 - tmp5\n",
      "                  tmp7 = load(buf2, i1)\n",
      "                  tmp8 = index_expr(768, torch.float32)\n",
      "                  tmp9 = tmp7 / tmp8\n",
      "                  tmp10 = constant(1e-05, torch.float32)\n",
      "                  tmp11 = tmp9 + tmp10\n",
      "                  tmp12 = rsqrt(tmp11)\n",
      "                  tmp13 = tmp6 * tmp12\n",
      "                  tmp14 = load(arg0_1, i2)\n",
      "                  tmp15 = tmp13 * tmp14\n",
      "                  tmp16 = load(arg1_1, i2)\n",
      "                  tmp17 = tmp15 + tmp16\n",
      "                  return tmp17\n",
      "                  ,\n",
      "                  ranges=[1, 512, 768],\n",
      "                  origins={embedding_1, arg0_1, embedding, iota, arg1_1, add_1, rsqrt, sub, arg50_1, mul, mul_1, add_2, arg51_1, add, unsqueeze, arg149_1, var_mean}\n",
      "                ))\n",
      "              ),\n",
      "              FixedLayout('cuda', torch.float32, size=(512, 768), stride=[768, 1]),\n",
      "              no origins?\n",
      "            ), ReinterpretView(\n",
      "              StorageBox(\n",
      "                InputBuffer(name='arg52_1', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "              ),\n",
      "              FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "              no origins?\n",
      "            )],\n",
      "            constant_args=(),\n",
      "            kwargs={'alpha': 1, 'beta': 1},\n",
      "            output_view=None,\n",
      "            origins={arg53_1, embedding_1, var_mean, arg0_1, embedding, permute, iota, arg1_1, add_1, rsqrt, addmm, sub, arg50_1, mul, mul_1, add_2, arg51_1, add, unsqueeze, arg149_1, arg52_1, view}\n",
      "          )\n",
      "        ),\n",
      "        FixedLayout('cuda', torch.float32, size=[1, 512, 768], stride=[1179648, 2304, 1]),\n",
      "        no origins?\n",
      "      ),\n",
      "      size=(1, 512, 12, 64),\n",
      "      reindex=lambda i0, i1, i2, i3: [0, i1, 64*i2 + i3],\n",
      "      origins={arg53_1, embedding_1, var_mean, arg0_1, view_3, embedding, permute, iota, arg1_1, view_1, add_1, rsqrt, addmm, sub, arg50_1, mul, mul_1, add_2, arg51_1, add, unsqueeze, arg149_1, arg52_1, split, view}\n",
      "    ), dims=[0, 2, 1, 3])\n",
      "  )\n",
      "  args[1]: TensorBox(\n",
      "    PermuteView(data=View(\n",
      "      ReinterpretView(\n",
      "        StorageBox(\n",
      "          ExternKernelOut(\n",
      "            name=buf4,\n",
      "            layout=FixedLayout('cuda', torch.float32, size=[512, 2304], stride=[2304, 1]),\n",
      "            inputs=[InputBuffer(name='arg53_1', layout=FixedLayout('cuda', torch.float32, size=[2304], stride=[1])), ReinterpretView(\n",
      "              StorageBox(\n",
      "                ComputedBuffer(name='buf3', layout=FixedLayout('cuda', torch.float32, size=[1, 512, 768], stride=[393216, 768, 1]), data=Pointwise(\n",
      "                  'cuda',\n",
      "                  torch.float32,\n",
      "                  tmp0 = load(arg149_1, i1)\n",
      "                  tmp1 = load(arg50_1, i2 + 768 * (tmp0))\n",
      "                  tmp2 = index_expr(i1, dtype=torch.int64)\n",
      "                  tmp3 = load(arg51_1, i2 + 768 * (tmp2))\n",
      "                  tmp4 = tmp1 + tmp3\n",
      "                  tmp5 = load(buf1, i1)\n",
      "                  tmp6 = tmp4 - tmp5\n",
      "                  tmp7 = load(buf2, i1)\n",
      "                  tmp8 = index_expr(768, torch.float32)\n",
      "                  tmp9 = tmp7 / tmp8\n",
      "                  tmp10 = constant(1e-05, torch.float32)\n",
      "                  tmp11 = tmp9 + tmp10\n",
      "                  tmp12 = rsqrt(tmp11)\n",
      "                  tmp13 = tmp6 * tmp12\n",
      "                  tmp14 = load(arg0_1, i2)\n",
      "                  tmp15 = tmp13 * tmp14\n",
      "                  tmp16 = load(arg1_1, i2)\n",
      "                  tmp17 = tmp15 + tmp16\n",
      "                  return tmp17\n",
      "                  ,\n",
      "                  ranges=[1, 512, 768],\n",
      "                  origins={embedding_1, arg0_1, embedding, iota, arg1_1, add_1, rsqrt, sub, arg50_1, mul, mul_1, add_2, arg51_1, add, unsqueeze, arg149_1, var_mean}\n",
      "                ))\n",
      "              ),\n",
      "              FixedLayout('cuda', torch.float32, size=(512, 768), stride=[768, 1]),\n",
      "              no origins?\n",
      "            ), ReinterpretView(\n",
      "              StorageBox(\n",
      "                InputBuffer(name='arg52_1', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "              ),\n",
      "              FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "              no origins?\n",
      "            )],\n",
      "            constant_args=(),\n",
      "            kwargs={'alpha': 1, 'beta': 1},\n",
      "            output_view=None,\n",
      "            origins={arg53_1, embedding_1, var_mean, arg0_1, embedding, permute, iota, arg1_1, add_1, rsqrt, addmm, sub, arg50_1, mul, mul_1, add_2, arg51_1, add, unsqueeze, arg149_1, arg52_1, view}\n",
      "          )\n",
      "        ),\n",
      "        FixedLayout('cuda', torch.float32, size=[1, 512, 768], stride=[1179648, 2304, 1], offset=768),\n",
      "        no origins?\n",
      "      ),\n",
      "      size=(1, 512, 12, 64),\n",
      "      reindex=lambda i0, i1, i2, i3: [0, i1, 64*i2 + i3],\n",
      "      origins={arg53_1, embedding_1, var_mean, arg0_1, embedding, permute, iota, arg1_1, view_1, add_1, rsqrt, addmm, view_2, sub, arg50_1, mul, mul_1, add_2, arg51_1, add, unsqueeze, arg149_1, arg52_1, split, view}\n",
      "    ), dims=[0, 2, 1, 3])\n",
      "  )\n",
      "  args[2]: TensorBox(\n",
      "    PermuteView(data=View(\n",
      "      ReinterpretView(\n",
      "        StorageBox(\n",
      "          ExternKernelOut(\n",
      "            name=buf4,\n",
      "            layout=FixedLayout('cuda', torch.float32, size=[512, 2304], stride=[2304, 1]),\n",
      "            inputs=[InputBuffer(name='arg53_1', layout=FixedLayout('cuda', torch.float32, size=[2304], stride=[1])), ReinterpretView(\n",
      "              StorageBox(\n",
      "                ComputedBuffer(name='buf3', layout=FixedLayout('cuda', torch.float32, size=[1, 512, 768], stride=[393216, 768, 1]), data=Pointwise(\n",
      "                  'cuda',\n",
      "                  torch.float32,\n",
      "                  tmp0 = load(arg149_1, i1)\n",
      "                  tmp1 = load(arg50_1, i2 + 768 * (tmp0))\n",
      "                  tmp2 = index_expr(i1, dtype=torch.int64)\n",
      "                  tmp3 = load(arg51_1, i2 + 768 * (tmp2))\n",
      "                  tmp4 = tmp1 + tmp3\n",
      "                  tmp5 = load(buf1, i1)\n",
      "                  tmp6 = tmp4 - tmp5\n",
      "                  tmp7 = load(buf2, i1)\n",
      "                  tmp8 = index_expr(768, torch.float32)\n",
      "                  tmp9 = tmp7 / tmp8\n",
      "                  tmp10 = constant(1e-05, torch.float32)\n",
      "                  tmp11 = tmp9 + tmp10\n",
      "                  tmp12 = rsqrt(tmp11)\n",
      "                  tmp13 = tmp6 * tmp12\n",
      "                  tmp14 = load(arg0_1, i2)\n",
      "                  tmp15 = tmp13 * tmp14\n",
      "                  tmp16 = load(arg1_1, i2)\n",
      "                  tmp17 = tmp15 + tmp16\n",
      "                  return tmp17\n",
      "                  ,\n",
      "                  ranges=[1, 512, 768],\n",
      "                  origins={embedding_1, arg0_1, embedding, iota, arg1_1, add_1, rsqrt, sub, arg50_1, mul, mul_1, add_2, arg51_1, add, unsqueeze, arg149_1, var_mean}\n",
      "                ))\n",
      "              ),\n",
      "              FixedLayout('cuda', torch.float32, size=(512, 768), stride=[768, 1]),\n",
      "              no origins?\n",
      "            ), ReinterpretView(\n",
      "              StorageBox(\n",
      "                InputBuffer(name='arg52_1', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "              ),\n",
      "              FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "              no origins?\n",
      "            )],\n",
      "            constant_args=(),\n",
      "            kwargs={'alpha': 1, 'beta': 1},\n",
      "            output_view=None,\n",
      "            origins={arg53_1, embedding_1, var_mean, arg0_1, embedding, permute, iota, arg1_1, add_1, rsqrt, addmm, sub, arg50_1, mul, mul_1, add_2, arg51_1, add, unsqueeze, arg149_1, arg52_1, view}\n",
      "          )\n",
      "        ),\n",
      "        FixedLayout('cuda', torch.float32, size=[1, 512, 768], stride=[1179648, 2304, 1], offset=1536),\n",
      "        no origins?\n",
      "      ),\n",
      "      size=(1, 512, 12, 64),\n",
      "      reindex=lambda i0, i1, i2, i3: [0, i1, 64*i2 + i3],\n",
      "      origins={arg53_1, embedding_1, var_mean, view_4, arg0_1, embedding, permute, iota, arg1_1, view_1, add_1, rsqrt, addmm, sub, arg50_1, mul, mul_1, add_2, arg51_1, add, unsqueeze, arg149_1, arg52_1, split, view}\n",
      "    ), dims=[0, 2, 1, 3])\n",
      "  )\n",
      "  args[3]: False\n",
      "  args[4]: True\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "[2023-05-11 12:33:00,378] torch._inductor.graph: [INFO] Using FallbackKernel: torch.ops.aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zero_.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._scaled_dot_product_efficient_attention.default\n",
      "[2023-05-11 12:33:01,479] torch._inductor.scheduler: [DEBUG] removed dead node: buf7\n",
      "[2023-05-11 12:33:01,480] torch._inductor.scheduler: [DEBUG] removed dead node: buf24\n",
      "[2023-05-11 12:33:01,481] torch._inductor.scheduler: [DEBUG] removed dead node: buf40\n",
      "[2023-05-11 12:33:01,482] torch._inductor.scheduler: [DEBUG] removed dead node: buf57\n",
      "[2023-05-11 12:33:01,483] torch._inductor.scheduler: [DEBUG] removed dead node: buf73\n",
      "[2023-05-11 12:33:01,484] torch._inductor.scheduler: [DEBUG] removed dead node: buf90\n",
      "[2023-05-11 12:33:01,485] torch._inductor.scheduler: [DEBUG] removed dead node: buf106\n",
      "[2023-05-11 12:33:01,486] torch._inductor.scheduler: [DEBUG] removed dead node: buf123\n",
      "[2023-05-11 12:33:01,487] torch._inductor.scheduler: [DEBUG] removed dead node: buf139\n",
      "[2023-05-11 12:33:01,488] torch._inductor.scheduler: [DEBUG] removed dead node: buf156\n",
      "[2023-05-11 12:33:01,489] torch._inductor.scheduler: [DEBUG] removed dead node: buf172\n",
      "[2023-05-11 12:33:01,490] torch._inductor.scheduler: [DEBUG] removed dead node: buf189\n",
      "[2023-05-11 12:33:01,607] torch._inductor.scheduler: [DEBUG] remove_buffer('buf2')\n",
      "[2023-05-11 12:33:01,619] torch._inductor.scheduler: [DEBUG] remove_buffer('buf11')\n",
      "[2023-05-11 12:33:01,631] torch._inductor.scheduler: [DEBUG] remove_buffer('buf19')\n",
      "[2023-05-11 12:33:01,640] torch._inductor.scheduler: [DEBUG] remove_buffer('buf28')\n",
      "[2023-05-11 12:33:01,651] torch._inductor.scheduler: [DEBUG] remove_buffer('buf35')\n",
      "[2023-05-11 12:33:01,662] torch._inductor.scheduler: [DEBUG] remove_buffer('buf44')\n",
      "[2023-05-11 12:33:01,673] torch._inductor.scheduler: [DEBUG] remove_buffer('buf52')\n",
      "[2023-05-11 12:33:01,683] torch._inductor.scheduler: [DEBUG] remove_buffer('buf61')\n",
      "[2023-05-11 12:33:01,695] torch._inductor.scheduler: [DEBUG] remove_buffer('buf68')\n",
      "[2023-05-11 12:33:01,706] torch._inductor.scheduler: [DEBUG] remove_buffer('buf77')\n",
      "[2023-05-11 12:33:01,717] torch._inductor.scheduler: [DEBUG] remove_buffer('buf85')\n",
      "[2023-05-11 12:33:01,727] torch._inductor.scheduler: [DEBUG] remove_buffer('buf94')\n",
      "[2023-05-11 12:33:01,739] torch._inductor.scheduler: [DEBUG] remove_buffer('buf101')\n",
      "[2023-05-11 12:33:01,750] torch._inductor.scheduler: [DEBUG] remove_buffer('buf110')\n",
      "[2023-05-11 12:33:01,761] torch._inductor.scheduler: [DEBUG] remove_buffer('buf118')\n",
      "[2023-05-11 12:33:01,771] torch._inductor.scheduler: [DEBUG] remove_buffer('buf127')\n",
      "[2023-05-11 12:33:01,781] torch._inductor.scheduler: [DEBUG] remove_buffer('buf134')\n",
      "[2023-05-11 12:33:01,792] torch._inductor.scheduler: [DEBUG] remove_buffer('buf143')\n",
      "[2023-05-11 12:33:01,803] torch._inductor.scheduler: [DEBUG] remove_buffer('buf151')\n",
      "[2023-05-11 12:33:01,813] torch._inductor.scheduler: [DEBUG] remove_buffer('buf160')\n",
      "[2023-05-11 12:33:01,823] torch._inductor.scheduler: [DEBUG] remove_buffer('buf167')\n",
      "[2023-05-11 12:33:01,834] torch._inductor.scheduler: [DEBUG] remove_buffer('buf176')\n",
      "[2023-05-11 12:33:01,845] torch._inductor.scheduler: [DEBUG] remove_buffer('buf184')\n",
      "[2023-05-11 12:33:01,854] torch._inductor.scheduler: [DEBUG] remove_buffer('buf193')\n",
      "[2023-05-11 12:33:01,865] torch._inductor.scheduler: [DEBUG] remove_buffer('buf200')\n",
      "[2023-05-11 12:33:01,875] torch._inductor.scheduler: [DEBUG] remove_buffer('buf205')\n",
      "[2023-05-11 12:33:02,134] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0\n",
      "[2023-05-11 12:33:02,137] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-05-11 12:33:02,312] torch._dynamo.eval_frame: [DEBUG] skipping _fn /home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py\n",
      "[2023-05-11 12:33:02,313] torch._dynamo.eval_frame: [DEBUG] skipping nothing /home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py\n",
      "[2023-05-11 12:33:03,095] torch._dynamo.eval_frame: [DEBUG] skipping __exit__ /home/jls/.pyenv/versions/3.10.11/lib/python3.10/contextlib.py\n",
      "[2023-05-11 12:33:03,096] torch._dynamo.eval_frame: [DEBUG] skipping __exit__ /home/jls/.pyenv/versions/3.10.11/lib/python3.10/contextlib.py\n",
      "[2023-05-11 12:33:11,068] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward\n",
      "[2023-05-11 12:33:11,069] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:178\n",
      "[2023-05-11 12:33:11,071] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST idx []\n",
      "[2023-05-11 12:33:11,072] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [TensorVariable()]\n",
      "[2023-05-11 12:33:11,073] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device [TorchVariable(cuda:0)]\n",
      "[2023-05-11 12:33:11,074] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:179\n",
      "[2023-05-11 12:33:11,075] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST idx []\n",
      "[2023-05-11 12:33:11,076] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:33:11,077] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:33:11,078] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [SizeVariable()]\n",
      "[2023-05-11 12:33:11,079] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST b [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,080] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST t [ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,081] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:180\n",
      "[2023-05-11 12:33:11,082] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST t []\n",
      "[2023-05-11 12:33:11,083] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,084] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,085] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR block_size [ConstantVariable(int), UserDefinedObjectVariable(GPTConfig)]\n",
      "[2023-05-11 12:33:11,087] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP <= [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,088] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 54 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:11,089] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:181\n",
      "[2023-05-11 12:33:11,089] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [ConstantVariable(str)]\n",
      "[2023-05-11 12:33:11,090] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR arange [ConstantVariable(str), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:11,091] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [ConstantVariable(str), TorchVariable(<built-in method arange of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:11,092] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST t [ConstantVariable(str), TorchVariable(<built-in method arange of type object at 0x7fe33e7c5540>), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,093] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [ConstantVariable(str), TorchVariable(<built-in method arange of type object at 0x7fe33e7c5540>), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,094] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR long [ConstantVariable(str), TorchVariable(<built-in method arange of type object at 0x7fe33e7c5540>), ConstantVariable(int), ConstantVariable(int), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:11,095] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device [ConstantVariable(str), TorchVariable(<built-in method arange of type object at 0x7fe33e7c5540>), ConstantVariable(int), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2023-05-11 12:33:11,096] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dtype', 'device') [ConstantVariable(str), TorchVariable(<built-in method arange of type object at 0x7fe33e7c5540>), ConstantVariable(int), ConstantVariable(int), ConstantVariable(dtype), TorchVariable(cuda:0)]\n",
      "[2023-05-11 12:33:11,097] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 4 [ConstantVariable(str), TorchVariable(<built-in method arange of type object at 0x7fe33e7c5540>), ConstantVariable(int), ConstantVariable(int), ConstantVariable(dtype), TorchVariable(cuda:0), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.arange.start\n",
      "[2023-05-11 12:33:11,108] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR unsqueeze [ConstantVariable(str), TensorVariable()]\n",
      "[2023-05-11 12:33:11,109] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [ConstantVariable(str), GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2023-05-11 12:33:11,110] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "[2023-05-11 12:33:11,115] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST pos [ConstantVariable(str), TensorVariable()]\n",
      "[2023-05-11 12:33:11,116] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:184\n",
      "[2023-05-11 12:33:11,117] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2023-05-11 12:33:11,118] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transformer [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,119] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR wte [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,122] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST idx [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,123] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.embedding.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.index.Tensor\n",
      "[2023-05-11 12:33:11,141] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST tok_emb [ConstantVariable(str), TensorVariable()]\n",
      "[2023-05-11 12:33:11,143] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:185\n",
      "[2023-05-11 12:33:11,144] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2023-05-11 12:33:11,145] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transformer [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,148] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR wpe [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,152] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST pos [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,153] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.embedding.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.index.Tensor\n",
      "[2023-05-11 12:33:11,179] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST pos_emb [ConstantVariable(str), TensorVariable()]\n",
      "[2023-05-11 12:33:11,181] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:186\n",
      "[2023-05-11 12:33:11,183] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2023-05-11 12:33:11,184] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transformer [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,187] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR drop [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,190] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST tok_emb [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,191] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST pos_emb [ConstantVariable(str), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:11,195] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [ConstantVariable(str), NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:11,203] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:11,229] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), TensorVariable()]\n",
      "[2023-05-11 12:33:11,230] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:33:11,232] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2023-05-11 12:33:11,233] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transformer [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,236] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR h [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,238] torch._dynamo.symbolic_convert: [DEBUG] TRACE GET_ITER None [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,245] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:11,248] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,249] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:33:11,250] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:11,255] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,257] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:11,260] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:11,262] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:33:11,264] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.3496, val loss 4.3035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-11 12:33:11,265] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:11,266] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,269] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,271] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,273] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,274] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:11,277] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:11,279] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:11,286] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:11,288] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:11,291] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:11,292] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:11,293] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:11,309] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:11,312] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:11,314] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:11,328] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:11,330] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:11,344] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:11,346] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:11,361] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:11,363] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:11,364] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:11,369] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:11,373] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:33:11,374] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:11,375] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:33:11,377] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:33:11,384] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:33:11,386] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,387] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,388] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,389] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:33:11,391] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:11,392] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,396] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,398] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:11,470] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:33:11,473] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:33:11,475] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,478] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,480] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,482] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:33:11,522] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:33:11,524] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:11,526] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:11,528] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:11,529] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:33:11,530] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:33:11,534] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:11,536] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:11,538] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,539] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,540] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,542] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,546] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,547] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,549] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,551] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:11,559] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:11,561] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:11,563] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,565] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:11,573] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:33:11,575] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:33:11,577] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:33:11,578] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:11,582] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:11,583] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,585] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,588] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,590] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,593] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,594] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,596] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,598] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:11,606] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:11,609] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:11,611] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,613] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:11,621] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:33:11,622] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:33:11,624] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:33:11,625] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:11,628] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:11,629] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,631] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,635] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,638] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,640] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,641] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,643] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,645] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:11,654] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:11,656] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:11,659] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,660] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:11,670] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:11,672] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:33:11,674] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:11,676] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,679] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:11,680] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:33:11,682] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:33:11,683] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:11,685] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:33:11,688] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:11,690] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:33:11,692] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:33:11,693] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:11,695] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:11,696] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:11,698] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,700] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:11,701] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:11,703] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,705] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 174 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:11,707] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:11,708] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:11,710] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill_.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add_.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:11,855] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:11,857] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:33:11,859] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:33:11,860] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:11,862] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:11,864] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:11,865] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,867] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:11,876] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:33:11,878] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "[2023-05-11 12:33:11,889] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:11,891] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:11,894] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,896] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:11,897] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:11,906] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:11,908] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:33:11,910] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:11,912] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,915] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,916] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,919] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:11,920] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:11,995] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:12,018] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:12,019] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:33:12,021] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:12,022] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:12,025] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:33:12,027] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:12,035] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:12,036] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:33:12,038] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:12,039] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:12,041] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,043] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,046] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,049] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,051] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:12,054] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:12,057] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:12,058] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:12,060] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:12,064] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:12,066] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:12,067] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:12,081] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:12,084] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:12,085] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:12,099] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:12,100] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:12,115] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:12,116] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:12,131] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:12,133] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:12,135] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:12,137] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:12,139] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:33:12,140] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:12,142] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,147] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,149] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:12,222] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:12,224] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:33:12,226] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:33:12,228] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:33:12,230] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:12,232] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:12,234] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:33:12,236] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:33:12,240] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:33:12,242] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:12,251] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:33:12,252] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:12,255] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:12,257] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:12,259] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:12,262] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:33:12,263] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:12,265] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:12,267] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:12,269] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:12,271] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:12,276] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:33:12,278] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:12,281] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:12,283] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:12,284] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:33:12,285] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:33:12,294] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:12,301] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:12,308] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:12,316] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:12,327] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:12,335] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:12,342] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:12,345] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:33:12,347] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:12,349] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:33:12,350] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:12,351] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,354] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,355] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:12,428] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:12,429] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:33:12,431] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:12,432] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,435] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,436] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:12,463] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:12,464] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:33:12,467] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:12,468] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:12,470] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:33:12,471] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:12,480] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:12,482] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:33:12,483] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:12,484] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:12,485] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:33:12,487] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:12,488] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:12,489] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:33:12,490] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:12,492] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,493] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:33:12,494] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:12,495] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,496] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:12,499] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:12,506] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:33:12,507] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:12,508] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:12,509] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,511] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,514] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,516] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,518] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:12,520] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:12,522] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:12,524] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:12,525] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:12,527] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:12,528] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:12,529] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:12,544] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:12,547] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:12,549] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:12,565] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:12,566] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:12,582] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:12,584] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:12,602] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:12,603] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:12,605] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:12,610] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:12,614] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:33:12,615] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:12,619] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:33:12,621] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:33:12,623] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:33:12,625] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,626] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,629] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,631] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:33:12,632] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:12,635] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,637] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,639] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:12,714] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:33:12,716] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:33:12,718] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,721] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,725] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,726] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:33:12,769] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:33:12,771] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:12,773] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:12,774] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:12,778] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:33:12,779] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:33:12,780] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:12,783] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:12,784] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,785] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,786] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,789] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,790] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,792] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,794] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,800] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:12,807] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:12,810] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:12,812] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,813] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:12,823] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:33:12,824] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:33:12,827] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:33:12,828] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:12,831] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:12,832] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,834] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,835] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,837] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,839] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,840] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,843] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,845] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:12,858] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:12,860] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:12,862] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,864] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:12,873] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:33:12,875] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:33:12,877] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:33:12,878] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:12,880] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:12,882] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,883] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,887] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,890] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,891] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,892] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,895] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,897] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:12,906] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:12,908] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:12,911] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:12,912] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:12,921] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:12,922] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:33:12,925] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:12,926] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,930] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:12,932] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:33:12,934] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:33:12,936] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:12,938] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:33:12,940] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:12,943] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:33:12,944] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:33:12,946] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:12,947] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:12,948] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:12,950] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,956] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:12,957] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:12,959] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:12,961] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 174 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:12,963] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:12,964] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:12,965] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill_.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add_.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:13,103] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:13,104] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:33:13,106] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:33:13,107] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:13,108] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:13,113] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:13,115] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:13,117] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:13,125] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:33:13,127] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "[2023-05-11 12:33:13,136] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:13,138] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:13,140] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:13,141] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:13,143] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:13,154] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:13,156] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:33:13,157] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:13,158] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,161] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,163] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,165] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,167] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:13,245] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:13,268] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:13,269] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:33:13,270] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:13,273] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:13,275] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:33:13,276] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:13,285] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:13,287] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:33:13,289] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:13,291] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:13,293] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,296] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,298] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,301] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,303] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:13,307] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:13,309] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:13,311] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:13,313] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:13,316] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:13,318] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:13,319] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:13,335] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:13,338] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:13,340] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:13,357] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:13,359] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:13,374] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:13,376] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:13,392] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:13,394] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:13,395] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:13,398] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:13,400] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:33:13,402] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:13,403] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,409] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,410] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:13,484] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:13,486] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:33:13,487] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:33:13,490] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:33:13,491] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:13,494] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:13,496] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:33:13,497] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:33:13,502] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:33:13,504] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:13,513] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:33:13,515] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:13,516] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:13,519] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:13,520] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:13,523] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:33:13,527] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:13,529] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:13,532] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:13,534] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:13,536] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:13,538] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:33:13,540] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:13,542] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:13,545] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:13,547] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:33:13,549] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:33:13,557] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:13,564] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:13,572] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:13,579] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:13,589] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:13,597] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:13,604] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:13,605] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:33:13,607] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:13,608] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:33:13,610] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:13,611] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,614] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,615] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:13,696] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:13,697] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:33:13,700] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:13,701] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,705] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,707] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:13,734] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:13,735] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:33:13,737] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:13,738] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:13,740] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:33:13,741] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:13,751] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:13,753] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:33:13,755] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:13,757] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:13,759] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:33:13,761] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:13,763] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:13,765] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:33:13,766] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:13,767] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,769] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:33:13,770] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:13,771] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,772] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:13,775] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:13,780] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:33:13,781] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:13,782] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:13,783] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,785] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,788] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,791] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,793] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:13,795] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:13,798] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:13,800] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:13,801] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:13,803] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:13,804] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:13,806] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:13,822] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:13,824] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:13,826] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:13,842] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:13,844] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:13,858] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:13,860] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:13,877] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:13,878] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:13,880] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:13,885] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:13,889] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:33:13,891] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:13,892] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:33:13,894] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:33:13,896] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:33:13,898] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:13,899] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:13,901] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:33:13,907] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:33:13,908] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:13,910] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,912] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:13,914] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:13,992] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:33:13,995] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:33:13,997] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,001] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,003] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,004] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:33:14,046] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:33:14,048] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:14,050] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:14,051] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:14,054] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:33:14,055] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:33:14,056] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:14,059] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:14,060] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,062] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,063] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,065] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,070] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,071] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,074] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,076] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:14,084] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:14,087] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:14,088] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,090] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:14,099] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:33:14,100] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:33:14,103] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:33:14,104] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:14,108] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:14,110] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,111] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,114] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,117] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,119] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,121] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,124] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,126] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:14,136] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:14,138] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:14,140] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,142] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:14,151] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:33:14,153] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:33:14,154] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:33:14,156] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:14,158] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:14,160] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,161] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,163] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,165] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,167] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,168] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,171] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,172] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:14,185] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:14,187] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:14,190] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,192] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:14,200] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:14,202] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:33:14,203] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:14,204] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,207] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:14,209] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:33:14,210] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:33:14,212] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:14,214] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:33:14,216] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:14,219] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:33:14,220] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:33:14,221] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:14,223] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:14,224] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:14,225] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,228] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:14,236] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:14,237] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,240] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 174 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:14,242] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:14,243] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:14,245] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill_.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add_.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:14,383] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:14,384] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:33:14,386] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:33:14,387] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:14,389] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:14,391] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:14,395] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,397] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:14,405] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:33:14,408] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "[2023-05-11 12:33:14,416] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:14,419] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:14,420] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,421] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:14,423] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:14,433] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:14,434] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:33:14,435] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:14,436] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,439] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,441] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,444] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,445] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:14,522] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:14,547] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:14,548] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:33:14,550] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:14,551] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:14,553] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:33:14,557] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:14,564] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:14,566] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:33:14,567] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:14,568] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:14,569] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,572] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,574] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,576] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,578] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:14,580] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:14,582] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:14,584] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:14,585] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:14,593] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:14,595] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:14,596] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:14,610] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:14,613] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:14,615] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:14,630] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:14,632] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:14,646] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:14,648] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:14,663] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:14,664] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:14,665] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:14,668] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:14,670] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:33:14,671] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:14,672] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,675] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,676] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:14,752] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:14,753] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:33:14,756] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:33:14,758] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:33:14,759] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:14,762] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:14,765] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:33:14,767] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:33:14,769] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:33:14,771] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:14,780] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:33:14,781] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:14,783] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:14,785] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:14,786] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:14,789] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:33:14,790] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:14,792] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:14,794] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:14,796] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:14,802] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:14,803] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:33:14,806] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:14,808] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:14,811] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:14,813] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:33:14,814] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:33:14,822] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:14,831] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:14,839] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:14,848] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:14,860] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:14,868] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:14,876] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:14,878] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:33:14,881] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:14,882] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:33:14,884] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:14,887] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,890] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,892] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:14,966] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:14,967] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:33:14,969] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:14,971] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,973] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:14,975] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:15,001] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:15,002] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:33:15,004] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:15,005] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:15,006] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:33:15,008] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:15,018] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:15,020] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:33:15,021] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:15,022] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:15,024] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:33:15,025] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:15,027] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:15,028] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:33:15,029] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:15,031] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,032] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:33:15,033] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:15,034] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,036] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:15,038] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:15,045] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:33:15,046] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:15,047] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:15,048] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,051] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,053] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,055] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,057] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:15,060] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:15,063] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:15,064] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:15,065] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:15,067] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:15,068] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:15,070] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:15,084] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:15,088] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:15,090] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:15,105] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:15,107] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:15,121] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:15,124] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:15,140] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:15,141] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:15,143] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:15,147] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:15,151] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:33:15,153] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:15,154] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:33:15,156] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:33:15,158] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:33:15,160] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,161] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,162] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,164] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:33:15,165] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:15,172] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,174] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,176] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:15,245] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:33:15,248] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:33:15,249] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,254] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,256] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,258] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:33:15,298] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:33:15,301] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:15,302] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:15,305] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:15,306] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:33:15,307] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:33:15,309] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:15,313] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:15,314] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,317] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,318] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,320] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,322] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,323] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,325] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,329] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:15,336] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:15,338] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:15,340] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,341] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:15,349] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:33:15,351] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:33:15,353] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:33:15,354] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:15,356] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:15,360] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,361] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,363] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,366] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,368] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,369] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,372] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,374] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:15,381] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:15,383] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:15,385] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,387] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:15,395] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:33:15,397] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:33:15,399] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:33:15,401] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:15,403] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:15,406] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,407] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,409] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,411] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,413] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,417] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,419] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,421] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:15,430] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:15,433] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:15,435] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,438] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:15,445] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:15,448] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:33:15,449] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:15,450] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,454] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:15,456] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:33:15,458] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:33:15,460] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:15,462] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:33:15,464] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:15,466] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:33:15,469] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:33:15,471] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:15,472] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:15,473] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:15,474] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,479] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:15,480] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:15,481] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,484] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 174 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:15,485] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:15,486] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:15,488] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill_.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add_.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:15,623] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:15,625] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:33:15,626] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:33:15,627] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:15,629] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:15,631] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:15,633] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,634] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:15,644] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:33:15,647] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "[2023-05-11 12:33:15,655] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:15,657] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:15,659] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,662] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:15,663] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:15,672] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:15,673] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:33:15,675] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:15,678] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,681] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,683] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,687] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,689] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:15,768] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:15,792] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:15,793] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:33:15,794] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:15,796] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:15,797] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:33:15,799] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:15,810] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:15,811] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:33:15,812] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:15,814] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:15,816] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,820] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,822] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,825] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,827] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:15,830] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:15,832] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:15,833] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:15,837] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:15,840] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:15,842] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:15,843] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:15,860] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:15,863] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:15,864] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:15,879] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:15,881] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:15,896] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:15,898] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:15,913] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:15,915] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:15,917] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:15,920] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:15,922] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:33:15,923] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:15,925] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,927] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:15,929] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:16,004] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:16,005] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:33:16,008] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:33:16,010] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:33:16,011] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:16,015] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:16,018] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:33:16,020] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:33:16,021] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:33:16,023] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:16,033] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:33:16,035] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:16,037] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:16,039] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:16,041] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:16,043] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:33:16,047] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:16,049] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:16,053] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:16,055] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:16,057] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:16,059] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:33:16,061] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:16,063] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:16,066] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:16,067] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:33:16,069] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:33:16,078] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:16,087] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:16,096] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:16,104] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:16,116] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:16,124] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:16,132] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:16,133] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:33:16,136] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:16,137] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:33:16,138] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:16,141] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,144] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,146] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:16,219] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:16,221] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:33:16,222] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:16,224] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,226] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,228] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:16,254] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:16,255] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:33:16,257] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:16,260] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:16,261] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:33:16,263] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:16,271] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:16,273] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:33:16,274] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:16,275] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:16,277] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:33:16,278] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:16,280] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:16,281] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:33:16,285] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:16,286] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,288] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:33:16,289] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:16,290] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,291] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:16,294] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:16,297] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:33:16,298] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:16,299] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:16,300] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,303] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,305] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,307] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,310] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:16,312] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:16,314] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:16,316] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:16,317] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:16,319] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:16,320] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:16,321] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:16,336] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:16,339] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:16,340] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:16,355] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:16,357] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:16,372] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:16,374] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:16,391] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:16,394] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:16,395] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:16,401] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:16,405] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:33:16,407] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:16,408] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:33:16,411] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:33:16,413] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:33:16,417] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,419] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,420] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,422] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:33:16,423] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:16,424] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,427] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,431] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:16,501] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:33:16,504] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:33:16,506] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,509] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,512] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,513] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:33:16,554] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:33:16,555] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:16,557] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:16,558] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:16,560] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:33:16,563] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:33:16,564] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:16,567] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:16,568] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,569] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,570] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,573] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,576] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,577] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,580] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,583] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:16,590] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:16,593] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:16,594] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,596] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:16,605] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:33:16,606] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:33:16,608] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:33:16,611] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:16,613] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:16,615] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,616] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,617] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,620] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,623] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,625] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,628] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,630] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:16,638] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:16,640] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:16,642] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,643] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:16,652] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:33:16,654] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:33:16,655] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:33:16,658] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:16,661] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:16,662] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,664] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,667] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,670] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,672] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,674] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,677] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,679] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:16,688] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:16,690] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:16,692] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,694] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:16,703] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:16,705] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:33:16,706] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:16,709] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,712] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:16,713] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:33:16,716] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:33:16,718] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:16,720] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:33:16,722] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:16,725] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:33:16,726] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:33:16,727] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:16,728] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:16,730] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:16,731] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,734] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:16,735] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:16,736] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,739] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 174 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:16,740] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:16,747] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:16,749] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill_.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add_.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:16,890] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:16,891] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:33:16,893] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:33:16,894] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:16,896] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:16,898] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:16,899] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,901] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:16,912] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:33:16,915] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "[2023-05-11 12:33:16,923] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:16,926] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:16,928] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,929] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:16,931] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:16,940] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:16,943] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:33:16,944] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:16,945] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,950] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,951] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,955] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:16,956] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:17,030] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:17,052] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:17,053] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:33:17,055] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:17,056] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:17,058] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:33:17,061] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:17,069] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:17,070] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:33:17,072] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:17,073] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:17,076] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,079] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,081] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,085] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,086] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:17,090] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:17,092] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:17,094] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:17,096] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:17,098] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:17,099] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:17,104] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:17,118] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:17,121] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:17,123] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:17,138] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:17,139] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:17,155] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:17,157] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:17,173] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:17,174] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:17,176] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:17,179] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:17,182] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:33:17,183] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:17,185] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,189] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,191] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:17,262] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:17,263] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:33:17,265] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:33:17,267] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:33:17,269] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:17,271] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:17,274] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:33:17,275] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:33:17,276] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:33:17,278] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:17,289] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:33:17,291] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:17,293] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:17,295] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:17,298] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:17,300] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:33:17,302] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:17,304] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:17,306] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:17,307] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:17,309] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:17,311] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:33:17,316] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:17,318] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:17,320] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:17,321] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:33:17,323] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:33:17,332] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:17,340] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:17,348] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:17,356] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:17,368] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:17,375] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:17,383] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:17,384] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:33:17,386] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:17,387] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:33:17,389] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:17,390] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,393] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,394] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:17,472] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:17,473] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:33:17,475] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:17,476] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,479] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,480] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:17,507] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:17,508] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:33:17,509] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:17,511] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:17,512] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:33:17,516] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:17,523] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:17,525] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:33:17,526] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:17,527] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:17,528] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:33:17,530] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:17,533] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:17,534] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:33:17,535] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:17,538] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,539] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:33:17,540] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:17,541] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,542] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:17,545] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:17,548] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:33:17,549] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:17,550] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:17,551] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,554] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,556] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,558] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,560] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:17,563] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:17,565] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:17,566] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:17,567] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:17,569] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:17,571] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:17,572] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:17,587] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:17,590] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:17,592] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:17,608] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:17,609] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:17,626] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:17,627] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:17,643] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:17,645] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:17,647] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:17,654] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:17,658] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:33:17,660] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:17,662] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:33:17,663] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:33:17,665] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:33:17,667] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,668] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,673] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,675] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:33:17,676] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:17,679] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,681] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,683] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:17,757] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:33:17,759] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:33:17,761] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,763] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,765] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,766] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:33:17,810] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:33:17,813] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:17,814] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:17,815] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:17,818] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:33:17,819] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:33:17,821] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:17,825] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:17,826] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,827] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,829] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,831] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,833] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,834] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,837] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,839] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:17,847] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:17,849] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:17,851] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,852] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:17,860] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:33:17,862] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:33:17,863] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:33:17,864] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:17,867] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:17,868] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,870] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,871] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,874] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,875] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,876] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,879] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,880] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:17,894] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:17,896] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:17,899] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,900] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:17,908] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:33:17,910] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:33:17,911] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:33:17,913] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:17,917] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:17,918] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,921] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,922] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,926] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,927] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,929] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,931] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,933] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:17,943] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:17,946] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:17,948] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:17,950] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:17,959] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:17,961] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:33:17,962] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:17,965] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,967] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:17,969] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:33:17,970] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:33:17,974] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:17,976] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:33:17,978] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:17,982] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:33:17,984] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:33:17,985] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:17,986] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:17,988] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:17,989] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,992] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:17,993] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:17,994] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:17,997] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 174 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:17,998] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:18,000] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:18,001] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill_.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add_.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:18,158] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:18,159] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:33:18,160] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:33:18,161] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:18,165] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:18,167] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:18,169] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:18,171] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:18,179] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:33:18,182] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "[2023-05-11 12:33:18,191] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:18,194] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:18,196] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:18,197] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:18,199] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:18,209] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:18,211] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:33:18,213] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:18,214] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,219] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,220] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,223] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,225] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:18,301] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:18,324] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:18,325] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:33:18,327] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:18,329] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:18,330] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:33:18,332] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:18,341] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:18,342] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:33:18,345] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:18,346] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:18,347] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,350] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,351] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,354] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,358] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:18,360] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:18,362] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:18,365] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:18,368] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:18,370] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:18,372] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:18,373] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:18,390] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:18,393] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:18,395] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:18,411] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:18,414] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:18,428] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:18,430] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:18,446] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:18,448] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:18,449] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:18,452] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:18,456] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:33:18,458] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:18,459] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,462] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,464] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:18,540] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:18,541] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:33:18,543] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:33:18,545] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:33:18,547] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:18,549] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:18,551] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:33:18,552] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:33:18,554] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:33:18,555] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:18,568] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:33:18,569] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:18,571] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:18,573] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:18,575] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:18,577] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:33:18,579] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:18,581] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:18,583] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:18,585] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:18,587] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:18,593] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:33:18,594] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:18,596] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:18,598] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:18,599] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:33:18,601] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:33:18,610] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:18,619] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:18,626] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:18,634] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:18,646] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:18,653] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:18,661] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:18,662] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:33:18,664] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:18,665] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:33:18,666] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:18,668] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,671] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,672] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:18,749] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:18,751] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:33:18,753] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:18,754] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,757] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,761] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:18,787] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:18,788] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:33:18,789] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:18,792] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:18,794] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:33:18,795] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:18,805] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:18,806] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:33:18,809] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:18,810] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:18,813] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:33:18,814] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:18,817] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:18,818] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:33:18,820] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:18,822] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,824] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:33:18,825] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:18,826] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,828] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:18,830] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:18,834] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:33:18,835] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:18,836] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:18,838] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,841] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,843] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,845] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,847] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:18,850] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:18,852] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:18,853] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:18,854] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:18,856] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:18,858] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:18,859] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:18,876] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:18,879] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:18,880] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:18,896] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:18,897] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:18,913] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:18,915] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:18,933] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:18,935] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:18,937] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:18,942] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:18,946] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:33:18,947] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:18,949] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:33:18,951] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:33:18,953] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:33:18,954] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:18,955] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:18,962] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:33:18,963] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:33:18,964] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:18,967] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,969] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:18,971] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:19,046] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:33:19,048] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:33:19,050] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,055] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,057] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,058] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:33:19,102] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:33:19,104] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:19,106] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:19,107] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:19,111] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:33:19,112] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:33:19,115] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:19,117] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:19,120] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,121] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,123] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,126] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,128] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,130] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,132] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,135] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:19,143] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:19,145] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:19,147] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,149] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:19,158] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:33:19,159] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:33:19,161] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:33:19,164] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:19,167] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:19,169] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,170] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,173] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,175] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,178] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,179] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,181] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,184] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:19,192] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:19,194] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:19,196] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,199] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:19,208] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:33:19,209] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:33:19,211] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:33:19,212] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:19,214] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:19,216] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,217] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,219] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,221] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,223] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,224] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,227] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,233] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:19,240] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:19,243] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:19,245] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,247] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:19,255] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:19,257] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:33:19,259] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:19,261] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,264] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:19,266] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:33:19,268] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:33:19,271] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:19,273] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:33:19,275] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:19,277] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:33:19,278] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:33:19,280] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:19,281] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:19,283] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:19,288] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,291] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:19,292] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:19,294] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,296] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 174 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:19,297] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:19,299] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:19,300] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill_.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add_.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:19,442] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:19,444] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:33:19,445] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:33:19,447] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:19,450] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:19,452] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:19,454] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,455] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:19,464] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:33:19,467] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "[2023-05-11 12:33:19,476] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:19,478] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:19,481] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,483] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:19,484] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:19,493] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:19,495] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:33:19,496] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:19,497] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,500] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,501] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,504] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,506] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:19,586] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:19,612] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:19,614] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:33:19,615] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:19,617] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:19,619] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:33:19,621] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:19,630] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:19,631] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:33:19,632] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:19,633] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:19,635] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,638] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,639] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,642] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,644] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:19,646] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:19,653] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:19,654] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:19,656] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:19,658] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:19,660] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:19,661] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:19,678] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:19,680] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:19,682] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:19,698] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:19,700] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:19,716] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:19,718] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:19,734] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:19,736] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:19,738] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:19,740] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:19,744] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:33:19,745] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:19,747] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,750] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,751] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:19,830] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:19,832] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:33:19,834] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:33:19,836] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:33:19,839] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:19,841] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:19,845] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:33:19,846] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:33:19,848] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:33:19,849] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:19,860] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:33:19,862] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:19,864] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:19,866] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:19,869] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:19,871] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:33:19,873] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:19,875] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:19,877] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:19,879] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:19,880] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:19,882] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:33:19,883] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:19,885] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:19,887] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:19,889] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:33:19,890] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:33:19,904] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:19,913] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:19,921] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:19,929] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:19,940] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:19,948] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:19,955] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:19,957] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:33:19,958] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:19,960] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:33:19,961] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:19,963] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,966] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:19,967] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:20,045] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:20,046] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:33:20,049] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:20,051] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,054] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,057] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:20,083] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:20,084] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:33:20,085] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:20,087] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:20,088] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:33:20,090] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:20,101] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:20,103] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:33:20,104] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:20,106] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:20,107] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:33:20,111] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:20,113] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:20,114] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:33:20,115] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:20,116] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,118] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:33:20,119] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:20,120] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,121] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:20,124] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:20,128] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:33:20,130] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:20,131] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:20,132] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,134] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,137] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,139] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,141] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:20,144] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:20,146] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:20,148] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:20,149] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:20,152] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:20,154] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:20,155] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:20,170] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:20,174] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:20,176] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:20,192] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:20,193] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:20,208] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:20,211] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:20,229] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:20,230] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:20,232] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:20,237] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:20,241] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:33:20,243] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:20,244] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:33:20,246] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:33:20,248] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:33:20,250] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,251] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,252] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,258] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:33:20,260] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:20,261] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,264] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,266] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:20,341] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:33:20,344] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:33:20,347] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,349] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,351] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,352] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:33:20,396] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:33:20,398] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:20,400] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:20,402] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:20,403] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:33:20,404] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:33:20,406] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:20,408] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:20,410] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,411] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,413] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,415] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,417] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,418] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,420] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,422] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:20,436] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:20,439] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:20,441] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,443] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:20,451] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:33:20,453] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:33:20,455] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:33:20,457] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:20,460] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:20,462] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,464] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,466] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,469] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,471] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,473] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,476] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,478] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:20,486] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:20,489] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:20,491] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,492] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:20,502] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:33:20,503] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:33:20,505] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:33:20,507] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:20,509] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:20,511] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,512] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,513] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,516] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,517] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,519] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,521] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,523] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:20,536] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:20,539] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:20,540] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,542] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:20,551] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:20,552] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:33:20,554] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:20,555] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,558] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:20,559] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:33:20,561] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:33:20,562] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:20,565] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:33:20,567] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:20,569] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:33:20,571] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:33:20,572] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:20,574] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:20,575] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:20,576] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,579] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:20,581] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:20,582] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,585] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 174 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:20,586] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:20,588] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:20,589] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill_.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add_.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:20,733] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:20,734] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:33:20,736] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:33:20,737] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:20,738] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:20,741] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:20,742] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,744] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:20,755] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:33:20,758] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "[2023-05-11 12:33:20,766] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:20,769] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:20,771] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,772] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:20,775] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:20,784] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:20,785] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:33:20,787] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:20,790] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,793] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,795] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,799] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,801] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:20,876] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:20,900] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:20,902] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:33:20,903] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:20,904] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:20,906] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:33:20,907] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:20,917] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:20,918] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:33:20,920] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:20,921] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:20,923] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,926] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,929] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,932] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:20,934] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:20,937] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:20,940] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:20,941] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:20,943] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:20,945] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:20,947] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:20,948] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:20,965] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:20,968] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:20,969] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:20,985] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:20,987] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:21,002] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:21,004] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:21,020] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:21,022] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:21,023] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:21,026] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:21,028] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:33:21,029] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:21,033] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,036] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,038] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:21,112] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:21,113] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:33:21,116] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:33:21,118] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:33:21,119] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:21,122] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:21,124] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:33:21,125] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:33:21,126] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:33:21,128] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:21,140] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:33:21,142] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:21,143] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:21,146] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:21,147] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:21,149] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:33:21,151] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:21,153] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:21,155] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:21,157] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:21,163] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:21,165] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:33:21,166] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:21,169] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:21,171] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:21,174] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:33:21,175] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:33:21,184] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:21,192] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:21,200] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:21,208] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:21,220] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:21,228] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:21,236] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:21,238] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:33:21,239] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:21,240] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:33:21,242] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:21,243] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,246] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,251] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:21,325] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:21,327] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:33:21,329] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:21,330] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,334] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,336] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:21,361] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:21,363] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:33:21,364] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:21,365] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:21,367] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:33:21,369] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:21,379] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:21,381] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:33:21,383] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:21,385] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:21,387] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:33:21,389] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:21,391] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:21,392] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:33:21,395] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:21,396] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,398] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:33:21,400] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:21,401] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,402] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:21,405] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:21,409] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:33:21,410] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:21,411] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:21,412] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,415] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,417] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,420] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,422] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:21,425] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:21,427] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:21,428] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:21,430] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:21,432] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:21,433] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:21,435] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:21,450] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:21,453] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:21,456] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:21,470] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:21,472] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:21,487] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:21,488] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:21,505] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:21,508] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:21,509] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:21,514] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:21,519] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:33:21,520] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:21,522] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:33:21,524] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:33:21,525] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:33:21,527] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,529] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,530] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,531] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:33:21,532] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:21,534] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,536] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,543] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:21,617] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:33:21,620] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:33:21,621] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,625] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,627] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,628] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:33:21,669] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:33:21,672] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:21,673] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:21,676] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:21,677] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:33:21,679] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:33:21,680] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:21,683] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:21,684] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,685] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,687] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,689] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,693] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,694] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,697] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,699] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:21,708] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:21,710] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:21,712] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,715] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:21,723] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:33:21,724] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:33:21,727] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:33:21,729] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:21,732] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:21,734] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,736] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,738] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,740] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,743] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,744] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,747] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,749] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:21,758] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:21,760] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:21,762] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,764] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:21,773] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:33:21,775] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:33:21,777] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:33:21,779] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:21,782] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:21,784] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,786] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,788] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,792] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,794] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,795] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,799] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,801] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:21,810] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:21,812] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:21,815] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:21,816] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:21,825] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:21,826] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:33:21,829] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:21,830] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,834] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:21,836] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:33:21,837] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:33:21,839] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:21,841] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:33:21,845] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:21,847] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:33:21,850] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:33:21,851] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:21,853] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:21,855] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:21,857] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,869] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:21,870] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:21,872] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:21,874] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 174 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:21,876] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:21,877] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:21,879] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill_.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add_.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:22,016] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:22,019] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:33:22,020] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:33:22,021] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:22,023] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:22,025] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:22,029] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:22,031] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:22,040] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:33:22,042] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "[2023-05-11 12:33:22,052] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:22,055] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:22,056] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:22,058] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:22,059] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:22,069] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:22,070] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:33:22,073] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:22,074] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,077] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,080] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,082] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,084] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:22,162] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:22,187] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:22,189] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:33:22,190] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:22,192] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:22,193] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:33:22,197] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:22,206] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:22,208] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:33:22,209] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:22,211] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:22,213] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,217] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,218] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,222] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,224] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:22,227] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:22,230] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:22,231] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:22,233] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:22,235] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:22,237] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:22,238] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:22,255] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:22,258] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:22,260] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:22,277] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:22,278] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:22,294] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:22,296] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:22,314] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:22,315] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:22,317] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:22,320] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:22,322] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:33:22,323] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:22,324] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,327] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,328] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:22,409] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:22,411] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:33:22,412] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:33:22,415] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:33:22,416] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:22,419] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:22,421] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:33:22,422] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:33:22,424] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:33:22,425] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:22,438] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:33:22,440] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:22,442] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:22,444] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:22,446] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:22,448] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:33:22,450] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:22,451] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:22,454] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:22,455] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:22,457] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:22,459] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:33:22,461] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:22,462] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:22,465] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:22,466] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:33:22,468] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:33:22,482] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:22,491] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:22,499] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:22,508] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:22,520] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:22,528] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:22,537] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:22,539] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:33:22,541] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:22,542] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:33:22,543] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:22,545] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,548] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,549] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:22,629] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:22,630] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:33:22,632] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:22,633] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,637] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,638] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:22,666] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:22,667] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:33:22,669] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:22,670] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:22,671] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:33:22,673] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:22,684] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:22,686] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:33:22,687] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:22,689] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:22,691] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:33:22,694] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:22,695] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:22,698] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:33:22,699] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:22,702] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,703] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:33:22,705] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:22,706] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,707] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:22,710] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:22,714] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:33:22,715] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:22,716] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:22,717] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,720] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,723] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,725] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,727] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:22,730] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:22,732] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:22,733] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:22,735] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:22,737] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:22,739] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:22,740] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:22,757] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:22,760] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:22,762] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:22,777] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:22,780] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:22,794] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:22,797] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:22,815] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:22,816] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:22,817] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:22,822] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:22,826] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:33:22,828] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:22,829] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:33:22,831] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:33:22,833] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:33:22,835] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:22,836] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:22,838] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:33:22,839] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:33:22,840] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:22,841] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,844] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,845] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:22,922] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:33:22,925] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:33:22,926] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,929] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:22,930] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:22,934] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:33:22,976] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:33:22,978] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:22,980] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:22,981] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:22,983] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:33:22,984] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:33:22,985] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:22,988] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:22,989] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:22,990] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:22,992] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:22,994] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:23,000] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:23,002] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,004] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:23,007] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:23,016] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:23,019] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:23,021] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:23,022] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:23,031] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:33:23,033] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:33:23,034] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:33:23,035] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:23,038] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:23,042] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:23,043] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:23,045] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,048] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:23,049] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:23,050] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,053] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:23,055] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:23,066] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:23,069] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:23,071] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:23,073] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:23,081] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:33:23,083] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:33:23,085] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:33:23,086] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:23,089] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:23,090] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:23,092] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:23,093] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,095] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:23,097] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:23,098] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,101] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:23,103] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:23,116] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:23,119] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:23,121] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:23,123] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:23,133] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:23,134] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:33:23,137] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:23,138] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,142] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:23,144] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:33:23,146] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:33:23,148] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:23,151] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:33:23,153] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:23,157] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:33:23,158] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:33:23,160] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:23,162] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:23,163] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:23,165] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,167] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:23,169] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:23,170] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,172] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 174 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:23,174] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:23,175] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:23,176] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill_.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add_.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:23,326] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:23,328] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:33:23,330] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:33:23,331] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:23,333] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:23,335] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:23,337] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:23,338] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:23,348] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:33:23,351] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "[2023-05-11 12:33:23,360] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:23,362] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:23,364] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:23,367] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:23,368] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:23,377] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:23,379] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:33:23,380] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:23,382] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,385] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,386] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,389] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,391] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:23,470] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:23,494] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:23,495] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:33:23,497] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:23,498] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:23,500] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:33:23,501] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:23,511] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:23,513] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:33:23,515] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:23,516] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:23,518] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,521] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,522] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,525] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,526] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:23,530] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:23,532] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:23,533] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:23,535] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:23,537] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:23,538] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:23,540] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:23,560] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:23,563] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:23,565] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:23,580] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:23,582] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:23,597] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:23,598] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:23,614] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:23,616] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:23,618] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:23,620] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:23,622] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:33:23,623] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:23,625] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,627] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,629] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:23,709] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:23,711] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:33:23,712] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:33:23,716] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:33:23,717] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:23,719] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:23,722] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:33:23,723] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:33:23,725] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:33:23,726] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:23,738] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:33:23,740] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:23,743] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:23,745] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:23,747] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:23,749] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:33:23,751] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:23,752] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:23,755] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:23,756] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:23,758] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:23,760] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:33:23,761] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:23,763] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:23,766] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:23,767] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:33:23,769] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:33:23,783] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:23,791] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:23,800] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:23,808] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:23,819] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:23,826] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:23,834] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:23,835] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:33:23,837] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:23,838] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:33:23,839] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:23,843] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,846] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,848] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:23,923] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:23,924] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:33:23,926] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:23,927] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,930] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,934] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:23,958] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:23,960] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:33:23,963] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:23,964] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:23,965] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:33:23,967] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:23,977] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:23,978] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:33:23,980] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:23,983] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:23,984] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:33:23,987] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:23,988] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:23,990] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:33:23,992] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:23,993] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,995] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:33:23,996] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:23,997] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:23,998] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:24,001] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:24,005] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:33:24,006] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:24,007] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:24,008] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,012] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,013] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,015] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,017] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:24,020] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:24,022] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:24,023] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:24,025] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:24,027] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:24,028] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:24,029] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:24,046] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:24,049] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:24,050] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:24,065] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:24,067] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:24,082] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:24,083] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:24,101] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:24,102] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:24,104] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:24,109] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:24,113] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:33:24,114] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:24,116] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:33:24,118] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:33:24,120] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:33:24,121] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,123] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,124] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,125] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:33:24,126] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:24,128] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,130] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,138] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:24,207] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:33:24,210] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:33:24,212] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,214] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,216] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,217] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:33:24,439] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:33:24,440] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:24,441] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:24,442] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:24,443] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:33:24,444] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:33:24,445] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:24,446] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:24,447] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,448] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,448] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,450] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,451] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,451] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,453] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,454] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:24,461] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:24,463] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:24,464] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,465] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:24,470] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:33:24,471] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:33:24,472] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:33:24,473] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:24,475] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:24,476] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,477] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,478] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,480] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,481] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,482] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,483] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,485] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:24,494] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:24,497] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:24,498] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,500] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:24,508] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:33:24,510] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:33:24,511] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:33:24,512] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:24,515] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:24,518] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,519] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,521] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,523] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,525] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,528] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,531] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,532] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:24,541] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:24,543] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:24,545] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,546] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:24,557] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:24,558] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:33:24,560] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:24,562] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,564] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:24,566] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:33:24,567] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:33:24,569] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:24,572] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:33:24,574] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:24,576] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:33:24,578] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:33:24,583] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:24,585] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:24,587] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:24,588] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,591] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:24,592] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:24,593] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,596] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 174 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:24,597] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:24,598] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:24,600] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill_.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add_.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:24,738] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:24,740] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:33:24,741] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:33:24,743] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:24,744] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:24,746] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:24,748] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,749] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:24,760] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:33:24,762] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "[2023-05-11 12:33:24,770] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:24,773] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:24,775] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,777] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:24,778] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:24,787] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:24,788] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:33:24,790] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:24,791] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,794] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,798] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,801] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,803] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:24,877] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:24,900] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:24,901] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:33:24,903] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:24,904] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:24,906] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:33:24,909] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:24,917] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:24,919] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:33:24,920] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:24,921] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:24,923] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,926] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,930] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,933] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:24,935] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:24,938] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:24,940] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:24,943] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:24,945] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:24,948] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:24,949] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:24,951] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:24,966] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:24,969] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:24,971] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:24,987] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:24,989] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:25,003] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:25,005] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:25,021] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:25,023] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:25,024] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:25,027] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:25,031] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:33:25,033] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:25,034] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,037] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,038] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:25,114] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:25,115] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:33:25,117] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:33:25,119] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:33:25,120] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:25,122] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:25,124] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:33:25,129] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:33:25,131] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:33:25,133] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:25,141] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:33:25,142] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:25,144] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:25,148] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:25,150] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:25,152] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:33:25,154] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:25,155] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:25,157] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:25,159] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:25,164] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:25,166] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:33:25,167] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:25,171] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:25,173] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:25,174] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:33:25,175] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:33:25,184] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:25,192] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:25,200] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:25,207] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:25,218] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:25,226] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:25,233] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:25,235] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:33:25,236] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:25,238] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:33:25,240] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:25,242] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,246] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,247] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:25,318] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:25,321] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:33:25,322] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:25,323] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,326] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,327] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:25,352] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:25,354] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:33:25,356] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:25,357] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:25,359] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:33:25,362] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:25,370] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:25,371] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:33:25,372] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:25,374] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:25,375] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:33:25,376] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:25,377] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:25,379] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:33:25,380] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:25,381] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST block [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,383] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:188\n",
      "[2023-05-11 12:33:25,384] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST block [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:25,385] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,386] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), ListIteratorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:25,389] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110> \n",
      " 111           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_FAST                0 (self)\n",
      "              4 LOAD_METHOD              0 (attn)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_METHOD              1 (ln_1)\n",
      "             10 LOAD_FAST                1 (x)\n",
      "             12 CALL_METHOD              1\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 STORE_FAST               1 (x)\n",
      "\n",
      "112          20 LOAD_FAST                1 (x)\n",
      "             22 LOAD_FAST                0 (self)\n",
      "             24 LOAD_METHOD              2 (mlp)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 LOAD_METHOD              3 (ln_2)\n",
      "             30 LOAD_FAST                1 (x)\n",
      "             32 CALL_METHOD              1\n",
      "             34 CALL_METHOD              1\n",
      "             36 BINARY_ADD\n",
      "             38 STORE_FAST               1 (x)\n",
      "\n",
      "113          40 LOAD_FAST                1 (x)\n",
      "             42 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:25,395] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:111\n",
      "[2023-05-11 12:33:25,396] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:25,397] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:25,398] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attn [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,400] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,402] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_1 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,405] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,407] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:25,409] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:25,411] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:25,413] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:25,414] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:25,416] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:25,417] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:25,418] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:25,433] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:25,436] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:25,439] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:25,455] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:25,457] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:25,472] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:25,473] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:25,489] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:25,490] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:25,492] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:25,497] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60> \n",
      "  61           0 LOAD_FAST                1 (x)\n",
      "              2 LOAD_METHOD              0 (size)\n",
      "              4 CALL_METHOD              0\n",
      "              6 UNPACK_SEQUENCE          3\n",
      "              8 STORE_FAST               2 (B)\n",
      "             10 STORE_FAST               3 (T)\n",
      "             12 STORE_FAST               4 (C)\n",
      "\n",
      " 64          14 LOAD_FAST                0 (self)\n",
      "             16 LOAD_METHOD              1 (c_attn)\n",
      "             18 LOAD_FAST                1 (x)\n",
      "             20 CALL_METHOD              1\n",
      "             22 LOAD_ATTR                2 (split)\n",
      "             24 LOAD_FAST                0 (self)\n",
      "             26 LOAD_ATTR                3 (n_embd)\n",
      "             28 LOAD_CONST               1 (2)\n",
      "             30 LOAD_CONST               2 (('dim',))\n",
      "             32 CALL_FUNCTION_KW         2\n",
      "             34 UNPACK_SEQUENCE          3\n",
      "             36 STORE_FAST               5 (q)\n",
      "             38 STORE_FAST               6 (k)\n",
      "             40 STORE_FAST               7 (v)\n",
      "\n",
      " 65          42 LOAD_FAST                6 (k)\n",
      "             44 LOAD_METHOD              4 (view)\n",
      "             46 LOAD_FAST                2 (B)\n",
      "             48 LOAD_FAST                3 (T)\n",
      "             50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_ATTR                5 (n_head)\n",
      "             54 LOAD_FAST                4 (C)\n",
      "             56 LOAD_FAST                0 (self)\n",
      "             58 LOAD_ATTR                5 (n_head)\n",
      "             60 BINARY_FLOOR_DIVIDE\n",
      "             62 CALL_METHOD              4\n",
      "             64 LOAD_METHOD              6 (transpose)\n",
      "             66 LOAD_CONST               3 (1)\n",
      "             68 LOAD_CONST               1 (2)\n",
      "             70 CALL_METHOD              2\n",
      "             72 STORE_FAST               6 (k)\n",
      "\n",
      " 66          74 LOAD_FAST                5 (q)\n",
      "             76 LOAD_METHOD              4 (view)\n",
      "             78 LOAD_FAST                2 (B)\n",
      "             80 LOAD_FAST                3 (T)\n",
      "             82 LOAD_FAST                0 (self)\n",
      "             84 LOAD_ATTR                5 (n_head)\n",
      "             86 LOAD_FAST                4 (C)\n",
      "             88 LOAD_FAST                0 (self)\n",
      "             90 LOAD_ATTR                5 (n_head)\n",
      "             92 BINARY_FLOOR_DIVIDE\n",
      "             94 CALL_METHOD              4\n",
      "             96 LOAD_METHOD              6 (transpose)\n",
      "             98 LOAD_CONST               3 (1)\n",
      "            100 LOAD_CONST               1 (2)\n",
      "            102 CALL_METHOD              2\n",
      "            104 STORE_FAST               5 (q)\n",
      "\n",
      " 67         106 LOAD_FAST                7 (v)\n",
      "            108 LOAD_METHOD              4 (view)\n",
      "            110 LOAD_FAST                2 (B)\n",
      "            112 LOAD_FAST                3 (T)\n",
      "            114 LOAD_FAST                0 (self)\n",
      "            116 LOAD_ATTR                5 (n_head)\n",
      "            118 LOAD_FAST                4 (C)\n",
      "            120 LOAD_FAST                0 (self)\n",
      "            122 LOAD_ATTR                5 (n_head)\n",
      "            124 BINARY_FLOOR_DIVIDE\n",
      "            126 CALL_METHOD              4\n",
      "            128 LOAD_METHOD              6 (transpose)\n",
      "            130 LOAD_CONST               3 (1)\n",
      "            132 LOAD_CONST               1 (2)\n",
      "            134 CALL_METHOD              2\n",
      "            136 STORE_FAST               7 (v)\n",
      "\n",
      " 70         138 LOAD_FAST                0 (self)\n",
      "            140 LOAD_ATTR                7 (flash)\n",
      "            142 POP_JUMP_IF_FALSE       92 (to 184)\n",
      "\n",
      " 72         144 LOAD_GLOBAL              8 (torch)\n",
      "            146 LOAD_ATTR                9 (nn)\n",
      "            148 LOAD_ATTR               10 (functional)\n",
      "            150 LOAD_ATTR               11 (scaled_dot_product_attention)\n",
      "            152 LOAD_FAST                5 (q)\n",
      "            154 LOAD_FAST                6 (k)\n",
      "            156 LOAD_FAST                7 (v)\n",
      "            158 LOAD_CONST               0 (None)\n",
      "            160 LOAD_FAST                0 (self)\n",
      "            162 LOAD_ATTR               12 (training)\n",
      "            164 POP_JUMP_IF_FALSE       86 (to 172)\n",
      "            166 LOAD_FAST                0 (self)\n",
      "            168 LOAD_ATTR               13 (dropout)\n",
      "            170 JUMP_FORWARD             1 (to 174)\n",
      "        >>  172 LOAD_CONST               4 (0)\n",
      "        >>  174 LOAD_CONST               5 (True)\n",
      "            176 LOAD_CONST               6 (('attn_mask', 'dropout_p', 'is_causal'))\n",
      "            178 CALL_FUNCTION_KW         6\n",
      "            180 STORE_FAST               8 (y)\n",
      "            182 JUMP_FORWARD            59 (to 302)\n",
      "\n",
      " 75     >>  184 LOAD_FAST                5 (q)\n",
      "            186 LOAD_FAST                6 (k)\n",
      "            188 LOAD_METHOD              6 (transpose)\n",
      "            190 LOAD_CONST               7 (-2)\n",
      "            192 LOAD_CONST               8 (-1)\n",
      "            194 CALL_METHOD              2\n",
      "            196 BINARY_MATRIX_MULTIPLY\n",
      "            198 LOAD_CONST               9 (1.0)\n",
      "            200 LOAD_GLOBAL             14 (math)\n",
      "            202 LOAD_METHOD             15 (sqrt)\n",
      "            204 LOAD_FAST                6 (k)\n",
      "            206 LOAD_METHOD              0 (size)\n",
      "            208 LOAD_CONST               8 (-1)\n",
      "            210 CALL_METHOD              1\n",
      "            212 CALL_METHOD              1\n",
      "            214 BINARY_TRUE_DIVIDE\n",
      "            216 BINARY_MULTIPLY\n",
      "            218 STORE_FAST               9 (att)\n",
      "\n",
      " 76         220 LOAD_FAST                9 (att)\n",
      "            222 LOAD_METHOD             16 (masked_fill)\n",
      "            224 LOAD_FAST                0 (self)\n",
      "            226 LOAD_ATTR               17 (bias)\n",
      "            228 LOAD_CONST               0 (None)\n",
      "            230 LOAD_CONST               0 (None)\n",
      "            232 BUILD_SLICE              2\n",
      "            234 LOAD_CONST               0 (None)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 BUILD_SLICE              2\n",
      "            240 LOAD_CONST               0 (None)\n",
      "            242 LOAD_FAST                3 (T)\n",
      "            244 BUILD_SLICE              2\n",
      "            246 LOAD_CONST               0 (None)\n",
      "            248 LOAD_FAST                3 (T)\n",
      "            250 BUILD_SLICE              2\n",
      "            252 BUILD_TUPLE              4\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_CONST               4 (0)\n",
      "            258 COMPARE_OP               2 (==)\n",
      "            260 LOAD_GLOBAL             18 (float)\n",
      "            262 LOAD_CONST              10 ('-inf')\n",
      "            264 CALL_FUNCTION            1\n",
      "            266 CALL_METHOD              2\n",
      "            268 STORE_FAST               9 (att)\n",
      "\n",
      " 77         270 LOAD_GLOBAL             19 (F)\n",
      "            272 LOAD_ATTR               20 (softmax)\n",
      "            274 LOAD_FAST                9 (att)\n",
      "            276 LOAD_CONST               8 (-1)\n",
      "            278 LOAD_CONST               2 (('dim',))\n",
      "            280 CALL_FUNCTION_KW         2\n",
      "            282 STORE_FAST               9 (att)\n",
      "\n",
      " 78         284 LOAD_FAST                0 (self)\n",
      "            286 LOAD_METHOD             21 (attn_dropout)\n",
      "            288 LOAD_FAST                9 (att)\n",
      "            290 CALL_METHOD              1\n",
      "            292 STORE_FAST               9 (att)\n",
      "\n",
      " 79         294 LOAD_FAST                9 (att)\n",
      "            296 LOAD_FAST                7 (v)\n",
      "            298 BINARY_MATRIX_MULTIPLY\n",
      "            300 STORE_FAST               8 (y)\n",
      "\n",
      " 80     >>  302 LOAD_FAST                8 (y)\n",
      "            304 LOAD_METHOD              6 (transpose)\n",
      "            306 LOAD_CONST               3 (1)\n",
      "            308 LOAD_CONST               1 (2)\n",
      "            310 CALL_METHOD              2\n",
      "            312 LOAD_METHOD             22 (contiguous)\n",
      "            314 CALL_METHOD              0\n",
      "            316 LOAD_METHOD              4 (view)\n",
      "            318 LOAD_FAST                2 (B)\n",
      "            320 LOAD_FAST                3 (T)\n",
      "            322 LOAD_FAST                4 (C)\n",
      "            324 CALL_METHOD              3\n",
      "            326 STORE_FAST               8 (y)\n",
      "\n",
      " 83         328 LOAD_FAST                0 (self)\n",
      "            330 LOAD_METHOD             23 (resid_dropout)\n",
      "            332 LOAD_FAST                0 (self)\n",
      "            334 LOAD_METHOD             24 (c_proj)\n",
      "            336 LOAD_FAST                8 (y)\n",
      "            338 CALL_METHOD              1\n",
      "            340 CALL_METHOD              1\n",
      "            342 STORE_FAST               8 (y)\n",
      "\n",
      " 84         344 LOAD_FAST                8 (y)\n",
      "            346 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:25,501] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:61\n",
      "[2023-05-11 12:33:25,502] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:25,504] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [TensorVariable()]\n",
      "[2023-05-11 12:33:25,506] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:33:25,508] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2023-05-11 12:33:25,510] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST B [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,511] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST T [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,513] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST C [ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,514] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:64\n",
      "[2023-05-11 12:33:25,515] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:25,516] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_attn [NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,519] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,520] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:25,597] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR split [TensorVariable()]\n",
      "[2023-05-11 12:33:25,600] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), split)]\n",
      "[2023-05-11 12:33:25,602] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_embd [GetAttrVariable(TensorVariable(), split), NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,604] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,606] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('dim',) [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,607] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 2 [GetAttrVariable(TensorVariable(), split), ConstantVariable(int), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "[2023-05-11 12:33:25,651] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2023-05-11 12:33:25,653] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:25,654] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:25,656] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:25,657] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:65\n",
      "[2023-05-11 12:33:25,659] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2023-05-11 12:33:25,660] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:25,663] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:25,664] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,665] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,667] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,670] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,671] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,672] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,675] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,676] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:25,689] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:25,692] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:25,693] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,695] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:25,703] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k [TensorVariable()]\n",
      "[2023-05-11 12:33:25,705] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:66\n",
      "[2023-05-11 12:33:25,706] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2023-05-11 12:33:25,707] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:25,709] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:25,711] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,712] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,713] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,716] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,717] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,718] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,721] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,723] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:25,735] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:25,738] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:25,740] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,741] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:25,750] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q [TensorVariable()]\n",
      "[2023-05-11 12:33:25,751] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:67\n",
      "[2023-05-11 12:33:25,753] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v []\n",
      "[2023-05-11 12:33:25,755] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:25,757] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:25,759] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,760] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,761] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,764] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,766] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,771] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR n_head [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,774] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_FLOOR_DIVIDE None [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,776] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 4 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:25,785] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:25,787] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:25,789] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,790] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:25,799] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST v [TensorVariable()]\n",
      "[2023-05-11 12:33:25,800] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:70\n",
      "[2023-05-11 12:33:25,802] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:25,803] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flash [NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,806] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 184 [ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:25,808] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:72\n",
      "[2023-05-11 12:33:25,809] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-05-11 12:33:25,811] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR nn [TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:25,816] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/__init__.py'>)]\n",
      "[2023-05-11 12:33:25,819] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR scaled_dot_product_attention [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:25,821] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TorchVariable(<built-in function scaled_dot_product_attention>)]\n",
      "[2023-05-11 12:33:25,823] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable()]\n",
      "[2023-05-11 12:33:25,824] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST v [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:25,826] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:25,827] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:25,828] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,830] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 172 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:25,832] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:25,833] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), NNModuleVariable()]\n",
      "[2023-05-11 12:33:25,835] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 174 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:25,837] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:25,838] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('attn_mask', 'dropout_p', 'is_causal') [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:25,839] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 6 [TorchVariable(<built-in function scaled_dot_product_attention>), TensorVariable(), TensorVariable(), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(float), ConstantVariable(bool), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._fused_sdp_choice.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill_.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add_.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:25,980] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:25,983] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 302 []\n",
      "[2023-05-11 12:33:25,984] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:80\n",
      "[2023-05-11 12:33:25,985] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:25,987] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transpose [TensorVariable()]\n",
      "[2023-05-11 12:33:25,991] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2023-05-11 12:33:25,993] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:25,994] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "[2023-05-11 12:33:26,002] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR contiguous [TensorVariable()]\n",
      "[2023-05-11 12:33:26,005] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), contiguous)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "[2023-05-11 12:33:26,013] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-05-11 12:33:26,016] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST B [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:26,018] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST T [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:26,019] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST C [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:26,021] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 3 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:26,030] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:26,031] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:83\n",
      "[2023-05-11 12:33:26,033] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:26,034] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR resid_dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:26,039] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NNModuleVariable()]\n",
      "[2023-05-11 12:33:26,041] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:26,044] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:26,046] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:26,119] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:26,142] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-05-11 12:33:26,144] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:84\n",
      "[2023-05-11 12:33:26,145] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-05-11 12:33:26,147] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:26,148] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789210, file \"/home/jls/Soft/nanoGPT/model.py\", line 60>\n",
      "[2023-05-11 12:33:26,149] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:26,159] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:26,160] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:112\n",
      "[2023-05-11 12:33:26,163] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:26,164] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2023-05-11 12:33:26,165] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR mlp [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:26,168] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:26,169] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_2 [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:26,172] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NNModuleVariable(), NNModuleVariable()]\n",
      "[2023-05-11 12:33:26,173] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:26,176] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:26,181] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:26,183] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:26,186] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:26,188] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:26,189] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:26,191] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:26,204] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:26,207] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:26,209] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:26,224] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:26,225] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:26,240] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:26,242] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:26,257] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:26,259] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:26,260] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:26,263] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94> \n",
      "  95           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (c_fc)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               1 (x)\n",
      "\n",
      " 96          10 LOAD_GLOBAL              1 (new_gelu)\n",
      "             12 LOAD_FAST                1 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 STORE_FAST               1 (x)\n",
      "\n",
      " 97          18 LOAD_FAST                0 (self)\n",
      "             20 LOAD_METHOD              2 (c_proj)\n",
      "             22 LOAD_FAST                1 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 STORE_FAST               1 (x)\n",
      "\n",
      " 98          28 LOAD_FAST                0 (self)\n",
      "             30 LOAD_METHOD              3 (dropout)\n",
      "             32 LOAD_FAST                1 (x)\n",
      "             34 CALL_METHOD              1\n",
      "             36 STORE_FAST               1 (x)\n",
      "\n",
      " 99          38 LOAD_FAST                1 (x)\n",
      "             40 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:26,265] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:95\n",
      "[2023-05-11 12:33:26,266] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:26,270] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_fc [NNModuleVariable()]\n",
      "[2023-05-11 12:33:26,272] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:26,274] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:26,346] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:26,347] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:96\n",
      "[2023-05-11 12:33:26,349] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL new_gelu []\n",
      "[2023-05-11 12:33:26,351] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-05-11 12:33:26,354] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:26,357] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19> \n",
      "  24           0 LOAD_CONST               1 (0.5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 BINARY_MULTIPLY\n",
      "              6 LOAD_CONST               2 (1.0)\n",
      "              8 LOAD_GLOBAL              0 (torch)\n",
      "             10 LOAD_METHOD              1 (tanh)\n",
      "             12 LOAD_GLOBAL              2 (math)\n",
      "             14 LOAD_METHOD              3 (sqrt)\n",
      "             16 LOAD_CONST               3 (2.0)\n",
      "             18 LOAD_GLOBAL              2 (math)\n",
      "             20 LOAD_ATTR                4 (pi)\n",
      "             22 BINARY_TRUE_DIVIDE\n",
      "             24 CALL_METHOD              1\n",
      "             26 LOAD_FAST                0 (x)\n",
      "             28 LOAD_CONST               4 (0.044715)\n",
      "             30 LOAD_GLOBAL              0 (torch)\n",
      "             32 LOAD_METHOD              5 (pow)\n",
      "             34 LOAD_FAST                0 (x)\n",
      "             36 LOAD_CONST               5 (3.0)\n",
      "             38 CALL_METHOD              2\n",
      "             40 BINARY_MULTIPLY\n",
      "             42 BINARY_ADD\n",
      "             44 BINARY_MULTIPLY\n",
      "             46 CALL_METHOD              1\n",
      "             48 BINARY_ADD\n",
      "             50 BINARY_MULTIPLY\n",
      "             52 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:26,361] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:24\n",
      "[2023-05-11 12:33:26,362] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.5 []\n",
      "[2023-05-11 12:33:26,364] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(float)]\n",
      "[2023-05-11 12:33:26,367] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:26,375] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1.0 [TensorVariable()]\n",
      "[2023-05-11 12:33:26,377] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:26,378] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR tanh [TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:26,382] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:26,384] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:26,387] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>)]\n",
      "[2023-05-11 12:33:26,389] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:26,391] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pi [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), TorchVariable(<module 'math' from '/home/jls/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/math.cpython-310-x86_64-linux-gnu.so'>)]\n",
      "[2023-05-11 12:33:26,394] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_TRUE_DIVIDE None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:26,395] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TorchVariable(<built-in function sqrt>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:26,397] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:26,399] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0.044715 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "[2023-05-11 12:33:26,400] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float)]\n",
      "[2023-05-11 12:33:26,405] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pow [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<module 'torch' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/__init__.py'>)]\n",
      "[2023-05-11 12:33:26,408] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>)]\n",
      "[2023-05-11 12:33:26,410] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3.0 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "[2023-05-11 12:33:26,412] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method pow of type object at 0x7fe33e7c5540>), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "[2023-05-11 12:33:26,421] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:26,428] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:26,436] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:26,444] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), ConstantVariable(float), TorchVariable(<built-in method tanh of type object at 0x7fe33e7c5540>), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:26,454] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(float), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:26,462] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:26,469] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:26,471] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object new_gelu at 0x7fe376788ea0, file \"/home/jls/Soft/nanoGPT/model.py\", line 19>\n",
      "[2023-05-11 12:33:26,473] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:26,475] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:97\n",
      "[2023-05-11 12:33:26,476] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:26,477] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR c_proj [NNModuleVariable()]\n",
      "[2023-05-11 12:33:26,480] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:26,483] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:26,553] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:26,555] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:98\n",
      "[2023-05-11 12:33:26,557] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-11 12:33:26,559] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dropout [NNModuleVariable()]\n",
      "[2023-05-11 12:33:26,562] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-11 12:33:26,565] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "[2023-05-11 12:33:26,589] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:26,591] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:99\n",
      "[2023-05-11 12:33:26,592] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:26,593] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:26,595] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789630, file \"/home/jls/Soft/nanoGPT/model.py\", line 94>\n",
      "[2023-05-11 12:33:26,596] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "[2023-05-11 12:33:26,606] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-05-11 12:33:26,607] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:113\n",
      "[2023-05-11 12:33:26,608] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-05-11 12:33:26,609] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:26,611] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789840, file \"/home/jls/Soft/nanoGPT/model.py\", line 110>\n",
      "[2023-05-11 12:33:26,612] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), ListIteratorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:26,614] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 128 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:26,615] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:187\n",
      "[2023-05-11 12:33:26,616] torch._dynamo.symbolic_convert: [DEBUG] TRACE FOR_ITER 142 [ConstantVariable(str), ListIteratorVariable()]\n",
      "[2023-05-11 12:33:26,617] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:189\n",
      "[2023-05-11 12:33:26,618] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2023-05-11 12:33:26,620] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR transformer [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:33:26,622] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR ln_f [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:33:26,629] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:33:26,630] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:26,633] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34> \n",
      "  35           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_METHOD              1 (layer_norm)\n",
      "              4 LOAD_FAST                1 (input)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (weight)\n",
      "             10 LOAD_ATTR                3 (shape)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                2 (weight)\n",
      "             16 LOAD_FAST                0 (self)\n",
      "             18 LOAD_ATTR                4 (bias)\n",
      "             20 LOAD_CONST               1 (1e-05)\n",
      "             22 CALL_METHOD              5\n",
      "             24 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-05-11 12:33:26,635] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:35\n",
      "[2023-05-11 12:33:26,636] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F []\n",
      "[2023-05-11 12:33:26,638] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer_norm [TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:26,640] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [TorchVariable(<function layer_norm at 0x7fe3752cdf30>)]\n",
      "[2023-05-11 12:33:26,641] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable()]\n",
      "[2023-05-11 12:33:26,642] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:26,658] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:26,661] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable()]\n",
      "[2023-05-11 12:33:26,662] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:26,678] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:26,679] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bias [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), NNModuleVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:33:26,694] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1e-05 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:26,696] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 5 [TorchVariable(<function layer_norm at 0x7fe3752cdf30>), TensorVariable(), ShapeVariable(), TensorVariable(), TensorVariable(), ConstantVariable(float)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "[2023-05-11 12:33:26,712] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-11 12:33:26,714] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fe376789000, file \"/home/jls/Soft/nanoGPT/model.py\", line 34>\n",
      "[2023-05-11 12:33:26,715] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [ConstantVariable(str), TensorVariable()]\n",
      "[2023-05-11 12:33:26,716] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:191\n",
      "[2023-05-11 12:33:26,718] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST targets [ConstantVariable(str)]\n",
      "[2023-05-11 12:33:26,721] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(str), TensorVariable()]\n",
      "[2023-05-11 12:33:26,723] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(str), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2023-05-11 12:33:26,724] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 216 [ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2023-05-11 12:33:26,725] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:193\n",
      "[2023-05-11 12:33:26,727] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2023-05-11 12:33:26,728] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR lm_head [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:33:26,730] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [ConstantVariable(str), NNModuleVariable()]\n",
      "[2023-05-11 12:33:26,732] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), NNModuleVariable(), TensorVariable()]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:26,766] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST logits [ConstantVariable(str), TensorVariable()]\n",
      "[2023-05-11 12:33:26,767] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:194\n",
      "[2023-05-11 12:33:26,768] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL F [ConstantVariable(str)]\n",
      "[2023-05-11 12:33:26,770] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cross_entropy [ConstantVariable(str), TorchVariable(<module 'torch.nn.functional' from '/home/jls/.pyenv/versions/3.10.11/envs/nanoGPT/lib/python3.10/site-packages/torch/nn/functional.py'>)]\n",
      "[2023-05-11 12:33:26,772] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST logits [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>)]\n",
      "[2023-05-11 12:33:26,773] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), TensorVariable()]\n",
      "[2023-05-11 12:33:26,779] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:26,780] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST logits [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:26,782] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), GetAttrVariable(TensorVariable(), view), ConstantVariable(int), TensorVariable()]\n",
      "[2023-05-11 12:33:26,784] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), GetAttrVariable(TensorVariable(), view), ConstantVariable(int), GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-11 12:33:26,785] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), GetAttrVariable(TensorVariable(), view), ConstantVariable(int), GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:26,788] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:26,797] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST targets [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), TensorVariable()]\n",
      "[2023-05-11 12:33:26,799] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:26,801] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), TensorVariable(), GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-05-11 12:33:26,803] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), TensorVariable(), GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "[2023-05-11 12:33:26,811] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:26,813] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('ignore_index',) [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), TensorVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2023-05-11 12:33:26,814] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_KW 3 [ConstantVariable(str), TorchVariable(<function cross_entropy at 0x7fe3752ce4d0>), TensorVariable(), TensorVariable(), ConstantVariable(int), ConstantVariable(tuple)]\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._log_softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.log.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.nll_loss_forward.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.where.ScalarOther\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gather.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.squeeze.dim\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.neg.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.where.ScalarOther\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.device\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "[2023-05-11 12:33:26,933] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST loss [ConstantVariable(str), TensorVariable()]\n",
      "[2023-05-11 12:33:26,935] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /home/jls/Soft/nanoGPT/model.py:200\n",
      "[2023-05-11 12:33:26,937] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST logits [ConstantVariable(str)]\n",
      "[2023-05-11 12:33:26,939] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST loss [ConstantVariable(str), TensorVariable()]\n",
      "[2023-05-11 12:33:26,940] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [ConstantVariable(str), TensorVariable(), TensorVariable()]\n",
      "[2023-05-11 12:33:26,942] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [ConstantVariable(str), TupleVariable()]\n",
      "[2023-05-11 12:33:26,944] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)\n",
      "[2023-05-11 12:33:26,947] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2023-05-11 12:33:26,949] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/jls/Soft/nanoGPT/model.py, line 200 in forward>])\n",
      "[2023-05-11 12:33:27,010] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.arange.start\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.embedding.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.index.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.embedding.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.index.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._log_softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.log.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.nll_loss_forward.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.where.ScalarOther\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gather.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.squeeze.dim\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.neg.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.where.ScalarOther\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.device\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.arange.start\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.embedding.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.index.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.embedding.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.index.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ones.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tril.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.zeros_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.masked_fill.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_dropout.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.transpose.int\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.native_layer_norm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.t.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._log_softmax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.log.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.nll_loss_forward.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.where.ScalarOther\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.gather.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.squeeze.dim\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.neg.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.where.ScalarOther\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.device\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten._to_copy.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.sum.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.embedding.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.index.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.embedding.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.index.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_seed_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.lift_fresh.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.detach_.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.le.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_and.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.le.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_and.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.le.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_and.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.le.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_and.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.le.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_and.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.le.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_and.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.le.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_and.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.le.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_and.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.le.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_and.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.le.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_and.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.le.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_and.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.split.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.split_with_sizes.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:  FakeTensorMode.__torch_dispatch__: aten.narrow.default\n",
      "DEBUG:torch._subclasses.fake_tensor:   FakeTensorMode.__torch_dispatch__: aten.slice.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:    FakeTensorMode.__torch_dispatch__: aten.as_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.iota.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty.memory_format\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.le.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_and.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.logical_not.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.expand.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.tanh.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.addmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.to.dtype\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.var_mean.correction\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.rsqrt.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.amax.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.log.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gather.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.squeeze.dim\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.neg.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.is_same_size.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.is_same_size.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scatter.value\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.ne.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.exp.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.new_empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.cat.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.new_empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.cat.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.new_empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.cat.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.new_empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.cat.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.new_empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.cat.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.new_empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.cat.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.new_empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.cat.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.new_empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.cat.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.new_empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.cat.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.new_empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.cat.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.new_empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.cat.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.pow.Tensor_Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.new_empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.bmm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.clone.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten._unsafe_view.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.cat.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mm.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.view.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.permute.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sub.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.div.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.sum.dim_IntList\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.add.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.philox_rand_like.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.gt.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: prims.convert_element_type.default\n",
      "DEBUG:torch._subclasses.fake_tensor: FakeTensorMode.__torch_dispatch__: aten.empty_strided.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.mul.Tensor\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.eq.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.index_put.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.eq.Scalar\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.unsqueeze.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.scalar_tensor.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.where.self\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.full.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.index_put.default\n",
      "DEBUG:torch._subclasses.fake_tensor:FakeTensorMode.__torch_dispatch__: aten.detach.default\n",
      "[2023-05-11 12:34:09,310] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1\n",
      "[2023-05-11 12:34:09,346] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-05-11 12:34:11,958] torch._inductor.scheduler: [DEBUG] remove_buffer('buf4')\n",
      "[2023-05-11 12:34:11,985] torch._inductor.scheduler: [DEBUG] remove_buffer('buf11')\n",
      "[2023-05-11 12:34:11,986] torch._inductor.scheduler: [DEBUG] remove_buffer('buf12')\n",
      "[2023-05-11 12:34:12,013] torch._inductor.scheduler: [DEBUG] remove_buffer('buf21')\n",
      "[2023-05-11 12:34:12,029] torch._inductor.scheduler: [DEBUG] remove_buffer('buf30')\n",
      "[2023-05-11 12:34:12,048] torch._inductor.scheduler: [DEBUG] remove_buffer('buf38')\n",
      "[2023-05-11 12:34:12,050] torch._inductor.scheduler: [DEBUG] remove_buffer('buf37')\n",
      "[2023-05-11 12:34:12,065] torch._inductor.scheduler: [DEBUG] remove_buffer('buf48')\n",
      "[2023-05-11 12:34:12,081] torch._inductor.scheduler: [DEBUG] remove_buffer('buf57')\n",
      "[2023-05-11 12:34:12,101] torch._inductor.scheduler: [DEBUG] remove_buffer('buf65')\n",
      "[2023-05-11 12:34:12,102] torch._inductor.scheduler: [DEBUG] remove_buffer('buf64')\n",
      "[2023-05-11 12:34:12,119] torch._inductor.scheduler: [DEBUG] remove_buffer('buf74')\n",
      "[2023-05-11 12:34:12,135] torch._inductor.scheduler: [DEBUG] remove_buffer('buf84')\n",
      "[2023-05-11 12:34:12,156] torch._inductor.scheduler: [DEBUG] remove_buffer('buf92')\n",
      "[2023-05-11 12:34:12,157] torch._inductor.scheduler: [DEBUG] remove_buffer('buf91')\n",
      "[2023-05-11 12:34:12,172] torch._inductor.scheduler: [DEBUG] remove_buffer('buf101')\n",
      "[2023-05-11 12:34:12,189] torch._inductor.scheduler: [DEBUG] remove_buffer('buf110')\n",
      "[2023-05-11 12:34:12,209] torch._inductor.scheduler: [DEBUG] remove_buffer('buf118')\n",
      "[2023-05-11 12:34:12,211] torch._inductor.scheduler: [DEBUG] remove_buffer('buf117')\n",
      "[2023-05-11 12:34:12,226] torch._inductor.scheduler: [DEBUG] remove_buffer('buf128')\n",
      "[2023-05-11 12:34:12,241] torch._inductor.scheduler: [DEBUG] remove_buffer('buf137')\n",
      "[2023-05-11 12:34:12,260] torch._inductor.scheduler: [DEBUG] remove_buffer('buf144')\n",
      "[2023-05-11 12:34:12,262] torch._inductor.scheduler: [DEBUG] remove_buffer('buf145')\n",
      "[2023-05-11 12:34:12,279] torch._inductor.scheduler: [DEBUG] remove_buffer('buf154')\n",
      "[2023-05-11 12:34:12,295] torch._inductor.scheduler: [DEBUG] remove_buffer('buf164')\n",
      "[2023-05-11 12:34:12,314] torch._inductor.scheduler: [DEBUG] remove_buffer('buf171')\n",
      "[2023-05-11 12:34:12,316] torch._inductor.scheduler: [DEBUG] remove_buffer('buf172')\n",
      "[2023-05-11 12:34:12,329] torch._inductor.scheduler: [DEBUG] remove_buffer('buf181')\n",
      "[2023-05-11 12:34:12,346] torch._inductor.scheduler: [DEBUG] remove_buffer('buf190')\n",
      "[2023-05-11 12:34:12,366] torch._inductor.scheduler: [DEBUG] remove_buffer('buf198')\n",
      "[2023-05-11 12:34:12,367] torch._inductor.scheduler: [DEBUG] remove_buffer('buf197')\n",
      "[2023-05-11 12:34:12,383] torch._inductor.scheduler: [DEBUG] remove_buffer('buf208')\n",
      "[2023-05-11 12:34:12,397] torch._inductor.scheduler: [DEBUG] remove_buffer('buf217')\n",
      "[2023-05-11 12:34:12,416] torch._inductor.scheduler: [DEBUG] remove_buffer('buf225')\n",
      "[2023-05-11 12:34:12,418] torch._inductor.scheduler: [DEBUG] remove_buffer('buf224')\n",
      "[2023-05-11 12:34:12,434] torch._inductor.scheduler: [DEBUG] remove_buffer('buf234')\n",
      "[2023-05-11 12:34:12,450] torch._inductor.scheduler: [DEBUG] remove_buffer('buf244')\n",
      "[2023-05-11 12:34:12,470] torch._inductor.scheduler: [DEBUG] remove_buffer('buf252')\n",
      "[2023-05-11 12:34:12,471] torch._inductor.scheduler: [DEBUG] remove_buffer('buf251')\n",
      "[2023-05-11 12:34:12,485] torch._inductor.scheduler: [DEBUG] remove_buffer('buf261')\n",
      "[2023-05-11 12:34:12,502] torch._inductor.scheduler: [DEBUG] remove_buffer('buf270')\n",
      "[2023-05-11 12:34:12,522] torch._inductor.scheduler: [DEBUG] remove_buffer('buf277')\n",
      "[2023-05-11 12:34:12,523] torch._inductor.scheduler: [DEBUG] remove_buffer('buf278')\n",
      "[2023-05-11 12:34:12,539] torch._inductor.scheduler: [DEBUG] remove_buffer('buf288')\n",
      "[2023-05-11 12:34:12,555] torch._inductor.scheduler: [DEBUG] remove_buffer('buf297')\n",
      "[2023-05-11 12:34:12,575] torch._inductor.scheduler: [DEBUG] remove_buffer('buf305')\n",
      "[2023-05-11 12:34:12,577] torch._inductor.scheduler: [DEBUG] remove_buffer('buf304')\n",
      "[2023-05-11 12:34:12,594] torch._inductor.scheduler: [DEBUG] remove_buffer('buf314')\n",
      "[2023-05-11 12:34:12,609] torch._inductor.scheduler: [DEBUG] remove_buffer('buf324')\n",
      "[2023-05-11 12:34:12,616] torch._inductor.scheduler: [DEBUG] remove_buffer('buf329')\n",
      "[2023-05-11 12:34:12,617] torch._inductor.scheduler: [DEBUG] remove_buffer('buf328')\n",
      "[2023-05-11 12:34:12,623] torch._inductor.scheduler: [DEBUG] remove_buffer('buf331')\n",
      "[2023-05-11 12:34:13,429] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1\n",
      "[2023-05-11 12:34:13,432] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-05-11 12:34:13,553] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1\n",
      "[2023-05-11 12:34:15,897] torch._inductor.scheduler: [DEBUG] remove_buffer('buf2')\n",
      "[2023-05-11 12:34:15,906] torch._inductor.scheduler: [DEBUG] remove_buffer('buf6')\n",
      "[2023-05-11 12:34:15,908] torch._inductor.scheduler: [DEBUG] remove_buffer('buf7')\n",
      "[2023-05-11 12:34:15,931] torch._inductor.scheduler: [DEBUG] remove_buffer('buf23')\n",
      "[2023-05-11 12:34:15,933] torch._inductor.scheduler: [DEBUG] remove_buffer('buf22')\n",
      "[2023-05-11 12:34:15,945] torch._inductor.scheduler: [DEBUG] remove_buffer('buf35')\n",
      "[2023-05-11 12:34:15,975] torch._inductor.scheduler: [DEBUG] remove_buffer('buf48')\n",
      "[2023-05-11 12:34:15,976] torch._inductor.scheduler: [DEBUG] remove_buffer('buf47')\n",
      "[2023-05-11 12:34:15,998] torch._inductor.scheduler: [DEBUG] remove_buffer('buf64')\n",
      "[2023-05-11 12:34:15,999] torch._inductor.scheduler: [DEBUG] remove_buffer('buf63')\n",
      "[2023-05-11 12:34:16,012] torch._inductor.scheduler: [DEBUG] remove_buffer('buf76')\n",
      "[2023-05-11 12:34:16,033] torch._inductor.scheduler: [DEBUG] remove_buffer('buf88')\n",
      "[2023-05-11 12:34:16,035] torch._inductor.scheduler: [DEBUG] remove_buffer('buf89')\n",
      "[2023-05-11 12:34:16,056] torch._inductor.scheduler: [DEBUG] remove_buffer('buf104')\n",
      "[2023-05-11 12:34:16,058] torch._inductor.scheduler: [DEBUG] remove_buffer('buf105')\n",
      "[2023-05-11 12:34:16,070] torch._inductor.scheduler: [DEBUG] remove_buffer('buf117')\n",
      "[2023-05-11 12:34:16,127] torch._inductor.scheduler: [DEBUG] remove_buffer('buf130')\n",
      "[2023-05-11 12:34:16,129] torch._inductor.scheduler: [DEBUG] remove_buffer('buf129')\n",
      "[2023-05-11 12:34:16,153] torch._inductor.scheduler: [DEBUG] remove_buffer('buf145')\n",
      "[2023-05-11 12:34:16,154] torch._inductor.scheduler: [DEBUG] remove_buffer('buf146')\n",
      "[2023-05-11 12:34:16,168] torch._inductor.scheduler: [DEBUG] remove_buffer('buf158')\n",
      "[2023-05-11 12:34:16,192] torch._inductor.scheduler: [DEBUG] remove_buffer('buf171')\n",
      "[2023-05-11 12:34:16,194] torch._inductor.scheduler: [DEBUG] remove_buffer('buf170')\n",
      "[2023-05-11 12:34:16,217] torch._inductor.scheduler: [DEBUG] remove_buffer('buf186')\n",
      "[2023-05-11 12:34:16,219] torch._inductor.scheduler: [DEBUG] remove_buffer('buf187')\n",
      "[2023-05-11 12:34:16,232] torch._inductor.scheduler: [DEBUG] remove_buffer('buf199')\n",
      "[2023-05-11 12:34:16,255] torch._inductor.scheduler: [DEBUG] remove_buffer('buf212')\n",
      "[2023-05-11 12:34:16,256] torch._inductor.scheduler: [DEBUG] remove_buffer('buf211')\n",
      "[2023-05-11 12:34:16,278] torch._inductor.scheduler: [DEBUG] remove_buffer('buf227')\n",
      "[2023-05-11 12:34:16,280] torch._inductor.scheduler: [DEBUG] remove_buffer('buf228')\n",
      "[2023-05-11 12:34:16,292] torch._inductor.scheduler: [DEBUG] remove_buffer('buf240')\n",
      "[2023-05-11 12:34:16,314] torch._inductor.scheduler: [DEBUG] remove_buffer('buf252')\n",
      "[2023-05-11 12:34:16,316] torch._inductor.scheduler: [DEBUG] remove_buffer('buf253')\n",
      "[2023-05-11 12:34:16,338] torch._inductor.scheduler: [DEBUG] remove_buffer('buf268')\n",
      "[2023-05-11 12:34:16,339] torch._inductor.scheduler: [DEBUG] remove_buffer('buf269')\n",
      "[2023-05-11 12:34:16,352] torch._inductor.scheduler: [DEBUG] remove_buffer('buf281')\n",
      "[2023-05-11 12:34:16,374] torch._inductor.scheduler: [DEBUG] remove_buffer('buf293')\n",
      "[2023-05-11 12:34:16,375] torch._inductor.scheduler: [DEBUG] remove_buffer('buf294')\n",
      "[2023-05-11 12:34:16,397] torch._inductor.scheduler: [DEBUG] remove_buffer('buf309')\n",
      "[2023-05-11 12:34:16,399] torch._inductor.scheduler: [DEBUG] remove_buffer('buf310')\n",
      "[2023-05-11 12:34:16,412] torch._inductor.scheduler: [DEBUG] remove_buffer('buf322')\n",
      "[2023-05-11 12:34:16,434] torch._inductor.scheduler: [DEBUG] remove_buffer('buf334')\n",
      "[2023-05-11 12:34:16,435] torch._inductor.scheduler: [DEBUG] remove_buffer('buf335')\n",
      "[2023-05-11 12:34:16,458] torch._inductor.scheduler: [DEBUG] remove_buffer('buf351')\n",
      "[2023-05-11 12:34:16,459] torch._inductor.scheduler: [DEBUG] remove_buffer('buf350')\n",
      "[2023-05-11 12:34:16,473] torch._inductor.scheduler: [DEBUG] remove_buffer('buf363')\n",
      "[2023-05-11 12:34:16,497] torch._inductor.scheduler: [DEBUG] remove_buffer('buf376')\n",
      "[2023-05-11 12:34:16,498] torch._inductor.scheduler: [DEBUG] remove_buffer('buf375')\n",
      "[2023-05-11 12:34:16,521] torch._inductor.scheduler: [DEBUG] remove_buffer('buf391')\n",
      "[2023-05-11 12:34:16,523] torch._inductor.scheduler: [DEBUG] remove_buffer('buf392')\n",
      "[2023-05-11 12:34:16,536] torch._inductor.scheduler: [DEBUG] remove_buffer('buf404')\n",
      "[2023-05-11 12:34:16,558] torch._inductor.scheduler: [DEBUG] remove_buffer('buf417')\n",
      "[2023-05-11 12:34:16,559] torch._inductor.scheduler: [DEBUG] remove_buffer('buf416')\n",
      "[2023-05-11 12:34:16,581] torch._inductor.scheduler: [DEBUG] remove_buffer('buf432')\n",
      "[2023-05-11 12:34:16,582] torch._inductor.scheduler: [DEBUG] remove_buffer('buf433')\n",
      "[2023-05-11 12:34:16,595] torch._inductor.scheduler: [DEBUG] remove_buffer('buf445')\n",
      "[2023-05-11 12:34:16,621] torch._inductor.scheduler: [DEBUG] remove_buffer('buf458')\n",
      "[2023-05-11 12:34:16,623] torch._inductor.scheduler: [DEBUG] remove_buffer('buf457')\n",
      "[2023-05-11 12:34:16,645] torch._inductor.scheduler: [DEBUG] remove_buffer('buf474')\n",
      "[2023-05-11 12:34:16,647] torch._inductor.scheduler: [DEBUG] remove_buffer('buf473')\n",
      "[2023-05-11 12:34:16,660] torch._inductor.scheduler: [DEBUG] remove_buffer('buf486')\n",
      "[2023-05-11 12:34:16,686] torch._inductor.scheduler: [DEBUG] remove_buffer('buf499')\n",
      "[2023-05-11 12:34:16,688] torch._inductor.scheduler: [DEBUG] remove_buffer('buf498')\n",
      "[2023-05-11 12:34:17,245] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: loss 4.7659, time 108881.69ms\n",
      "iter 1: loss 5.6204, time 114.15ms\n",
      "iter 2: loss 4.8298, time 157.86ms\n",
      "iter 3: loss 5.1755, time 138.46ms\n",
      "iter 4: loss 5.0482, time 136.74ms\n",
      "iter 5: loss 4.8515, time 153.80ms\n",
      "iter 6: loss 4.8296, time 144.41ms\n",
      "iter 7: loss 4.7301, time 141.71ms\n",
      "iter 8: loss 4.7736, time 141.44ms\n",
      "iter 9: loss 4.1424, time 146.22ms\n",
      "iter 10: loss 4.2852, time 140.91ms\n",
      "iter 11: loss 4.6730, time 144.84ms\n",
      "iter 12: loss 3.8106, time 141.64ms\n",
      "iter 13: loss 4.1139, time 141.70ms\n",
      "iter 14: loss 4.4279, time 142.02ms\n",
      "iter 15: loss 4.5959, time 142.92ms\n",
      "iter 16: loss 4.4862, time 142.43ms\n",
      "iter 17: loss 4.3012, time 145.80ms\n",
      "iter 18: loss 4.2965, time 141.45ms\n",
      "iter 19: loss 3.6305, time 140.90ms\n",
      "iter 20: loss 4.1029, time 142.77ms\n",
      "iter 21: loss 4.7699, time 142.32ms\n",
      "iter 22: loss 4.7316, time 141.07ms\n",
      "iter 23: loss 4.7945, time 141.30ms\n",
      "iter 24: loss 4.7031, time 144.99ms\n",
      "iter 25: loss 4.6681, time 146.18ms\n",
      "iter 26: loss 4.5303, time 141.57ms\n",
      "iter 27: loss 4.4913, time 142.19ms\n",
      "iter 28: loss 4.3209, time 141.38ms\n",
      "iter 29: loss 4.0139, time 141.65ms\n",
      "iter 30: loss 4.4220, time 141.75ms\n",
      "iter 31: loss 4.4353, time 145.55ms\n",
      "iter 32: loss 3.6702, time 142.38ms\n",
      "iter 33: loss 4.4502, time 144.23ms\n",
      "iter 34: loss 4.2396, time 139.78ms\n",
      "iter 35: loss 4.4232, time 144.09ms\n",
      "iter 36: loss 4.1951, time 141.55ms\n",
      "iter 37: loss 4.2661, time 142.35ms\n",
      "iter 38: loss 4.5998, time 142.13ms\n",
      "iter 39: loss 4.1855, time 145.61ms\n",
      "iter 40: loss 4.4043, time 141.89ms\n",
      "iter 41: loss 4.6773, time 143.08ms\n",
      "iter 42: loss 3.7085, time 141.44ms\n",
      "iter 43: loss 4.5645, time 142.56ms\n",
      "iter 44: loss 4.1694, time 141.81ms\n",
      "iter 45: loss 4.4668, time 142.20ms\n",
      "iter 46: loss 4.2565, time 140.48ms\n",
      "iter 47: loss 4.7092, time 150.20ms\n",
      "iter 48: loss 3.2443, time 141.07ms\n",
      "iter 49: loss 4.4102, time 142.37ms\n",
      "iter 50: loss 3.8896, time 141.41ms\n",
      "iter 51: loss 4.4304, time 142.10ms\n",
      "iter 52: loss 3.6464, time 141.76ms\n",
      "iter 53: loss 4.4466, time 144.83ms\n",
      "iter 54: loss 2.5463, time 148.60ms\n",
      "iter 55: loss 3.9800, time 138.75ms\n",
      "iter 56: loss 3.7609, time 141.35ms\n",
      "iter 57: loss 4.5848, time 141.93ms\n",
      "iter 58: loss 3.6044, time 142.16ms\n",
      "iter 59: loss 2.9107, time 145.54ms\n",
      "iter 60: loss 3.5652, time 143.29ms\n",
      "iter 61: loss 3.9869, time 143.56ms\n",
      "iter 62: loss 4.6326, time 141.37ms\n",
      "iter 63: loss 3.6233, time 142.49ms\n",
      "iter 64: loss 4.2081, time 141.67ms\n",
      "iter 65: loss 4.0027, time 143.87ms\n",
      "iter 66: loss 4.5367, time 143.16ms\n",
      "iter 67: loss 4.3473, time 144.88ms\n",
      "iter 68: loss 4.0268, time 141.65ms\n",
      "iter 69: loss 3.9151, time 140.92ms\n",
      "iter 70: loss 4.5720, time 142.47ms\n",
      "iter 71: loss 3.3170, time 142.25ms\n",
      "iter 72: loss 3.9743, time 142.25ms\n",
      "iter 73: loss 4.2816, time 139.28ms\n",
      "iter 74: loss 3.7541, time 144.64ms\n",
      "iter 75: loss 4.3550, time 147.35ms\n",
      "iter 76: loss 4.3862, time 141.99ms\n",
      "iter 77: loss 3.4395, time 142.51ms\n",
      "iter 78: loss 4.1484, time 141.50ms\n",
      "iter 79: loss 4.5256, time 142.74ms\n",
      "iter 80: loss 4.1424, time 141.73ms\n",
      "iter 81: loss 4.4629, time 144.32ms\n",
      "iter 82: loss 4.3936, time 143.79ms\n",
      "iter 83: loss 4.2356, time 143.44ms\n",
      "iter 84: loss 3.2337, time 141.93ms\n",
      "iter 85: loss 3.7984, time 141.81ms\n",
      "iter 86: loss 3.5990, time 141.49ms\n",
      "iter 87: loss 3.3807, time 140.42ms\n",
      "iter 88: loss 4.6541, time 142.93ms\n",
      "iter 89: loss 3.6860, time 143.71ms\n",
      "iter 90: loss 4.5339, time 145.07ms\n",
      "iter 91: loss 4.6274, time 143.50ms\n",
      "iter 92: loss 4.0964, time 142.69ms\n",
      "iter 93: loss 4.2719, time 140.80ms\n",
      "iter 94: loss 3.6442, time 144.83ms\n",
      "iter 95: loss 3.2351, time 147.71ms\n",
      "iter 96: loss 4.5460, time 141.50ms\n",
      "iter 97: loss 3.9942, time 142.67ms\n",
      "iter 98: loss 3.8811, time 141.83ms\n",
      "iter 99: loss 4.1742, time 144.46ms\n",
      "iter 100: loss 4.3585, time 145.80ms\n",
      "iter 101: loss 3.8498, time 142.90ms\n",
      "iter 102: loss 3.8062, time 141.67ms\n",
      "iter 103: loss 4.2105, time 143.05ms\n",
      "iter 104: loss 4.3505, time 146.64ms\n",
      "iter 105: loss 4.1520, time 144.13ms\n",
      "iter 106: loss 4.2973, time 141.85ms\n",
      "iter 107: loss 4.3994, time 142.26ms\n",
      "iter 108: loss 4.3153, time 142.05ms\n",
      "iter 109: loss 3.8894, time 145.70ms\n",
      "iter 110: loss 3.9597, time 144.30ms\n",
      "iter 111: loss 3.7421, time 143.01ms\n",
      "iter 112: loss 3.7571, time 142.35ms\n",
      "iter 113: loss 3.3823, time 142.58ms\n",
      "iter 114: loss 4.3225, time 143.61ms\n",
      "iter 115: loss 3.7413, time 146.76ms\n",
      "iter 116: loss 4.3965, time 141.68ms\n",
      "iter 117: loss 4.0229, time 141.05ms\n",
      "iter 118: loss 4.1520, time 144.04ms\n",
      "iter 119: loss 3.7022, time 147.03ms\n",
      "iter 120: loss 4.1310, time 143.36ms\n",
      "iter 121: loss 3.9479, time 142.64ms\n",
      "iter 122: loss 4.1994, time 141.80ms\n",
      "iter 123: loss 2.9828, time 142.65ms\n",
      "iter 124: loss 3.9190, time 145.57ms\n",
      "iter 125: loss 4.3175, time 145.25ms\n",
      "iter 126: loss 3.5696, time 141.71ms\n",
      "iter 127: loss 4.2109, time 142.82ms\n",
      "iter 128: loss 3.1533, time 142.89ms\n",
      "iter 129: loss 4.1636, time 147.82ms\n",
      "iter 130: loss 3.4788, time 141.53ms\n",
      "iter 131: loss 4.2134, time 142.69ms\n",
      "iter 132: loss 3.2510, time 142.05ms\n",
      "iter 133: loss 3.9618, time 143.29ms\n",
      "iter 134: loss 4.1738, time 144.37ms\n",
      "iter 135: loss 1.9601, time 145.28ms\n",
      "iter 136: loss 4.0969, time 141.86ms\n",
      "iter 137: loss 4.1242, time 142.75ms\n",
      "iter 138: loss 3.9974, time 141.90ms\n",
      "iter 139: loss 4.1102, time 149.71ms\n",
      "iter 140: loss 4.3289, time 140.76ms\n",
      "iter 141: loss 4.2627, time 142.99ms\n",
      "iter 142: loss 3.0727, time 141.75ms\n",
      "iter 143: loss 4.2717, time 142.87ms\n",
      "iter 144: loss 3.5647, time 146.64ms\n",
      "iter 145: loss 4.1172, time 144.94ms\n",
      "iter 146: loss 3.8350, time 141.77ms\n",
      "iter 147: loss 4.2517, time 142.47ms\n",
      "iter 148: loss 3.6493, time 141.85ms\n",
      "iter 149: loss 4.2323, time 143.70ms\n",
      "iter 150: loss 4.2531, time 145.07ms\n",
      "iter 151: loss 3.1370, time 144.76ms\n",
      "iter 152: loss 4.1363, time 141.45ms\n",
      "iter 153: loss 3.2262, time 142.73ms\n",
      "iter 154: loss 3.7314, time 145.48ms\n",
      "iter 155: loss 4.0215, time 145.34ms\n",
      "iter 156: loss 4.1774, time 141.85ms\n",
      "iter 157: loss 3.9637, time 142.78ms\n",
      "iter 158: loss 3.5526, time 142.69ms\n",
      "iter 159: loss 3.3694, time 145.77ms\n",
      "iter 160: loss 4.1214, time 143.40ms\n",
      "iter 161: loss 4.2493, time 142.61ms\n",
      "iter 162: loss 3.5059, time 142.29ms\n",
      "iter 163: loss 4.2786, time 144.07ms\n",
      "iter 164: loss 3.5001, time 144.81ms\n",
      "iter 165: loss 3.7616, time 144.77ms\n",
      "iter 166: loss 3.1143, time 141.72ms\n",
      "iter 167: loss 4.2147, time 142.78ms\n",
      "iter 168: loss 4.4029, time 141.79ms\n",
      "iter 169: loss 3.4211, time 146.93ms\n",
      "iter 170: loss 3.1852, time 143.41ms\n",
      "iter 171: loss 3.6325, time 142.48ms\n",
      "iter 172: loss 3.5719, time 142.55ms\n",
      "iter 173: loss 4.2681, time 140.54ms\n",
      "iter 174: loss 4.0410, time 147.34ms\n",
      "iter 175: loss 4.0848, time 144.81ms\n",
      "iter 176: loss 4.0777, time 142.00ms\n",
      "iter 177: loss 3.3458, time 140.96ms\n",
      "iter 178: loss 4.1701, time 143.62ms\n",
      "iter 179: loss 4.3043, time 146.67ms\n",
      "iter 180: loss 4.1073, time 142.47ms\n",
      "iter 181: loss 3.1811, time 144.43ms\n",
      "iter 182: loss 3.6492, time 141.72ms\n",
      "iter 183: loss 3.5073, time 143.14ms\n",
      "iter 184: loss 3.8494, time 146.33ms\n",
      "iter 185: loss 4.2078, time 144.10ms\n",
      "iter 186: loss 2.6538, time 141.77ms\n",
      "iter 187: loss 3.6245, time 142.19ms\n",
      "iter 188: loss 4.3063, time 144.68ms\n",
      "iter 189: loss 3.8789, time 146.91ms\n",
      "iter 190: loss 3.7255, time 141.46ms\n",
      "iter 191: loss 3.9807, time 142.74ms\n",
      "iter 192: loss 3.5675, time 143.02ms\n",
      "iter 193: loss 3.3905, time 147.79ms\n",
      "iter 194: loss 3.9707, time 141.57ms\n",
      "iter 195: loss 3.8085, time 142.56ms\n",
      "iter 196: loss 3.3495, time 141.80ms\n",
      "iter 197: loss 3.8370, time 147.23ms\n",
      "iter 198: loss 3.5486, time 143.76ms\n",
      "iter 199: loss 4.2290, time 142.40ms\n",
      "iter 200: loss 4.3638, time 141.79ms\n",
      "iter 201: loss 3.9346, time 147.10ms\n",
      "iter 202: loss 3.8296, time 143.43ms\n",
      "iter 203: loss 3.7253, time 143.16ms\n",
      "iter 204: loss 3.5562, time 142.56ms\n",
      "iter 205: loss 3.4261, time 146.08ms\n",
      "iter 206: loss 4.2895, time 143.91ms\n",
      "iter 207: loss 3.5381, time 144.42ms\n",
      "iter 208: loss 3.9422, time 147.06ms\n",
      "iter 209: loss 4.1533, time 143.17ms\n",
      "iter 210: loss 4.0094, time 142.40ms\n",
      "iter 211: loss 2.8582, time 147.38ms\n",
      "iter 212: loss 3.6892, time 143.26ms\n",
      "iter 213: loss 3.6027, time 142.85ms\n",
      "iter 214: loss 2.1415, time 144.11ms\n",
      "iter 215: loss 3.8956, time 145.76ms\n",
      "iter 216: loss 3.7348, time 144.29ms\n",
      "iter 217: loss 4.2421, time 145.57ms\n",
      "iter 218: loss 4.1468, time 145.08ms\n",
      "iter 219: loss 3.9054, time 142.83ms\n",
      "iter 220: loss 4.1351, time 142.32ms\n",
      "iter 221: loss 3.7158, time 148.23ms\n",
      "iter 222: loss 3.9931, time 142.20ms\n",
      "iter 223: loss 3.4853, time 143.45ms\n",
      "iter 224: loss 3.8074, time 147.31ms\n",
      "iter 225: loss 3.6726, time 143.63ms\n",
      "iter 226: loss 3.7920, time 141.92ms\n",
      "iter 227: loss 3.7030, time 149.00ms\n",
      "iter 228: loss 3.4731, time 142.58ms\n",
      "iter 229: loss 3.7725, time 143.88ms\n",
      "iter 230: loss 3.8200, time 147.51ms\n",
      "iter 231: loss 4.1317, time 142.63ms\n",
      "iter 232: loss 3.9015, time 142.57ms\n",
      "iter 233: loss 3.7085, time 145.51ms\n",
      "iter 234: loss 3.1501, time 145.39ms\n",
      "iter 235: loss 3.9664, time 142.81ms\n",
      "iter 236: loss 3.5101, time 143.24ms\n",
      "iter 237: loss 3.7250, time 148.12ms\n",
      "iter 238: loss 3.7680, time 141.98ms\n",
      "iter 239: loss 4.1553, time 144.32ms\n",
      "iter 240: loss 3.3055, time 146.94ms\n",
      "iter 241: loss 3.5450, time 142.31ms\n",
      "iter 242: loss 3.7685, time 143.01ms\n",
      "iter 243: loss 3.0484, time 146.93ms\n",
      "iter 244: loss 4.2255, time 144.02ms\n",
      "iter 245: loss 3.3536, time 143.87ms\n",
      "iter 246: loss 4.1206, time 146.68ms\n",
      "iter 247: loss 2.9970, time 141.29ms\n",
      "iter 248: loss 3.3696, time 144.19ms\n",
      "iter 249: loss 3.9972, time 148.99ms\n",
      "iter 250: loss 3.8491, time 142.41ms\n",
      "iter 251: loss 3.8361, time 142.75ms\n",
      "iter 252: loss 3.1871, time 145.26ms\n",
      "iter 253: loss 3.5168, time 143.06ms\n",
      "iter 254: loss 3.6181, time 144.76ms\n",
      "iter 255: loss 3.8753, time 145.22ms\n",
      "iter 256: loss 3.0998, time 145.13ms\n",
      "iter 257: loss 3.1278, time 142.64ms\n",
      "iter 258: loss 3.7325, time 145.49ms\n",
      "iter 259: loss 4.1172, time 145.20ms\n",
      "iter 260: loss 3.8164, time 143.55ms\n",
      "iter 261: loss 3.4403, time 145.99ms\n",
      "iter 262: loss 3.8435, time 144.75ms\n",
      "iter 263: loss 3.4090, time 143.13ms\n",
      "iter 264: loss 3.7586, time 144.74ms\n",
      "iter 265: loss 3.9895, time 145.82ms\n",
      "iter 266: loss 3.3541, time 142.13ms\n",
      "iter 267: loss 3.1326, time 144.42ms\n",
      "iter 268: loss 3.7926, time 146.18ms\n",
      "iter 269: loss 3.2994, time 143.49ms\n",
      "iter 270: loss 3.9190, time 142.96ms\n",
      "iter 271: loss 3.9915, time 147.91ms\n",
      "iter 272: loss 4.0222, time 143.97ms\n",
      "iter 273: loss 4.1020, time 143.34ms\n",
      "iter 274: loss 3.0070, time 144.18ms\n",
      "iter 275: loss 3.5428, time 144.48ms\n",
      "iter 276: loss 2.7264, time 142.94ms\n",
      "iter 277: loss 3.5059, time 146.86ms\n",
      "iter 278: loss 3.7446, time 144.25ms\n",
      "iter 279: loss 2.9148, time 141.33ms\n",
      "iter 280: loss 2.3841, time 147.93ms\n",
      "iter 281: loss 3.3040, time 144.49ms\n",
      "iter 282: loss 3.8772, time 142.35ms\n",
      "iter 283: loss 3.5133, time 149.72ms\n",
      "iter 284: loss 3.9302, time 141.87ms\n",
      "iter 285: loss 4.0221, time 142.71ms\n",
      "iter 286: loss 3.3985, time 145.22ms\n",
      "iter 287: loss 3.0425, time 145.88ms\n",
      "iter 288: loss 3.5024, time 142.38ms\n",
      "iter 289: loss 3.7205, time 147.08ms\n",
      "iter 290: loss 4.2424, time 143.87ms\n",
      "iter 291: loss 3.5473, time 143.19ms\n",
      "iter 292: loss 3.3375, time 146.18ms\n",
      "iter 293: loss 3.8371, time 145.09ms\n",
      "iter 294: loss 3.9339, time 142.69ms\n",
      "iter 295: loss 3.6389, time 145.08ms\n",
      "iter 296: loss 2.9000, time 145.72ms\n",
      "iter 297: loss 3.4663, time 141.75ms\n",
      "iter 298: loss 3.8990, time 147.97ms\n",
      "iter 299: loss 3.5852, time 144.27ms\n",
      "iter 300: loss 2.8811, time 142.15ms\n",
      "iter 301: loss 3.9330, time 147.99ms\n",
      "iter 302: loss 3.8590, time 143.46ms\n",
      "iter 303: loss 4.1326, time 143.34ms\n",
      "iter 304: loss 4.2157, time 145.07ms\n",
      "iter 305: loss 3.3799, time 145.62ms\n",
      "iter 306: loss 3.3402, time 142.38ms\n",
      "iter 307: loss 4.4793, time 146.33ms\n",
      "iter 308: loss 3.9862, time 144.96ms\n",
      "iter 309: loss 3.2496, time 143.37ms\n",
      "iter 310: loss 4.2255, time 143.34ms\n",
      "iter 311: loss 2.9871, time 147.04ms\n",
      "iter 312: loss 3.8795, time 140.65ms\n",
      "iter 313: loss 3.2894, time 148.01ms\n",
      "iter 314: loss 2.1061, time 146.18ms\n",
      "iter 315: loss 4.0524, time 141.79ms\n",
      "iter 316: loss 3.8005, time 144.27ms\n",
      "iter 317: loss 4.0280, time 147.00ms\n",
      "iter 318: loss 3.7351, time 141.98ms\n",
      "iter 319: loss 3.4192, time 146.06ms\n",
      "iter 320: loss 3.5550, time 144.96ms\n",
      "iter 321: loss 3.2129, time 143.38ms\n",
      "iter 322: loss 3.8810, time 143.41ms\n",
      "iter 323: loss 3.8777, time 148.16ms\n",
      "iter 324: loss 4.1547, time 142.30ms\n",
      "iter 325: loss 3.8275, time 144.04ms\n",
      "iter 326: loss 3.9378, time 145.77ms\n",
      "iter 327: loss 3.7041, time 144.84ms\n",
      "iter 328: loss 2.5756, time 142.28ms\n",
      "iter 329: loss 4.1190, time 147.54ms\n",
      "iter 330: loss 4.1355, time 144.44ms\n",
      "iter 331: loss 3.9641, time 143.13ms\n",
      "iter 332: loss 3.1895, time 146.16ms\n",
      "iter 333: loss 3.3412, time 144.74ms\n",
      "iter 334: loss 3.6230, time 142.06ms\n",
      "iter 335: loss 4.0488, time 149.43ms\n",
      "iter 336: loss 3.6048, time 142.02ms\n",
      "iter 337: loss 3.8795, time 140.65ms\n",
      "iter 338: loss 3.3214, time 148.87ms\n",
      "iter 339: loss 3.0543, time 144.93ms\n",
      "iter 340: loss 3.9200, time 141.97ms\n",
      "iter 341: loss 3.8931, time 149.16ms\n",
      "iter 342: loss 3.8534, time 141.80ms\n",
      "iter 343: loss 2.7580, time 143.21ms\n",
      "iter 344: loss 4.0205, time 145.58ms\n",
      "iter 345: loss 2.8273, time 145.49ms\n",
      "iter 346: loss 3.8069, time 142.43ms\n",
      "iter 347: loss 3.4257, time 149.51ms\n",
      "iter 348: loss 3.8624, time 142.29ms\n",
      "iter 349: loss 2.5574, time 143.03ms\n",
      "iter 350: loss 3.0881, time 144.02ms\n",
      "iter 351: loss 3.7378, time 147.26ms\n",
      "iter 352: loss 4.0444, time 142.41ms\n",
      "iter 353: loss 3.3227, time 143.95ms\n",
      "iter 354: loss 3.1470, time 147.61ms\n",
      "iter 355: loss 3.5724, time 142.41ms\n",
      "iter 356: loss 3.6171, time 142.75ms\n",
      "iter 357: loss 4.0230, time 147.41ms\n",
      "iter 358: loss 3.6900, time 143.63ms\n",
      "iter 359: loss 3.2384, time 143.72ms\n",
      "iter 360: loss 3.8239, time 142.72ms\n",
      "iter 361: loss 4.0822, time 152.60ms\n",
      "iter 362: loss 3.9925, time 138.37ms\n",
      "iter 363: loss 3.8946, time 144.08ms\n",
      "iter 364: loss 3.3093, time 147.80ms\n",
      "iter 365: loss 3.3277, time 143.35ms\n",
      "iter 366: loss 3.3322, time 147.41ms\n",
      "iter 367: loss 3.9922, time 143.32ms\n",
      "iter 368: loss 3.8855, time 143.95ms\n",
      "iter 369: loss 2.9442, time 149.46ms\n",
      "iter 370: loss 3.3975, time 142.18ms\n",
      "iter 371: loss 4.3277, time 149.07ms\n",
      "iter 372: loss 3.8267, time 142.93ms\n",
      "iter 373: loss 4.2522, time 146.78ms\n",
      "iter 374: loss 3.5969, time 145.44ms\n",
      "iter 375: loss 3.8424, time 141.29ms\n",
      "iter 376: loss 2.9420, time 149.29ms\n",
      "iter 377: loss 3.7524, time 145.01ms\n",
      "iter 378: loss 3.9389, time 142.54ms\n",
      "iter 379: loss 3.2949, time 149.49ms\n",
      "iter 380: loss 3.8085, time 142.95ms\n",
      "iter 381: loss 3.5711, time 137.77ms\n",
      "iter 382: loss 3.9927, time 153.94ms\n",
      "iter 383: loss 3.5926, time 143.25ms\n",
      "iter 384: loss 2.7109, time 148.61ms\n",
      "iter 385: loss 3.1065, time 142.97ms\n",
      "iter 386: loss 4.2681, time 143.39ms\n",
      "iter 387: loss 2.8448, time 148.55ms\n",
      "iter 388: loss 3.9238, time 142.66ms\n",
      "iter 389: loss 3.4406, time 149.34ms\n",
      "iter 390: loss 3.5402, time 142.56ms\n",
      "iter 391: loss 2.9782, time 146.61ms\n",
      "iter 392: loss 4.0439, time 145.59ms\n",
      "iter 393: loss 3.5077, time 143.82ms\n",
      "iter 394: loss 3.8845, time 148.52ms\n",
      "iter 395: loss 3.7251, time 141.70ms\n",
      "iter 396: loss 4.0422, time 144.18ms\n",
      "iter 397: loss 3.2200, time 149.30ms\n",
      "iter 398: loss 3.5198, time 143.40ms\n",
      "iter 399: loss 3.0809, time 148.21ms\n",
      "iter 400: loss 3.9604, time 145.09ms\n",
      "iter 401: loss 3.9350, time 145.69ms\n",
      "iter 402: loss 3.6816, time 146.66ms\n",
      "iter 403: loss 3.9018, time 142.93ms\n",
      "iter 404: loss 2.2510, time 145.59ms\n",
      "iter 405: loss 4.0269, time 144.40ms\n",
      "iter 406: loss 4.1527, time 144.87ms\n",
      "iter 407: loss 3.7026, time 148.93ms\n",
      "iter 408: loss 3.4840, time 143.31ms\n",
      "iter 409: loss 3.1720, time 148.90ms\n",
      "iter 410: loss 3.6968, time 142.94ms\n",
      "iter 411: loss 3.8479, time 145.48ms\n",
      "iter 412: loss 2.8762, time 146.90ms\n",
      "iter 413: loss 3.4473, time 141.58ms\n",
      "iter 414: loss 3.8677, time 149.27ms\n",
      "iter 415: loss 3.3173, time 144.94ms\n",
      "iter 416: loss 3.4481, time 146.08ms\n",
      "iter 417: loss 3.5739, time 144.15ms\n",
      "iter 418: loss 3.8395, time 145.77ms\n",
      "iter 419: loss 3.1413, time 148.99ms\n",
      "iter 420: loss 3.7783, time 142.75ms\n",
      "iter 421: loss 3.8940, time 147.67ms\n",
      "iter 422: loss 3.7007, time 144.28ms\n",
      "iter 423: loss 3.4496, time 145.33ms\n",
      "iter 424: loss 3.4558, time 147.18ms\n",
      "iter 425: loss 3.6740, time 143.41ms\n",
      "iter 426: loss 2.9162, time 143.11ms\n",
      "iter 427: loss 3.2376, time 146.86ms\n",
      "iter 428: loss 4.0277, time 144.56ms\n",
      "iter 429: loss 4.0829, time 149.50ms\n",
      "iter 430: loss 3.8005, time 142.55ms\n",
      "iter 431: loss 2.6402, time 146.79ms\n",
      "iter 432: loss 3.1290, time 145.48ms\n",
      "iter 433: loss 3.1049, time 143.24ms\n",
      "iter 434: loss 3.2237, time 147.36ms\n",
      "iter 435: loss 3.9786, time 143.18ms\n",
      "iter 436: loss 3.1415, time 144.39ms\n",
      "iter 437: loss 3.8853, time 149.92ms\n",
      "iter 438: loss 3.5566, time 142.00ms\n",
      "iter 439: loss 2.3887, time 138.52ms\n",
      "iter 440: loss 3.4515, time 153.68ms\n",
      "iter 441: loss 4.1331, time 141.74ms\n",
      "iter 442: loss 3.3941, time 148.77ms\n",
      "iter 443: loss 3.9617, time 145.53ms\n",
      "iter 444: loss 3.2601, time 142.85ms\n",
      "iter 445: loss 3.6327, time 147.31ms\n",
      "iter 446: loss 3.2806, time 144.66ms\n",
      "iter 447: loss 2.6248, time 147.85ms\n",
      "iter 448: loss 3.2673, time 143.99ms\n",
      "iter 449: loss 2.8004, time 143.61ms\n",
      "iter 450: loss 3.4886, time 146.44ms\n",
      "iter 451: loss 4.3130, time 140.62ms\n",
      "iter 452: loss 3.7233, time 149.42ms\n",
      "iter 453: loss 3.0657, time 148.34ms\n",
      "iter 454: loss 2.7298, time 142.63ms\n",
      "iter 455: loss 3.9639, time 149.10ms\n",
      "iter 456: loss 3.5913, time 142.94ms\n",
      "iter 457: loss 3.8947, time 144.43ms\n",
      "iter 458: loss 3.5997, time 147.74ms\n",
      "iter 459: loss 3.5962, time 142.75ms\n",
      "iter 460: loss 3.1329, time 146.35ms\n",
      "iter 461: loss 3.1706, time 146.00ms\n",
      "iter 462: loss 3.2891, time 142.54ms\n",
      "iter 463: loss 3.0812, time 149.97ms\n",
      "iter 464: loss 3.9253, time 142.68ms\n",
      "iter 465: loss 3.8940, time 146.79ms\n",
      "iter 466: loss 2.9477, time 145.60ms\n",
      "iter 467: loss 3.3385, time 143.51ms\n",
      "iter 468: loss 3.8271, time 146.08ms\n",
      "iter 469: loss 2.8030, time 146.81ms\n",
      "iter 470: loss 3.9065, time 143.02ms\n",
      "iter 471: loss 3.5605, time 149.60ms\n",
      "iter 472: loss 2.6091, time 143.00ms\n",
      "iter 473: loss 3.4428, time 147.67ms\n",
      "iter 474: loss 3.5501, time 144.45ms\n",
      "iter 475: loss 3.5908, time 144.28ms\n",
      "iter 476: loss 3.5332, time 147.61ms\n",
      "iter 477: loss 3.1280, time 143.09ms\n",
      "iter 478: loss 3.0078, time 145.91ms\n",
      "iter 479: loss 3.6534, time 144.30ms\n",
      "iter 480: loss 3.0775, time 144.49ms\n",
      "iter 481: loss 3.3083, time 148.85ms\n",
      "iter 482: loss 3.7076, time 142.94ms\n",
      "iter 483: loss 4.0093, time 148.27ms\n",
      "iter 484: loss 3.0667, time 143.68ms\n",
      "iter 485: loss 3.4054, time 146.96ms\n",
      "iter 486: loss 2.7586, time 144.99ms\n",
      "iter 487: loss 3.0082, time 143.58ms\n",
      "iter 488: loss 3.2668, time 146.04ms\n",
      "iter 489: loss 3.6394, time 146.07ms\n",
      "iter 490: loss 3.7735, time 143.71ms\n",
      "iter 491: loss 3.9812, time 148.65ms\n",
      "iter 492: loss 3.3187, time 143.08ms\n",
      "iter 493: loss 3.4206, time 148.06ms\n",
      "iter 494: loss 2.1276, time 144.43ms\n",
      "iter 495: loss 3.5826, time 144.37ms\n",
      "iter 496: loss 3.8872, time 147.74ms\n",
      "iter 497: loss 2.8736, time 143.74ms\n",
      "iter 498: loss 3.6674, time 147.40ms\n",
      "iter 499: loss 3.1800, time 145.36ms\n",
      "step 500: train loss 3.1377, val loss 3.1714\n",
      "saving checkpoint to out-calderon\n",
      "iter 500: loss 3.5835, time 13592.98ms\n",
      "iter 501: loss 3.6929, time 148.01ms\n",
      "iter 502: loss 2.8846, time 155.31ms\n",
      "iter 503: loss 3.4593, time 147.97ms\n",
      "iter 504: loss 3.4837, time 142.22ms\n",
      "iter 505: loss 3.6705, time 148.64ms\n",
      "iter 506: loss 3.7124, time 145.61ms\n",
      "iter 507: loss 3.1308, time 143.25ms\n",
      "iter 508: loss 3.4549, time 147.58ms\n",
      "iter 509: loss 3.9225, time 144.49ms\n",
      "iter 510: loss 3.8192, time 144.51ms\n",
      "iter 511: loss 3.4412, time 148.05ms\n",
      "iter 512: loss 3.1850, time 142.59ms\n",
      "iter 513: loss 3.2033, time 147.63ms\n",
      "iter 514: loss 2.5577, time 144.80ms\n",
      "iter 515: loss 3.4657, time 149.38ms\n",
      "iter 516: loss 3.9190, time 141.25ms\n",
      "iter 517: loss 2.9951, time 150.99ms\n",
      "iter 518: loss 2.3949, time 142.89ms\n",
      "iter 519: loss 2.6904, time 144.98ms\n",
      "iter 520: loss 3.3043, time 146.82ms\n",
      "iter 521: loss 2.6206, time 143.11ms\n",
      "iter 522: loss 3.9712, time 148.59ms\n",
      "iter 523: loss 3.2707, time 143.93ms\n",
      "iter 524: loss 3.0878, time 145.58ms\n",
      "iter 525: loss 4.0712, time 146.41ms\n",
      "iter 526: loss 3.7646, time 142.85ms\n",
      "iter 527: loss 3.7207, time 148.92ms\n",
      "iter 528: loss 2.8230, time 142.46ms\n",
      "iter 529: loss 3.1977, time 147.83ms\n",
      "iter 530: loss 3.2530, time 145.08ms\n",
      "iter 531: loss 3.0193, time 147.20ms\n",
      "iter 532: loss 2.5048, time 144.78ms\n",
      "iter 533: loss 3.8782, time 145.06ms\n",
      "iter 534: loss 3.3563, time 146.13ms\n",
      "iter 535: loss 3.7009, time 145.52ms\n",
      "iter 536: loss 3.6159, time 145.45ms\n",
      "iter 537: loss 3.2387, time 148.66ms\n",
      "iter 538: loss 3.2623, time 141.46ms\n",
      "iter 539: loss 3.1936, time 146.86ms\n",
      "iter 540: loss 3.5668, time 146.36ms\n",
      "iter 541: loss 3.5079, time 155.14ms\n",
      "iter 542: loss 3.2847, time 134.34ms\n",
      "iter 543: loss 3.5682, time 148.29ms\n",
      "iter 544: loss 3.8601, time 143.12ms\n",
      "iter 545: loss 3.5686, time 148.73ms\n",
      "iter 546: loss 3.6025, time 143.05ms\n",
      "iter 547: loss 3.2085, time 147.49ms\n",
      "iter 548: loss 3.8518, time 144.11ms\n",
      "iter 549: loss 3.8046, time 146.49ms\n",
      "iter 550: loss 3.0267, time 145.95ms\n",
      "iter 551: loss 3.9573, time 141.96ms\n",
      "iter 552: loss 3.3704, time 149.43ms\n",
      "iter 553: loss 3.1814, time 144.95ms\n",
      "iter 554: loss 3.7378, time 141.32ms\n",
      "iter 555: loss 2.7062, time 149.32ms\n",
      "iter 556: loss 3.1162, time 144.98ms\n",
      "iter 557: loss 3.7807, time 146.65ms\n",
      "iter 558: loss 3.0469, time 144.38ms\n",
      "iter 559: loss 3.3983, time 146.55ms\n",
      "iter 560: loss 3.4680, time 147.61ms\n",
      "iter 561: loss 2.8106, time 143.75ms\n",
      "iter 562: loss 4.0529, time 145.82ms\n",
      "iter 563: loss 3.5949, time 144.55ms\n",
      "iter 564: loss 3.7104, time 146.40ms\n",
      "iter 565: loss 3.0131, time 147.14ms\n",
      "iter 566: loss 3.0517, time 143.16ms\n",
      "iter 567: loss 3.7365, time 139.17ms\n",
      "iter 568: loss 2.7987, time 152.67ms\n",
      "iter 569: loss 3.5008, time 146.65ms\n",
      "iter 570: loss 2.9968, time 145.65ms\n",
      "iter 571: loss 3.5154, time 144.30ms\n",
      "iter 572: loss 3.8205, time 145.54ms\n",
      "iter 573: loss 2.3044, time 145.72ms\n",
      "iter 574: loss 3.3001, time 142.65ms\n",
      "iter 575: loss 3.0955, time 149.57ms\n",
      "iter 576: loss 3.5252, time 142.83ms\n",
      "iter 577: loss 2.8319, time 149.02ms\n",
      "iter 578: loss 3.4344, time 143.12ms\n",
      "iter 579: loss 3.4892, time 147.93ms\n",
      "iter 580: loss 3.6391, time 143.84ms\n",
      "iter 581: loss 3.3557, time 145.25ms\n",
      "iter 582: loss 2.6503, time 141.26ms\n",
      "iter 583: loss 3.4504, time 148.84ms\n",
      "iter 584: loss 3.7433, time 146.96ms\n",
      "iter 585: loss 3.4848, time 145.64ms\n",
      "iter 586: loss 3.6265, time 149.12ms\n",
      "iter 587: loss 3.1639, time 142.98ms\n",
      "iter 588: loss 2.6051, time 145.46ms\n",
      "iter 589: loss 3.6241, time 146.56ms\n",
      "iter 590: loss 3.4851, time 142.50ms\n",
      "iter 591: loss 3.2138, time 149.46ms\n",
      "iter 592: loss 3.4496, time 143.40ms\n",
      "iter 593: loss 3.9626, time 149.69ms\n",
      "iter 594: loss 3.3990, time 144.41ms\n",
      "iter 595: loss 3.6047, time 147.91ms\n",
      "iter 596: loss 3.5593, time 143.77ms\n",
      "iter 597: loss 2.3345, time 149.24ms\n",
      "iter 598: loss 3.0566, time 144.65ms\n",
      "iter 599: loss 2.6002, time 145.56ms\n",
      "iter 600: loss 3.7836, time 138.50ms\n",
      "iter 601: loss 3.4093, time 157.07ms\n",
      "iter 602: loss 3.1085, time 143.16ms\n",
      "iter 603: loss 2.7062, time 147.69ms\n",
      "iter 604: loss 2.8836, time 145.13ms\n",
      "iter 605: loss 2.7867, time 147.87ms\n",
      "iter 606: loss 3.3856, time 144.59ms\n",
      "iter 607: loss 3.6282, time 149.61ms\n",
      "iter 608: loss 3.2405, time 142.91ms\n",
      "iter 609: loss 3.7711, time 149.66ms\n",
      "iter 610: loss 3.2739, time 143.54ms\n",
      "iter 611: loss 3.4720, time 149.83ms\n",
      "iter 612: loss 4.0505, time 142.76ms\n",
      "iter 613: loss 3.3135, time 149.63ms\n",
      "iter 614: loss 3.1758, time 142.73ms\n",
      "iter 615: loss 3.3370, time 149.23ms\n",
      "iter 616: loss 3.1616, time 142.84ms\n",
      "iter 617: loss 3.7163, time 149.66ms\n",
      "iter 618: loss 3.1980, time 143.11ms\n",
      "iter 619: loss 2.5774, time 149.76ms\n",
      "iter 620: loss 3.8395, time 142.89ms\n",
      "iter 621: loss 3.7693, time 149.61ms\n",
      "iter 622: loss 3.0978, time 142.63ms\n",
      "iter 623: loss 3.7143, time 149.82ms\n",
      "iter 624: loss 3.4667, time 143.19ms\n",
      "iter 625: loss 3.7413, time 150.12ms\n",
      "iter 626: loss 3.8913, time 142.49ms\n",
      "iter 627: loss 2.9358, time 149.30ms\n",
      "iter 628: loss 3.0462, time 143.04ms\n",
      "iter 629: loss 3.6790, time 149.82ms\n",
      "iter 630: loss 3.7995, time 143.07ms\n",
      "iter 631: loss 3.3571, time 149.99ms\n",
      "iter 632: loss 2.0215, time 140.86ms\n",
      "iter 633: loss 3.9724, time 152.08ms\n",
      "iter 634: loss 3.8191, time 142.48ms\n",
      "iter 635: loss 3.2945, time 147.69ms\n",
      "iter 636: loss 3.5726, time 145.01ms\n",
      "iter 637: loss 3.3914, time 149.94ms\n",
      "iter 638: loss 4.0370, time 142.85ms\n",
      "iter 639: loss 3.5412, time 149.82ms\n",
      "iter 640: loss 3.0062, time 143.35ms\n",
      "iter 641: loss 2.8838, time 147.94ms\n",
      "iter 642: loss 2.6565, time 145.46ms\n",
      "iter 643: loss 2.4991, time 148.92ms\n",
      "iter 644: loss 3.3126, time 143.88ms\n",
      "iter 645: loss 3.1436, time 148.19ms\n",
      "iter 646: loss 3.0762, time 145.69ms\n",
      "iter 647: loss 3.1932, time 148.27ms\n",
      "iter 648: loss 3.4291, time 145.69ms\n",
      "iter 649: loss 2.6995, time 146.60ms\n",
      "iter 650: loss 4.1126, time 146.33ms\n",
      "iter 651: loss 3.2390, time 146.28ms\n",
      "iter 652: loss 3.2794, time 146.44ms\n",
      "iter 653: loss 2.9598, time 146.34ms\n",
      "iter 654: loss 2.9406, time 146.76ms\n",
      "iter 655: loss 3.7091, time 145.11ms\n",
      "iter 656: loss 3.0456, time 150.34ms\n",
      "iter 657: loss 3.3929, time 143.84ms\n",
      "iter 658: loss 3.4292, time 147.44ms\n",
      "iter 659: loss 2.9551, time 143.96ms\n",
      "iter 660: loss 2.4021, time 147.96ms\n",
      "iter 661: loss 3.3181, time 146.53ms\n",
      "iter 662: loss 3.2300, time 146.00ms\n",
      "iter 663: loss 3.9487, time 146.54ms\n",
      "iter 664: loss 3.7461, time 146.25ms\n",
      "iter 665: loss 3.7392, time 146.52ms\n",
      "iter 666: loss 3.7433, time 144.25ms\n",
      "iter 667: loss 2.9311, time 148.70ms\n",
      "iter 668: loss 3.7246, time 143.95ms\n",
      "iter 669: loss 4.0094, time 148.56ms\n",
      "iter 670: loss 2.9269, time 144.71ms\n",
      "iter 671: loss 2.9819, time 148.56ms\n",
      "iter 672: loss 3.1670, time 144.25ms\n",
      "iter 673: loss 3.7579, time 147.88ms\n",
      "iter 674: loss 3.8073, time 146.47ms\n",
      "iter 675: loss 3.8480, time 146.27ms\n",
      "iter 676: loss 3.4591, time 143.07ms\n",
      "iter 677: loss 3.4013, time 147.02ms\n",
      "iter 678: loss 3.3435, time 145.31ms\n",
      "iter 679: loss 2.8659, time 149.61ms\n",
      "iter 680: loss 3.0497, time 142.96ms\n",
      "iter 681: loss 3.8160, time 149.75ms\n",
      "iter 682: loss 3.4298, time 143.19ms\n",
      "iter 683: loss 3.7363, time 150.16ms\n",
      "iter 684: loss 2.6517, time 143.67ms\n",
      "iter 685: loss 3.8467, time 149.13ms\n",
      "iter 686: loss 3.2664, time 142.78ms\n",
      "iter 687: loss 3.6126, time 149.85ms\n",
      "iter 688: loss 2.5597, time 142.83ms\n",
      "iter 689: loss 3.2792, time 149.80ms\n",
      "iter 690: loss 3.8751, time 142.82ms\n",
      "iter 691: loss 3.8383, time 148.12ms\n",
      "iter 692: loss 3.1827, time 144.71ms\n",
      "iter 693: loss 2.9452, time 148.04ms\n",
      "iter 694: loss 3.5445, time 144.78ms\n",
      "iter 695: loss 3.2700, time 146.13ms\n",
      "iter 696: loss 3.4135, time 145.79ms\n",
      "iter 697: loss 2.8315, time 146.84ms\n",
      "iter 698: loss 3.0247, time 146.41ms\n",
      "iter 699: loss 3.3783, time 146.79ms\n",
      "iter 700: loss 2.7139, time 146.05ms\n",
      "iter 701: loss 2.5289, time 145.70ms\n",
      "iter 702: loss 3.8715, time 147.34ms\n",
      "iter 703: loss 4.0685, time 146.58ms\n",
      "iter 704: loss 3.6057, time 145.84ms\n",
      "iter 705: loss 3.6053, time 145.17ms\n",
      "iter 706: loss 2.9310, time 147.28ms\n",
      "iter 707: loss 3.0546, time 147.33ms\n",
      "iter 708: loss 3.8974, time 144.82ms\n",
      "iter 709: loss 3.3489, time 149.68ms\n",
      "iter 710: loss 3.1187, time 144.77ms\n",
      "iter 711: loss 3.2362, time 148.09ms\n",
      "iter 712: loss 2.3798, time 144.64ms\n",
      "iter 713: loss 3.2402, time 147.45ms\n",
      "iter 714: loss 3.0228, time 145.48ms\n",
      "iter 715: loss 3.5652, time 146.94ms\n",
      "iter 716: loss 3.5118, time 145.84ms\n",
      "iter 717: loss 3.6065, time 146.84ms\n",
      "iter 718: loss 3.5782, time 145.49ms\n",
      "iter 719: loss 3.4080, time 146.97ms\n",
      "iter 720: loss 3.8473, time 145.77ms\n",
      "iter 721: loss 3.8024, time 147.04ms\n",
      "iter 722: loss 3.3204, time 145.90ms\n",
      "iter 723: loss 3.3245, time 148.38ms\n",
      "iter 724: loss 3.4252, time 142.87ms\n",
      "iter 725: loss 3.5880, time 154.02ms\n",
      "iter 726: loss 3.7454, time 141.46ms\n",
      "iter 727: loss 3.2654, time 150.02ms\n",
      "iter 728: loss 3.7682, time 143.12ms\n",
      "iter 729: loss 3.0626, time 147.97ms\n",
      "iter 730: loss 3.8856, time 144.50ms\n",
      "iter 731: loss 3.7621, time 148.42ms\n",
      "iter 732: loss 4.0292, time 144.74ms\n",
      "iter 733: loss 2.7955, time 146.91ms\n",
      "iter 734: loss 3.5414, time 145.98ms\n",
      "iter 735: loss 2.8624, time 150.22ms\n",
      "iter 736: loss 3.2026, time 142.79ms\n",
      "iter 737: loss 3.1094, time 146.96ms\n",
      "iter 738: loss 3.9817, time 145.93ms\n",
      "iter 739: loss 2.5524, time 148.64ms\n",
      "iter 740: loss 2.5910, time 144.27ms\n",
      "iter 741: loss 2.9135, time 147.02ms\n",
      "iter 742: loss 2.8871, time 147.22ms\n",
      "iter 743: loss 3.7194, time 146.74ms\n",
      "iter 744: loss 2.9768, time 145.80ms\n",
      "iter 745: loss 3.0503, time 145.48ms\n",
      "iter 746: loss 3.7034, time 147.53ms\n",
      "iter 747: loss 3.3518, time 144.58ms\n",
      "iter 748: loss 2.9685, time 148.00ms\n",
      "iter 749: loss 2.8059, time 144.70ms\n",
      "iter 750: loss 3.2426, time 148.31ms\n",
      "iter 751: loss 2.9117, time 143.82ms\n",
      "iter 752: loss 3.8250, time 148.86ms\n",
      "iter 753: loss 3.5624, time 144.06ms\n",
      "iter 754: loss 3.7641, time 149.35ms\n",
      "iter 755: loss 3.3858, time 143.87ms\n",
      "iter 756: loss 2.6102, time 147.49ms\n",
      "iter 757: loss 3.5367, time 145.58ms\n",
      "iter 758: loss 3.1675, time 146.28ms\n",
      "iter 759: loss 3.5498, time 146.37ms\n",
      "iter 760: loss 3.5812, time 146.39ms\n",
      "iter 761: loss 3.2412, time 146.51ms\n",
      "iter 762: loss 3.2039, time 146.30ms\n",
      "iter 763: loss 3.2254, time 146.87ms\n",
      "iter 764: loss 2.5932, time 144.57ms\n",
      "iter 765: loss 2.7409, time 147.94ms\n",
      "iter 766: loss 3.1826, time 144.08ms\n",
      "iter 767: loss 3.8905, time 147.21ms\n",
      "iter 768: loss 3.1774, time 144.87ms\n",
      "iter 769: loss 2.2499, time 148.87ms\n",
      "iter 770: loss 3.7831, time 144.46ms\n",
      "iter 771: loss 3.1585, time 150.17ms\n",
      "iter 772: loss 3.4813, time 143.13ms\n",
      "iter 773: loss 3.4296, time 149.69ms\n",
      "iter 774: loss 3.7946, time 143.28ms\n",
      "iter 775: loss 2.8288, time 149.52ms\n",
      "iter 776: loss 3.8723, time 147.68ms\n",
      "iter 777: loss 3.7303, time 145.93ms\n",
      "iter 778: loss 3.2697, time 142.76ms\n",
      "iter 779: loss 3.3976, time 149.77ms\n",
      "iter 780: loss 3.3144, time 143.33ms\n",
      "iter 781: loss 3.2869, time 147.43ms\n",
      "iter 782: loss 3.7153, time 145.64ms\n",
      "iter 783: loss 4.0304, time 149.64ms\n",
      "iter 784: loss 3.9657, time 142.84ms\n",
      "iter 785: loss 3.6310, time 149.84ms\n",
      "iter 786: loss 3.3824, time 144.14ms\n",
      "iter 787: loss 3.7689, time 149.58ms\n",
      "iter 788: loss 3.2959, time 141.57ms\n",
      "iter 789: loss 3.7089, time 151.50ms\n",
      "iter 790: loss 2.1008, time 144.10ms\n",
      "iter 791: loss 2.5532, time 146.76ms\n",
      "iter 792: loss 2.8447, time 146.31ms\n",
      "iter 793: loss 2.0972, time 148.90ms\n",
      "iter 794: loss 3.6587, time 145.85ms\n",
      "iter 795: loss 3.5220, time 147.17ms\n",
      "iter 796: loss 3.2679, time 144.27ms\n",
      "iter 797: loss 3.0157, time 149.91ms\n",
      "iter 798: loss 3.3073, time 141.44ms\n",
      "iter 799: loss 3.2309, time 152.14ms\n",
      "iter 800: loss 2.9649, time 142.72ms\n",
      "iter 801: loss 3.1310, time 141.57ms\n",
      "iter 802: loss 1.9877, time 150.78ms\n",
      "iter 803: loss 2.7479, time 147.89ms\n",
      "iter 804: loss 3.0782, time 144.75ms\n",
      "iter 805: loss 3.1474, time 150.38ms\n",
      "iter 806: loss 3.4720, time 143.33ms\n",
      "iter 807: loss 3.4091, time 149.73ms\n",
      "iter 808: loss 3.2927, time 143.55ms\n",
      "iter 809: loss 3.9996, time 150.08ms\n",
      "iter 810: loss 3.0528, time 142.72ms\n",
      "iter 811: loss 3.6636, time 148.19ms\n",
      "iter 812: loss 3.5017, time 145.40ms\n",
      "iter 813: loss 3.4643, time 149.78ms\n",
      "iter 814: loss 2.4403, time 143.42ms\n",
      "iter 815: loss 3.4113, time 150.32ms\n",
      "iter 816: loss 3.1144, time 142.54ms\n",
      "iter 817: loss 3.1106, time 147.68ms\n",
      "iter 818: loss 2.3632, time 145.32ms\n",
      "iter 819: loss 3.2588, time 149.80ms\n",
      "iter 820: loss 3.0295, time 143.18ms\n",
      "iter 821: loss 2.9022, time 148.15ms\n",
      "iter 822: loss 3.1672, time 144.37ms\n",
      "iter 823: loss 3.2433, time 149.38ms\n",
      "iter 824: loss 3.4340, time 145.86ms\n",
      "iter 825: loss 3.3731, time 146.70ms\n",
      "iter 826: loss 3.9258, time 144.77ms\n",
      "iter 827: loss 3.2382, time 149.89ms\n",
      "iter 828: loss 3.7477, time 143.01ms\n",
      "iter 829: loss 2.7744, time 147.91ms\n",
      "iter 830: loss 3.4159, time 140.65ms\n",
      "iter 831: loss 3.6737, time 152.20ms\n",
      "iter 832: loss 2.8278, time 145.39ms\n",
      "iter 833: loss 2.4059, time 149.71ms\n",
      "iter 834: loss 2.9889, time 143.57ms\n",
      "iter 835: loss 3.0070, time 147.51ms\n",
      "iter 836: loss 3.3550, time 145.26ms\n",
      "iter 837: loss 2.6981, time 147.79ms\n",
      "iter 838: loss 3.5357, time 145.42ms\n",
      "iter 839: loss 3.0900, time 150.18ms\n",
      "iter 840: loss 3.3033, time 142.91ms\n",
      "iter 841: loss 2.6369, time 149.69ms\n",
      "iter 842: loss 3.2718, time 143.44ms\n",
      "iter 843: loss 3.5847, time 147.13ms\n",
      "iter 844: loss 3.5595, time 140.38ms\n",
      "iter 845: loss 3.1359, time 154.51ms\n",
      "iter 846: loss 2.9065, time 143.04ms\n",
      "iter 847: loss 2.8453, time 149.76ms\n",
      "iter 848: loss 3.1075, time 142.85ms\n",
      "iter 849: loss 3.1774, time 149.58ms\n",
      "iter 850: loss 4.0536, time 143.04ms\n",
      "iter 851: loss 3.6673, time 150.14ms\n",
      "iter 852: loss 3.2397, time 143.26ms\n",
      "iter 853: loss 2.6299, time 149.64ms\n",
      "iter 854: loss 2.9969, time 144.69ms\n",
      "iter 855: loss 2.5709, time 148.72ms\n",
      "iter 856: loss 3.5456, time 142.99ms\n",
      "iter 857: loss 1.9095, time 148.68ms\n",
      "iter 858: loss 2.7828, time 144.69ms\n",
      "iter 859: loss 3.6555, time 149.96ms\n",
      "iter 860: loss 3.4758, time 143.11ms\n",
      "iter 861: loss 3.4221, time 149.86ms\n",
      "iter 862: loss 3.5853, time 143.24ms\n",
      "iter 863: loss 2.9805, time 148.71ms\n",
      "iter 864: loss 2.9529, time 145.45ms\n",
      "iter 865: loss 2.9461, time 149.13ms\n",
      "iter 866: loss 2.8862, time 142.51ms\n",
      "iter 867: loss 3.3339, time 149.88ms\n",
      "iter 868: loss 3.8685, time 142.87ms\n",
      "iter 869: loss 3.3440, time 150.08ms\n",
      "iter 870: loss 3.0198, time 143.04ms\n",
      "iter 871: loss 2.6832, time 147.64ms\n",
      "iter 872: loss 2.6122, time 145.23ms\n",
      "iter 873: loss 3.1019, time 149.93ms\n",
      "iter 874: loss 3.4332, time 138.79ms\n",
      "iter 875: loss 3.2788, time 154.10ms\n",
      "iter 876: loss 2.3586, time 142.92ms\n",
      "iter 877: loss 3.1700, time 149.52ms\n",
      "iter 878: loss 3.2486, time 143.49ms\n",
      "iter 879: loss 3.3834, time 150.20ms\n",
      "iter 880: loss 2.9571, time 142.80ms\n",
      "iter 881: loss 3.2524, time 149.68ms\n",
      "iter 882: loss 2.4418, time 143.34ms\n",
      "iter 883: loss 2.5761, time 149.77ms\n",
      "iter 884: loss 3.5064, time 143.10ms\n",
      "iter 885: loss 3.3280, time 149.67ms\n",
      "iter 886: loss 3.4547, time 143.37ms\n",
      "iter 887: loss 3.6771, time 149.70ms\n",
      "iter 888: loss 3.6695, time 143.41ms\n",
      "iter 889: loss 2.6737, time 149.33ms\n",
      "iter 890: loss 3.0186, time 143.16ms\n",
      "iter 891: loss 3.8088, time 149.72ms\n",
      "iter 892: loss 3.4494, time 143.08ms\n",
      "iter 893: loss 2.8822, time 149.91ms\n",
      "iter 894: loss 3.0700, time 142.85ms\n",
      "iter 895: loss 3.4377, time 149.60ms\n",
      "iter 896: loss 3.6834, time 143.07ms\n",
      "iter 897: loss 2.9165, time 149.90ms\n",
      "iter 898: loss 2.6170, time 143.46ms\n",
      "iter 899: loss 3.1923, time 149.94ms\n",
      "iter 900: loss 3.3321, time 142.52ms\n",
      "iter 901: loss 2.9857, time 148.13ms\n",
      "iter 902: loss 3.1303, time 145.06ms\n",
      "iter 903: loss 3.4761, time 149.83ms\n",
      "iter 904: loss 3.5127, time 143.05ms\n",
      "iter 905: loss 3.4048, time 146.98ms\n",
      "iter 906: loss 3.0721, time 145.25ms\n",
      "iter 907: loss 2.8417, time 147.71ms\n",
      "iter 908: loss 2.6706, time 145.32ms\n",
      "iter 909: loss 2.9414, time 149.65ms\n",
      "iter 910: loss 3.2317, time 142.92ms\n",
      "iter 911: loss 3.2414, time 150.31ms\n",
      "iter 912: loss 3.7671, time 142.97ms\n",
      "iter 913: loss 3.9822, time 149.98ms\n",
      "iter 914: loss 3.7171, time 142.46ms\n",
      "iter 915: loss 2.9787, time 149.61ms\n",
      "iter 916: loss 3.0389, time 143.14ms\n",
      "iter 917: loss 2.6090, time 140.83ms\n",
      "iter 918: loss 3.3708, time 152.45ms\n",
      "iter 919: loss 2.8495, time 149.46ms\n",
      "iter 920: loss 3.2361, time 143.50ms\n",
      "iter 921: loss 3.7661, time 149.68ms\n",
      "iter 922: loss 3.5696, time 143.21ms\n",
      "iter 923: loss 3.5930, time 149.76ms\n",
      "iter 924: loss 3.4066, time 143.13ms\n",
      "iter 925: loss 3.7905, time 149.33ms\n",
      "iter 926: loss 3.3807, time 144.46ms\n",
      "iter 927: loss 3.5574, time 149.34ms\n",
      "iter 928: loss 3.1293, time 142.75ms\n",
      "iter 929: loss 3.1482, time 148.31ms\n",
      "iter 930: loss 3.4550, time 145.07ms\n",
      "iter 931: loss 3.0480, time 149.59ms\n",
      "iter 932: loss 3.4053, time 142.29ms\n",
      "iter 933: loss 3.1439, time 149.96ms\n",
      "iter 934: loss 2.8628, time 144.90ms\n",
      "iter 935: loss 2.8906, time 146.96ms\n",
      "iter 936: loss 3.4802, time 144.97ms\n",
      "iter 937: loss 3.8440, time 149.68ms\n",
      "iter 938: loss 2.3168, time 143.42ms\n",
      "iter 939: loss 3.4101, time 149.85ms\n",
      "iter 940: loss 3.6349, time 144.98ms\n",
      "iter 941: loss 3.4567, time 146.14ms\n",
      "iter 942: loss 2.8853, time 145.62ms\n",
      "iter 943: loss 2.6924, time 148.88ms\n",
      "iter 944: loss 3.7659, time 143.85ms\n",
      "iter 945: loss 3.8924, time 149.09ms\n",
      "iter 946: loss 2.6099, time 144.69ms\n",
      "iter 947: loss 3.7284, time 148.93ms\n",
      "iter 948: loss 2.6341, time 142.69ms\n",
      "iter 949: loss 2.5281, time 149.63ms\n",
      "iter 950: loss 3.3275, time 143.36ms\n",
      "iter 951: loss 3.3893, time 148.13ms\n",
      "iter 952: loss 3.4729, time 145.48ms\n",
      "iter 953: loss 3.4025, time 148.57ms\n",
      "iter 954: loss 2.9040, time 142.98ms\n",
      "iter 955: loss 3.6095, time 150.62ms\n",
      "iter 956: loss 3.6097, time 142.44ms\n",
      "iter 957: loss 2.5086, time 149.69ms\n",
      "iter 958: loss 3.5286, time 143.38ms\n",
      "iter 959: loss 2.5914, time 150.01ms\n",
      "iter 960: loss 2.8597, time 143.02ms\n",
      "iter 961: loss 2.7671, time 150.23ms\n",
      "iter 962: loss 3.8013, time 143.74ms\n",
      "iter 963: loss 2.8361, time 149.69ms\n",
      "iter 964: loss 3.5646, time 142.86ms\n",
      "iter 965: loss 2.9213, time 149.40ms\n",
      "iter 966: loss 2.9803, time 143.33ms\n",
      "iter 967: loss 3.7497, time 149.95ms\n",
      "iter 968: loss 3.7439, time 143.11ms\n",
      "iter 969: loss 2.9920, time 149.22ms\n",
      "iter 970: loss 3.6738, time 142.97ms\n",
      "iter 971: loss 2.8122, time 149.91ms\n",
      "iter 972: loss 3.2070, time 143.12ms\n",
      "iter 973: loss 3.1689, time 150.29ms\n",
      "iter 974: loss 2.8924, time 144.29ms\n",
      "iter 975: loss 3.3850, time 148.72ms\n",
      "iter 976: loss 3.6133, time 143.93ms\n",
      "iter 977: loss 2.8327, time 149.01ms\n",
      "iter 978: loss 3.7268, time 143.22ms\n",
      "iter 979: loss 3.2793, time 149.92ms\n",
      "iter 980: loss 3.2168, time 142.91ms\n",
      "iter 981: loss 3.8880, time 148.05ms\n",
      "iter 982: loss 2.7178, time 145.08ms\n",
      "iter 983: loss 3.6499, time 149.72ms\n",
      "iter 984: loss 3.5322, time 143.31ms\n",
      "iter 985: loss 3.0468, time 149.37ms\n",
      "iter 986: loss 3.5809, time 143.44ms\n",
      "iter 987: loss 3.3569, time 149.57ms\n",
      "iter 988: loss 3.2530, time 141.12ms\n",
      "iter 989: loss 3.8612, time 151.55ms\n",
      "iter 990: loss 3.0332, time 139.73ms\n",
      "iter 991: loss 3.1343, time 151.54ms\n",
      "iter 992: loss 2.2238, time 145.44ms\n",
      "iter 993: loss 3.0686, time 149.07ms\n",
      "iter 994: loss 2.9671, time 143.17ms\n",
      "iter 995: loss 3.6514, time 148.84ms\n",
      "iter 996: loss 2.7767, time 143.26ms\n",
      "iter 997: loss 2.8354, time 149.63ms\n",
      "iter 998: loss 3.2965, time 143.19ms\n",
      "iter 999: loss 2.9499, time 150.07ms\n",
      "step 1000: train loss 2.9795, val loss 2.9991\n",
      "saving checkpoint to out-calderon\n",
      "iter 1000: loss 2.2749, time 13282.17ms\n"
     ]
    }
   ],
   "source": [
    "#@markdown ## Training (custom)\n",
    "\"\"\"\n",
    "This training script can be run both on a single gpu in debug mode,\n",
    "and also in a larger training run with distributed data parallel (ddp).\n",
    "\n",
    "To run in debug mode example:\n",
    "$ python train.py --batch_size=32 --other=args\n",
    "\n",
    "To run DDP on 4 gpus on one node, example:\n",
    "$ torchrun --standalone --nproc_per_node=4 train.py\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "from contextlib import nullcontext\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "\n",
    "from model import GPTConfig, GPT\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# default config values designed to train a gpt2 (124M) on OpenWebText\n",
    "# I/O\n",
    "out_dir = 'out-calderon'\n",
    "eval_interval = 2000\n",
    "log_interval = 1\n",
    "eval_iters = 200\n",
    "eval_only = False # if True, script exits right after the first eval\n",
    "always_save_checkpoint = True # if True, always save a checkpoint after each eval\n",
    "init_from = 'gpt2' # 'scratch' or 'resume' or 'gpt2*'\n",
    "# wandb logging\n",
    "wandb_log = False # disabled by default\n",
    "wandb_project = 'calderon'\n",
    "wandb_run_name = 'ft-gpt2' # 'run' + str(time.time())\n",
    "# data\n",
    "dataset = 'calderon'\n",
    "batch_size = 12\n",
    "block_size = 1024\n",
    "# model\n",
    "n_layer = 12\n",
    "n_head = 12\n",
    "n_embd = 768\n",
    "dropout = 0.2 # for pretraining 0 is good, for finetuning try 0.1+\n",
    "# adamw optimizer\n",
    "learning_rate = 3e-5 # max learning rate\n",
    "max_iters = 600000 # total number of training iterations\n",
    "weight_decay = 1e-2\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "# learning rate decay settings\n",
    "decay_lr = False # whether to decay the learning rate\n",
    "warmup_iters = 2000 # how many steps to warm up for\n",
    "lr_decay_iters = 600000 # should be ~= max_iters per Chinchilla\n",
    "#min_lr = 6e-5 # minimum learning rate, should be ~= learning_rate/10 per Chinchilla\n",
    "# DDP settings\n",
    "backend = 'nccl' # 'nccl', 'gloo', etc.\n",
    "# system\n",
    "device = 'cuda' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1', etc.\n",
    "dtype = 'float32' # 'float32' or 'bfloat16'\n",
    "compile = False # use PyTorch 2.0 to compile the model to be faster\n",
    "\n",
    "### Custom overrides\n",
    "out_dir = 'out-calderon'\n",
    "eval_interval = 500\n",
    "wandb_log = False # feel free to turn on\n",
    "wandb_project = 'calderon'\n",
    "wandb_run_name = 'ft-' + str(time.time())\n",
    "compile = True # takes too little time to finetune, not worth it\n",
    "\n",
    "always_save_checkpoint = False\n",
    "\n",
    "dataset = 'calderon'\n",
    "init_from = 'gpt2'\n",
    "batch_size = 1\n",
    "block_size = 512\n",
    "\n",
    "learning_rate = 1e-5\n",
    "max_iters = 1000\n",
    "decay_lr = False\n",
    "# -----------------------------------------------------------------------------\n",
    "config_keys = [k for k,v in globals().items() if not k.startswith('_') and isinstance(v, (int, float, bool, str))]\n",
    "config = {k: globals()[k] for k in config_keys} # will be useful for logging\n",
    "# -----------------------------------------------------------------------------\n",
    "os.environ[\"LOCAL_RANK\"] = \"6\"\n",
    "# various inits, derived attributes, I/O setup\n",
    "ddp = int(os.environ.get('LOCAL_RANK', -1)) != -1 # is this a ddp run?\n",
    "if ddp:\n",
    "    init_process_group(backend=backend)\n",
    "    gpu_id = int(os.environ[\"LOCAL_RANK\"])\n",
    "    device = f\"cuda:{gpu_id}\"\n",
    "else:\n",
    "    gpu_id = 0 # gpu_id 0 means this is the (single) master process, basically\n",
    "\n",
    "if gpu_id == 0:\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "torch.manual_seed(1337 + gpu_id) # note: each worker gets a different seed\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
    "# note: float16 would require us to change the code to use a GradScaler\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16}[dtype]\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "\n",
    "# poor man's data loader, TODO evaluate need for actual DataLoader\n",
    "data_dir = os.path.join('data', dataset)\n",
    "train_data = np.memmap(os.path.join(data_dir, 'train.bin'), dtype=np.uint16, mode='r')\n",
    "val_data = np.memmap(os.path.join(data_dir, 'val.bin'), dtype=np.uint16, mode='r')\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n",
    "    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "# init these up here, can override if init_from='resume' (i.e. from a checkpoint)\n",
    "iter_num = 0\n",
    "best_val_loss = 1e9\n",
    "\n",
    "# model init. TODO: fix bug we should also propagate the correct vocab_size to the model_args\n",
    "model_args = dict(n_layer = n_layer, n_head = n_head, n_embd = n_embd, block_size = block_size, dropout = dropout)\n",
    "if init_from == 'scratch':\n",
    "    # init a new model from scratch\n",
    "    print(\"Initializing a new model from scratch\")\n",
    "    gptconf = GPTConfig(**model_args)\n",
    "    model = GPT(gptconf)\n",
    "elif init_from == 'resume':\n",
    "    print(f\"Resuming training from {out_dir}\")\n",
    "    # resume training from a checkpoint.\n",
    "    ckpt_path = os.path.join(out_dir, 'ckpt.pt')\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    checkpoint_model_args = checkpoint['model_args']\n",
    "    for k, v in model_args.items():\n",
    "        assert checkpoint_model_args[k] == v, \"for now\"\n",
    "        # TODO: think through how passed in params should interact with checkpoint params\n",
    "    gptconf = GPTConfig(**model_args)\n",
    "    model = GPT(gptconf)\n",
    "    state_dict = checkpoint['model']\n",
    "    # fix the keys of the state dictionary :(\n",
    "    # honestly no idea how checkpoints sometimes get this prefix, have to debug more\n",
    "    unwanted_prefix = '_orig_mod.'\n",
    "    for k,v in list(state_dict.items()):\n",
    "        if k.startswith(unwanted_prefix):\n",
    "            state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "    model.load_state_dict(state_dict)\n",
    "    iter_num = checkpoint['iter_num']\n",
    "    best_val_loss = checkpoint['best_val_loss']\n",
    "elif init_from.startswith('gpt2'):\n",
    "    print(f\"Initializing from OpenAI GPT-2 weights: {init_from}\")\n",
    "    # initialize from OpenAI GPT-2 weights\n",
    "    override_args = dict(dropout=dropout)\n",
    "    model = GPT.from_pretrained(init_from, override_args)\n",
    "    # read off and override the GPT sizing model args from the model config\n",
    "    model_args['n_layer'] = model.config.n_layer\n",
    "    model_args['n_head'] = model.config.n_head\n",
    "    model_args['n_embd'] = model.config.n_embd\n",
    "# crop down the model block size if desired\n",
    "if block_size < model.config.block_size:\n",
    "    model.crop_block_size(block_size)\n",
    "model.to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = model.configure_optimizers(weight_decay, learning_rate, (beta1, beta2), device_type);#'cpu')\n",
    "if init_from == 'resume':\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "# compile the model\n",
    "if compile:\n",
    "    print(\"compiling the model... (takes a ~minute)\")\n",
    "    unoptimized_model = model\n",
    "    model = torch.compile(model) # requires PyTorch 2.0\n",
    "\n",
    "# wrap model into DDP container\n",
    "if ddp:\n",
    "    model = DDP(model, device_ids=[gpu_id])\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            with ctx:\n",
    "                logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "# learning rate decay scheduler (cosine with warmup)\n",
    "def get_lr(iter):\n",
    "    # 1) linear warmup for warmup_iters steps\n",
    "    if iter < warmup_iters:\n",
    "        return learning_rate * iter / warmup_iters\n",
    "    # 2) if iter > lr_decay_iters, return min learning rate\n",
    "    if iter > lr_decay_iters:\n",
    "        return min_lr\n",
    "    # 3) in between, use cosine decay down to min learning rate\n",
    "    decay_ratio = (iter - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff ranges 0..1\n",
    "    return min_lr + coeff * (learning_rate - min_lr)\n",
    "\n",
    "# logging\n",
    "if wandb_log and gpu_id == 0:\n",
    "    import wandb\n",
    "    wandb.init(project=wandb_project, name=wandb_run_name, config=config)\n",
    "\n",
    "# training loop\n",
    "t0 = time.time()\n",
    "while True:\n",
    "\n",
    "    # determine the learning rate for this iteration\n",
    "    if decay_lr:\n",
    "        lr = get_lr(iter_num)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    else:\n",
    "        lr = learning_rate\n",
    "\n",
    "    if iter_num % eval_interval == 0 and gpu_id == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter_num}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        if wandb_log:\n",
    "            wandb.log({\n",
    "                \"iter\": iter_num,\n",
    "                \"train/loss\": losses['train'],\n",
    "                \"val/loss\": losses['val'],\n",
    "                \"lr\": lr,\n",
    "            })\n",
    "        if losses['val'] < best_val_loss or always_save_checkpoint:\n",
    "            best_val_loss = losses['val']\n",
    "            raw_model = model.module if ddp else model\n",
    "            if iter_num > 0:\n",
    "                checkpoint = {\n",
    "                    'model': raw_model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'model_args': model_args,\n",
    "                    'iter_num': iter_num,\n",
    "                    'best_val_loss': best_val_loss,\n",
    "                    'config': config,\n",
    "                }\n",
    "                print(f\"saving checkpoint to {out_dir}\")\n",
    "                torch.save(checkpoint, os.path.join(out_dir, 'ckpt.pt'))\n",
    "    if iter_num == 0 and eval_only:\n",
    "        break\n",
    "\n",
    "    X, Y = get_batch('train')\n",
    "    with ctx:\n",
    "        logits, loss = model(X, Y)\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    # TODO: gradient clipping evaluate need for\n",
    "    optimizer.step()\n",
    "\n",
    "    t1 = time.time()\n",
    "    dt = t1 - t0\n",
    "    t0 = t1\n",
    "    if iter_num % log_interval == 0 and gpu_id == 0:\n",
    "        lossf = loss.item() # loss as float. TODO CPU-GPU sync: profile, make sure not slow af\n",
    "        print(f\"iter {iter_num}: loss {lossf:.4f}, time {dt*1000:.2f}ms\")\n",
    "    iter_num += 1\n",
    "\n",
    "    # termination conditions\n",
    "    if iter_num > max_iters:\n",
    "        break\n",
    "\n",
    "if ddp:\n",
    "    destroy_process_group()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: init_from = gpt2\n",
      "Overriding: start = Qué dijo Segismundo?\n",
      "Overriding: num_samples = 1\n",
      "Overriding: max_new_tokens = 100\n",
      "loading weights from pretrained gpt: gpt2\n",
      "forcing vocab_size=50257, block_size=1024, bias=True\n",
      "overriding dropout rate to 0.0\n",
      "number of parameters: 123.65M\n",
      "No meta.pkl found, assuming GPT-2 encodings...\n",
      "Qué dijo Segismundo?\n",
      "\n",
      "- It has been reported that two persons have been arrested in connection with the 'accomplishments with funds related to a 'mass kidnapping' in the 'Mexico City area' in 2007.\n",
      "\n",
      "- A man was arrested yesterday on suspicion of illegally transporting narcotics before a police operation.\n",
      "\n",
      "- The suspect, who has been identified as Carlos 'El' Hernández, a Colombian citizen, was reportedly deported in 2008.\n",
      "\n",
      "- The 'mass' kidnapping affair\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "#!python sample.py --out_dir=out-calderon --device=cpu\n",
    "!python sample.py \\\n",
    "    --init_from=resume \\\n",
    "    --start=\"Qué dijo Segismundo?\" \\\n",
    "    --num_samples=1 --max_new_tokens=100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanoGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
